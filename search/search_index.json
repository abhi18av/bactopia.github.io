{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview \u00b6 Bactopia is a flexible pipeline for complete analysis of bacterial genomes. The goal of Bactopia is process your data with a broad set of tools, so that you can get to the fun part of analyses quicker! Bactopia was inspired by Staphopia , a workflow we (Tim Read and myself) released that targets Staphylococcus aureus genomes. Using what we learned from Staphopia and user feedback, Bactopia was developed from scratch with usability, portability, and speed in mind from the start. Bactopia uses Nextflow to manage the workflow, allowing for support of many types of environments (e.g. cluster or cloud). Bactopia allows for the usage of many public datasets as well as your own datasets to further enhance the analysis of your seqeuncing. Bactopia only uses software packages available from Bioconda (or other Anaconda channels ) to make installation as simple as possible for all users. To highlight the use of Bactopia Datasets , Bactopia , and Bactopia Tools , we performed an analysis of 1,664 public Lactobacillus genomes, focusing on Lactobacillus crispatus , a species that is a common part of the human vaginal microbiome. The results from this analysis are published in mSystems under the title: Bactopia: a flexible pipeline for complete analysis of bacterial genomes Bactopia Workflow \u00b6 Documentation Overview \u00b6 Quick Start Very concise and to straight the point details (unlike this!) for using Bactopia. Installation More detailed information for getting Bactopia set up on your system. Basic Usage A subset of parameters users may commonly adjust. Tutorial A brief tutorial on how to replicate the Staphopia Analysis Pipeline using Bactopia. Build Datasets A description on how to make use of datasets (public or private) with Bactopia. Workflow Overview A description of Bactopia workflow and software used. Output Overview A description of Bactopia output directories and files. Complete Usage The full set of parameters that users can tweak in Bactopia. Acknowledgements A list of datasets and software (and many thanks!) used by Bactopia.","title":"Introduction"},{"location":"#overview","text":"Bactopia is a flexible pipeline for complete analysis of bacterial genomes. The goal of Bactopia is process your data with a broad set of tools, so that you can get to the fun part of analyses quicker! Bactopia was inspired by Staphopia , a workflow we (Tim Read and myself) released that targets Staphylococcus aureus genomes. Using what we learned from Staphopia and user feedback, Bactopia was developed from scratch with usability, portability, and speed in mind from the start. Bactopia uses Nextflow to manage the workflow, allowing for support of many types of environments (e.g. cluster or cloud). Bactopia allows for the usage of many public datasets as well as your own datasets to further enhance the analysis of your seqeuncing. Bactopia only uses software packages available from Bioconda (or other Anaconda channels ) to make installation as simple as possible for all users. To highlight the use of Bactopia Datasets , Bactopia , and Bactopia Tools , we performed an analysis of 1,664 public Lactobacillus genomes, focusing on Lactobacillus crispatus , a species that is a common part of the human vaginal microbiome. The results from this analysis are published in mSystems under the title: Bactopia: a flexible pipeline for complete analysis of bacterial genomes","title":"Overview"},{"location":"#bactopia-workflow","text":"","title":"Bactopia Workflow"},{"location":"#documentation-overview","text":"Quick Start Very concise and to straight the point details (unlike this!) for using Bactopia. Installation More detailed information for getting Bactopia set up on your system. Basic Usage A subset of parameters users may commonly adjust. Tutorial A brief tutorial on how to replicate the Staphopia Analysis Pipeline using Bactopia. Build Datasets A description on how to make use of datasets (public or private) with Bactopia. Workflow Overview A description of Bactopia workflow and software used. Output Overview A description of Bactopia output directories and files. Complete Usage The full set of parameters that users can tweak in Bactopia. Acknowledgements A list of datasets and software (and many thanks!) used by Bactopia.","title":"Documentation Overview"},{"location":"acknowledgements/","text":"Acknowledgements \u00b6 Bactopia is truly a case of \"standing upon the shoulders of giants\" . Nearly every component of Bactopia was created by others and made freely available to the public. I would like to personally extend my many thanks and gratitude to the authors of these software packages and public datasets. If you've made it this far, I owe you a beer \ud83c\udf7b (or coffee \u2615!) if we ever encounter one another in person. Really, thank you very much! Please Cite Datasets and Tools If you have used Bactopia in your work, please be sure to cite any datasets or software you may have used. A citation link for each dataset/software has been made available. A BibTeX file of each citation is also available at Bactopia Datasets and Software BibTeX Public Datasets \u00b6 Below is a list of public datasets (alphabetical) that could have potentially been included during the Build Datasets step. Ariba Reference Datasets \u00b6 These datasets are available using Ariba's getref function. You can learn more about this function at Ariba's Wiki . ARG-ANNOT Gupta, S. K. et al. ARG-ANNOT, a new bioinformatic tool to discover antibiotic resistance genes in bacterial genomes. Antimicrob. Agents Chemother. 58, 212\u2013220 (2014). CARD Alcock, Brian P., et al. CARD 2020: antibiotic resistome surveillance with the comprehensive antibiotic resistance database. Nucleic acids research 48.D1, D517-D525 (2020). MEGARes Lakin, S. M. et al. MEGARes: an antimicrobial resistance database for high throughput sequencing . Nucleic Acids Res. 45, D574\u2013D580 (2017). NCBI Reference Gene Catalog Feldgarden, M. et al. Validating the NCBI AMRFinder Tool and Resistance Gene Database Using Antimicrobial Resistance Genotype-Phenotype Correlations in a Collection of NARMS Isolates . Antimicrob. Agents Chemother. (2019) plasmidfinder Carattoli, A. et al. In silico detection and typing of plasmids using PlasmidFinder and plasmid multilocus sequence typing. Antimicrob. Agents Chemother. 58, 3895\u20133903 (2014). resfinder Zankari, E. et al. Identification of acquired antimicrobial resistance genes. J. Antimicrob. Chemother. 67, 2640\u20132644 (2012). SRST2 Inouye, M. et al. SRST2: Rapid genomic surveillance for public health and hospital microbiology labs. Genome Med. 6, 90 (2014). VFDB Chen, L., Zheng, D., Liu, B., Yang, J. & Jin, Q. VFDB 2016: hierarchical and refined dataset for big data analysis--10 years on. Nucleic Acids Res. 44, D694\u20137 (2016). VirulenceFinder Joensen, K. G. et al. Real-time whole-genome sequencing for routine typing, surveillance, and outbreak detection of verotoxigenic Escherichia coli. J. Clin. Microbiol. 52, 1501\u20131510 (2014). Minmer Datasets \u00b6 Mash Refseq (release 88) Sketch Ondov, B. D. et al. Mash Screen: High-throughput sequence containment estimation for genome discovery. bioRxiv 557314 (2019). Sourmash Genbank LCA Signature Titus Brown, C. & Irber, L. sourmash: a library for MinHash sketching of DNA. JOSS 1, 27 (2016). Everything Else \u00b6 eggNOG 5.0 Database J. Huerta-Cepas, D. Szklarczyk, D. Heller, A. Hern\u00e1ndez-Plaza, S. K. Forslund, H. Cook, D. R. Mende, I. Letunic, T. Rattei, L. J. Jensen, C. von Mering, P. Bork, eggNOG 5.0: a hierarchical, functionally and phylogenetically annotated orthology resource based on 5090 organisms and 2502 viruses. Nucleic Acids Res. 47, D309\u2013D314 (2019). Genome Taxonomy Database Parks, D. H. et al. A standardized bacterial taxonomy based on genome phylogeny substantially revises the tree of life. Nat. Biotechnol. 36, 996\u20131004 (2018) Parks, D. H. et al. Selection of representative genomes for 24,706 bacterial and archaeal species clusters provide a complete genome-based taxonomy. bioRxiv 771964 (2019) NCBI RefSeq Database O\u2019Leary, N. A. et al. Reference sequence (RefSeq) database at NCBI: current status, taxonomic expansion, and functional annotation . Nucleic Acids Res. 44, D733\u201345 (2016). PLSDB - A plasmid database Galata, V., Fehlmann, T., Backes, C. & Keller, A. PLSDB: a resource of complete bacterial plasmids . Nucleic Acids Res. 47, D195\u2013D202 (2019). PubMLST.org Jolley, K. A., Bray, J. E. & Maiden, M. C. J. Open-access bacterial population genomics: BIGSdb software, the PubMLST.org website and their applications . Wellcome Open Res 3, 124 (2018). SILVA rRNA Database Quast, C. et al. The SILVA ribosomal RNA gene database project: improved data processing and web-based tools. Nucleic Acids Res. 41, D590\u20136 (2013) Software Included In Bactopia \u00b6 Below is a list of software (alphabetical) used (directly and indirectly) by Bactopia. A link to the software page as well as the citation (if available) have been included. AgrVATE Rapid identification of Staphylococcus aureus agr locus type and agr operon variants. Raghuram V., AgrVATE: Rapid identification of Staphylococcus aureus agr locus type and agr operon variants. AMRFinderPlus Find acquired antimicrobial resistance genes and some point mutations in protein or assembled nucleotide sequences. Feldgarden, M. et al. Validating the NCBI AMRFinder Tool and Resistance Gene Database Using Antimicrobial Resistance Genotype-Phenotype Correlations in a Collection of NARMS Isolates . Antimicrob. Agents Chemother. (2019) Aragorn Finds transfer RNA features (tRNA) Laslett D. and B. Canback, ARAGORN, a program to detect tRNA genes and tmRNA genes in nucleotide sequences. Nucleic Acids Res. 32(1):11-6. (2004) Ariba Antimicrobial Resistance Identification By Assembly Hunt, M. et al. ARIBA: rapid antimicrobial resistance genotyping directly from sequencing reads . Microb Genom 3, e000131 (2017). ART A set of simulation tools to generate synthetic next-generation sequencing reads W. Huang, L. Li, J. R. Myers, G. T. Marth, ART: a next-generation sequencing read simulator. Bioinformatics. 28, 593\u2013594 (2012). assembly-scan Generate basic stats for an assembly. Petit III, R. A. assembly-scan: generate basic stats for an assembly . Barrnap Bacterial ribosomal RNA predictor Seemann, T. Barrnap: Bacterial ribosomal RNA predictor BBTools BBTools is a suite of fast, multithreaded bioinformatics tools designed for analysis of DNA and RNA sequence data. Bushnell, B. BBMap short read aligner, and other bioinformatic tools. BCFtools Utilities for variant calling and manipulating VCFs and BCFs. Danecek, P. et al. BCFtools - Utilities for variant calling and manipulating VCFs and BCFs. Bedtools A powerful toolset for genome arithmetic. Quinlan, A. R. & Hall, I. M. BEDTools: a flexible suite of utilities for comparing genomic features . Bioinformatics 26, 841\u2013842 (2010). BLAST Basic Local Alignment Search Tool Camacho, C. et al. BLAST+: architecture and applications . BMC Bioinformatics 10, 421 (2009). Bowtie2 A fast and sensitive gapped read aligner B. Langmead, S. L. Salzberg, Fast gapped-read alignment with Bowtie 2. Nat. Methods. 9, 357\u2013359 (2012). BWA Burrow-Wheeler Aligner for short-read alignment Li, H. Aligning sequence reads, clone sequences and assembly contigs with BWA-MEM . arXiv [q-bio.GN] (2013). CD-Hit Accelerated for clustering the next-generation sequencing data Li, W. & Godzik, A. Cd-hit: a fast program for clustering and comparing large sets of protein or nucleotide sequences . Bioinformatics 22, 1658\u20131659 (2006). Fu, L., Niu, B., Zhu, Z., Wu, S. & Li, W. CD-HIT: accelerated for clustering the next-generation sequencing data . Bioinformatics 28, 3150\u20133152 (2012). CheckM Assess the quality of microbial genomes recovered from isolates, single cells, and metagenomes D. H. Parks, M. Imelfort, C. T. Skennerton, P. Hugenholtz, G. W. Tyson, CheckM: assessing the quality of microbial genomes recovered from isolates, single cells, and metagenomes. Genome Res. 25, 1043\u20131055 (2015). ClonalFramML Efficient Inference of Recombination in Whole Bacterial Genomes Didelot, X. & Wilson, D. J. ClonalFrameML: efficient inference of recombination in whole bacterial genomes. PLoS Comput. Biol. 11, e1004041 (2015) DIAMOND Accelerated BLAST compatible local sequence aligner. B. Buchfink, C. Xie, D. H. Huson, Fast and sensitive protein alignment using DIAMOND. Nat. Methods. 12, 59\u201360 (2015). eggNOG-mapper Fast genome-wide functional annotation through orthology assignment J. Huerta-Cepas, K. Forslund, L. P. Coelho, D. Szklarczyk, L. J. Jensen, C. von Mering, P. Bork, Fast Genome-Wide Functional Annotation through Orthology Assignment by eggNOG-Mapper. Mol. Biol. Evol. 34, 2115\u20132122 (2017). FastANI Fast Whole-Genome Similarity (ANI) Estimation Jain, C., Rodriguez-R, L. M., Phillippy, A. M., Konstantinidis, K. T. & Aluru, S. High throughput ANI analysis of 90K prokaryotic genomes reveals clear species boundaries. Nat. Commun. 9, 5114 (2018) FastQC A quality control analysis tool for high throughput sequencing data. Andrews, S. FastQC: a quality control tool for high throughput sequence data. . fastq-dl Download FASTQ files from SRA or ENA repositories. Petit III, R. A. fastq-dl: Download FASTQ files from SRA or ENA repositories. fastq-scan Output FASTQ summary statistics in JSON format Petit III, R. A. fastq-scan: generate summary statistics of input FASTQ sequences. FastTree 2 Approximately-maximum-likelihood phylogenetic trees Price, M. N., Dehal, P. S. & Arkin, A. P. FastTree 2 \u2013 Approximately Maximum-Likelihood Trees for Large Alignments. PLoS One 5, e9490 (2010) FLASH A fast and accurate tool to merge paired-end reads. Mago\u010d, T., and S. L. Salzberg, FLASH: fast length adjustment of short reads to improve genome assemblies. Bioinformatics 27.21 (2011): 2957-2963. freebayes Bayesian haplotype-based genetic polymorphism discovery and genotyping Garrison E., and G. Marth, Haplotype-based variant detection from short-read sequencing. arXiv preprint arXiv:1207.3907 [q-bio.GN] (2012) GNU Parallel A shell tool for executing jobs in parallel Tange, O. GNU Parallel 2018, March 2018 GTDB-Tk A toolkit for assigning objective taxonomic classifications to bacterial and archaeal genomes Chaumeil, P.-A., Mussig, A. J., Hugenholtz, P. & Parks, D. H. GTDB-Tk: a toolkit to classify genomes with the Genome Taxonomy Database. Bioinformatics (2019) hicap in silico typing of the H. influenzae cap locus Watts S.C. and Holt K.E. hicap: in silico serotyping of the Haemophilus influenzae capsule locus. Journal of Clinical Microbiology, JCM.00190-19 (2019). HMMER Biosequence analysis using profile hidden Markov models Eddy, S. R. Accelerated Profile HMM Searches. PLoS Comput. Biol. 7, e1002195 (2011) Infernal Searches DNA sequence databases for RNA structure and sequence similarities Nawrocki, E. P., and S. R. Eddy, Infernal 1.1: 100-fold faster RNA homology searches. Bioinformatics, 29(22), 2933-2935. (2013) IQ-TREE Efficient phylogenomic software by maximum likelihood L.-T. Nguyen, H.A. Schmidt, A. von Haeseler, B.Q. Minh (2015) IQ-TREE: A fast and effective stochastic algorithm for estimating maximum likelihood phylogenies. Mol. Biol. Evol., 32:268-274. S. Kalyaanamoorthy, B.Q. Minh, T.K.F. Wong, A. von Haeseler, L.S. Jermiin (2017) ModelFinder: Fast model selection for accurate phylogenetic estimates. Nat. Methods, 14:587-589. D.T. Hoang, O. Chernomor, A. von Haeseler, B.Q. Minh, L.S. Vinh (2018) UFBoot2: Improving the ultrafast bootstrap approximation. Mol. Biol. Evol., 35:518\u2013522. ISMapper IS mapping software Hawkey, J. et al. ISMapper: identifying transposase insertion sites in bacterial genomes from short read sequence data . BMC Genomics 16, 667 (2015). Lighter Fast and memory-efficient sequencing error corrector Song, L., Florea, L. and B. Langmead, Lighter: Fast and Memory-efficient Sequencing Error Correction without Counting . Genome Biol. 2014 Nov 15;15(11):509. MAFFT Multiple alignment program for amino acid or nucleotide sequences Katoh, K. & Standley, D. M. MAFFT multiple sequence alignment software version 7: improvements in performance and usability. Mol. Biol. Evol. 30, 772\u2013780 (2013) Mash Fast genome and metagenome distance estimation using MinHash Ondov, B. D. et al. Mash: fast genome and metagenome distance estimation using MinHash . Genome Biol. 17, 132 (2016). Ondov, B. D. et al. Mash Screen: High-throughput sequence containment estimation for genome discovery . bioRxiv 557314 (2019). Mashtree Create a tree using Mash distances Katz, L. S., Griswold, T., Morrison, S., Caravas, J., Zhang, S., den Bakker, H.C., Deng, X., and Carleton, H. A. Mashtree: a rapid comparison of whole genome sequence files. Journal of Open Source Software, 4(44), 1762, (2019) maskrc-svg Masks recombination as detected by ClonalFrameML or Gubbins Kwong, J. maskrc-svg - Masks recombination as detected by ClonalFrameML or Gubbins and draws an SVG. McCortex De novo genome assembly and multisample variant calling Turner, I., Garimella, K. V., Iqbal, Z. and G. McVean, Integrating long-range connectivity information into de Bruijn graphs. Bioinformatics 34, 2556\u20132565 (2018). MEGAHIT Ultra-fast and memory-efficient (meta-)genome assembler Li, D., et al. MEGAHIT: an ultra-fast single-node solution for large and complex metagenomics assembly via succinct de Bruijn graph. Bioinformatics 31.10 (2015): 1674-1676. MinCED Mining CRISPRs in Environmental Datasets Skennerton, C. MinCED: Mining CRISPRs in Environmental Datasets Minimap2 A versatile pairwise aligner for genomic and spliced nucleotide sequences Li, H. Minimap2: pairwise alignment for nucleotide sequences. Bioinformatics, 34:3094-3100. (2018) ncbi-genome-download Scripts to download genomes from the NCBI FTP servers Blin, K. ncbi-genome-download: Scripts to download genomes from the NCBI FTP servers Nextflow A DSL for data-driven computational pipelines. Di Tommaso, P., Chatzou, M., Floden, E. W., Barja, P.P., Palumbo, E., Notredame, C., 2017. Nextflow enables reproducible computational workflows. Nat. Biotechnol. 35, 316\u2013319. nhmmer DNA homology search with profile HMMs. Wheeler, T. J. & Eddy, S. R. nhmmer: DNA homology search with profile HMMs. Bioinformatics 29, 2487\u20132489 (2013) phyloFlash A pipeline to rapidly reconstruct the SSU rRNAs and explore phylogenetic composition of an illumina (meta)genomic dataset. H. R. Gruber-Vodicka, B.KB. Seah, E. Pruesse. phyloFlash \u2014 Rapid SSU rRNA profiling and targeted assembly from metagenomes. bioRxiv 521922 Pigz A parallel implementation of gzip for modern multi-processor, multi-core machines. Adler, M. pigz: A parallel implementation of gzip for modern multi-processor, multi-core machines. Jet Propulsion Laboratory (2015). Pilon An automated genome assembly improvement and variant detection tool Walker, B. J., et al. Pilon: an integrated tool for comprehensive microbial variant detection and genome assembly improvement. PloS one 9.11 (2014): e112963. PIRATE A toolbox for pangenome analysis and threshold evaluation. S. C. Bayliss, H. A. Thorpe, N. M. Coyle, S. K. Sheppard, E. J. Feil PIRATE: A fast and scalable pangenomics toolbox for clustering diverged orthologues in bacteria. Gigascience. 8 (2019) pplacer Phylogenetic placement and downstream analysis Matsen, F. A., Kodner, R. B. & Armbrust, E. V. pplacer: linear time maximum-likelihood and Bayesian phylogenetic placement of sequences onto a fixed reference tree. BMC Bioinformatics 11, 538 (2010) Prodigal Fast, reliable protein-coding gene prediction for prokaryotic genomes. Hyatt, D., et al. Prodigal: prokaryotic gene recognition and translation initiation site identification. BMC Bioinformatics 11.1 (2010): 119. Prokka Rapid prokaryotic genome annotation Seemann, T. Prokka: rapid prokaryotic genome annotation . Bioinformatics 30, 2068\u20132069 (2014). QUAST Quality Assessment Tool for Genome A. Gurevich, V. Saveliev, N. Vyahhi, G. Tesler, QUAST: quality assessment tool for genome assemblies. Bioinformatics. 29, 1072\u20131075 (2013). Racon Ultrafast consensus module for raw de novo genome assembly of long uncorrected reads R. Vaser, I. Sovi\u0107, N. Nagarajan, M. \u0160iki\u0107, Fast and accurate de novo genome assembly from long uncorrected reads. Genome Res. 27, 737\u2013746 (2017). RNAmmer Consistent and rapid annotation of ribosomal RNA genes Lagesen, K., et al. RNAmmer: consistent annotation of rRNA genes in genomic sequences. Nucleic Acids Res 35.9: 3100-3108. (2007) Roary Rapid large-scale prokaryote pan genome analysis Page, A. J. et al. Roary: rapid large-scale prokaryote pan genome analysis. Bioinformatics 31, 3691\u20133693 (2015) samclip Filter SAM file for soft and hard clipped alignments Seemann, T. Samclip: Filter SAM file for soft and hard clipped alignments Samtools Tools for manipulating next-generation sequencing data Li, H. et al. The Sequence Alignment/Map format and SAMtools . Bioinformatics 25, 2078\u20132079 (2009). Seqtk A fast and lightweight tool for processing sequences in the FASTA or FASTQ format. Li, H. Toolkit for processing sequences in FASTA/Q formats Shovill Faster assembly of Illumina reads Seemann, T. Shovill: De novo assembly pipeline for Illumina paired reads SignalP Finds signal peptide features in CDS Petersen, T. N., et al. SignalP 4.0: discriminating signal peptides from transmembrane regions. Nature methods 8.10: 785.(2011) SKESA Strategic Kmer Extension for Scrupulous Assemblies Souvorov, A., Agarwala, R. and D. J. Lipman. SKESA: strategic k-mer extension for scrupulous assemblies. Genome Biology 19:153 (2018)._ Snippy Rapid haploid variant calling and core genome alignment Seemann, T. Snippy: fast bacterial variant calling from NGS reads (2015) SnpEff Genomic variant annotations and functional effect prediction toolbox. Cingolani, P., et al. A program for annotating and predicting the effects of single nucleotide polymorphisms, SnpEff: SNPs in the genome of Drosophila melanogaster strain w1118; iso-2; iso-3. Fly, 6(2), 80-92 (2012) snp-dists Pairwise SNP distance matrix from a FASTA sequence alignment Seemann, T. snp-dists - Pairwise SNP distance matrix from a FASTA sequence alignment. SNP-sites Rapidly extracts SNPs from a multi-FASTA alignment. Page, A. J., et al. SNP-sites: rapid efficient extraction of SNPs from multi-FASTA alignments. Microbial Genomics 2.4 (2016). Sourmash Compute and compare MinHash signatures for DNA data sets. Titus Brown, C. and L. Irber sourmash: a library for MinHash sketching of DNA . JOSS 1, 27 (2016). SPAdes An assembly toolkit containing various assembly pipelines. Bankevich, A., et al. SPAdes: a new genome assembly algorithm and its applications to single-cell sequencing. Journal of computational biology 19.5 (2012): 455-477. spaTyper Computational method for finding spa types. Harmsen D., Claus H., Witte W., Rothg\u00e4nger J., Claus H., Turnwald D., and Vogel U.. Typing of methicillin-resistant Staphylococcus aureus in a university hospital setting using a novel software for spa-repeat determination and database management. J. Clin. Microbiol. 41:5442-5448 (2003). Sanchez-Herrero J. F., and Sullivan M. (2020, October 2). spaTyper: Staphylococcal protein A (spa) characterization pipeline . Zenodo. staphopia-sccmec A standalone version of Staphopia's SCCmec typing method. Petit III R. A., Read T. D., Staphylococcus aureus viewed from the perspective of 40,000+ genomes. PeerJ 6, e5261 (2018). Trimmomatic A flexible read trimming tool for Illumina NGS data Bolger, A. M., Lohse, M., and B. Usadel. Trimmomatic: a flexible trimmer for Illumina sequence data. Bioinformatics 30.15 (2014): 2114-2120. Unicycler Hybrid assembly pipeline for bacterial genomes R. R. Wick, L. M. Judd, C. L. Gorrie, K. E. Holt, Unicycler: Resolving bacterial genome assemblies from short and long sequencing reads. PLoS Comput. Biol. 13, e1005595 (2017). VCF-Annotator Add biological annotations to variants in a VCF file. Petit III, R. A. VCF-Annotator: Add biological annotations to variants in a VCF file. . Vcflib a simple C++ library for parsing and manipulating VCF files Garrison, E. Vcflib: A C++ library for parsing and manipulating VCF files Velvet Short read de novo assembler using de Bruijn graphs Zerbino, D. R., and E. Birney. Velvet: algorithms for de novo short read assembly using de Bruijn graphs. Genome research 18.5 (2008): 821-829. VSEARCH Versatile open-source tool for metagenomics Rognes, T., Flouri, T., Nichols, B., Quince, C. & Mah\u00e9, F. VSEARCH: a versatile open source tool for metagenomics. PeerJ 4, e2584 (2016) vt A tool set for short variant discovery in genetic sequence data. Tan, A., Abecasis, G. R., and H. M. Kang, Unified representation of genetic variants. Bioinformatics, 31(13), 2202-2204. (2015)","title":"Acknowledgements"},{"location":"acknowledgements/#acknowledgements","text":"Bactopia is truly a case of \"standing upon the shoulders of giants\" . Nearly every component of Bactopia was created by others and made freely available to the public. I would like to personally extend my many thanks and gratitude to the authors of these software packages and public datasets. If you've made it this far, I owe you a beer \ud83c\udf7b (or coffee \u2615!) if we ever encounter one another in person. Really, thank you very much! Please Cite Datasets and Tools If you have used Bactopia in your work, please be sure to cite any datasets or software you may have used. A citation link for each dataset/software has been made available. A BibTeX file of each citation is also available at Bactopia Datasets and Software BibTeX","title":"Acknowledgements"},{"location":"acknowledgements/#public-datasets","text":"Below is a list of public datasets (alphabetical) that could have potentially been included during the Build Datasets step.","title":"Public Datasets"},{"location":"acknowledgements/#ariba-reference-datasets","text":"These datasets are available using Ariba's getref function. You can learn more about this function at Ariba's Wiki . ARG-ANNOT Gupta, S. K. et al. ARG-ANNOT, a new bioinformatic tool to discover antibiotic resistance genes in bacterial genomes. Antimicrob. Agents Chemother. 58, 212\u2013220 (2014). CARD Alcock, Brian P., et al. CARD 2020: antibiotic resistome surveillance with the comprehensive antibiotic resistance database. Nucleic acids research 48.D1, D517-D525 (2020). MEGARes Lakin, S. M. et al. MEGARes: an antimicrobial resistance database for high throughput sequencing . Nucleic Acids Res. 45, D574\u2013D580 (2017). NCBI Reference Gene Catalog Feldgarden, M. et al. Validating the NCBI AMRFinder Tool and Resistance Gene Database Using Antimicrobial Resistance Genotype-Phenotype Correlations in a Collection of NARMS Isolates . Antimicrob. Agents Chemother. (2019) plasmidfinder Carattoli, A. et al. In silico detection and typing of plasmids using PlasmidFinder and plasmid multilocus sequence typing. Antimicrob. Agents Chemother. 58, 3895\u20133903 (2014). resfinder Zankari, E. et al. Identification of acquired antimicrobial resistance genes. J. Antimicrob. Chemother. 67, 2640\u20132644 (2012). SRST2 Inouye, M. et al. SRST2: Rapid genomic surveillance for public health and hospital microbiology labs. Genome Med. 6, 90 (2014). VFDB Chen, L., Zheng, D., Liu, B., Yang, J. & Jin, Q. VFDB 2016: hierarchical and refined dataset for big data analysis--10 years on. Nucleic Acids Res. 44, D694\u20137 (2016). VirulenceFinder Joensen, K. G. et al. Real-time whole-genome sequencing for routine typing, surveillance, and outbreak detection of verotoxigenic Escherichia coli. J. Clin. Microbiol. 52, 1501\u20131510 (2014).","title":"Ariba Reference Datasets"},{"location":"acknowledgements/#minmer-datasets","text":"Mash Refseq (release 88) Sketch Ondov, B. D. et al. Mash Screen: High-throughput sequence containment estimation for genome discovery. bioRxiv 557314 (2019). Sourmash Genbank LCA Signature Titus Brown, C. & Irber, L. sourmash: a library for MinHash sketching of DNA. JOSS 1, 27 (2016).","title":"Minmer Datasets"},{"location":"acknowledgements/#everything-else","text":"eggNOG 5.0 Database J. Huerta-Cepas, D. Szklarczyk, D. Heller, A. Hern\u00e1ndez-Plaza, S. K. Forslund, H. Cook, D. R. Mende, I. Letunic, T. Rattei, L. J. Jensen, C. von Mering, P. Bork, eggNOG 5.0: a hierarchical, functionally and phylogenetically annotated orthology resource based on 5090 organisms and 2502 viruses. Nucleic Acids Res. 47, D309\u2013D314 (2019). Genome Taxonomy Database Parks, D. H. et al. A standardized bacterial taxonomy based on genome phylogeny substantially revises the tree of life. Nat. Biotechnol. 36, 996\u20131004 (2018) Parks, D. H. et al. Selection of representative genomes for 24,706 bacterial and archaeal species clusters provide a complete genome-based taxonomy. bioRxiv 771964 (2019) NCBI RefSeq Database O\u2019Leary, N. A. et al. Reference sequence (RefSeq) database at NCBI: current status, taxonomic expansion, and functional annotation . Nucleic Acids Res. 44, D733\u201345 (2016). PLSDB - A plasmid database Galata, V., Fehlmann, T., Backes, C. & Keller, A. PLSDB: a resource of complete bacterial plasmids . Nucleic Acids Res. 47, D195\u2013D202 (2019). PubMLST.org Jolley, K. A., Bray, J. E. & Maiden, M. C. J. Open-access bacterial population genomics: BIGSdb software, the PubMLST.org website and their applications . Wellcome Open Res 3, 124 (2018). SILVA rRNA Database Quast, C. et al. The SILVA ribosomal RNA gene database project: improved data processing and web-based tools. Nucleic Acids Res. 41, D590\u20136 (2013)","title":"Everything Else"},{"location":"acknowledgements/#software-included-in-bactopia","text":"Below is a list of software (alphabetical) used (directly and indirectly) by Bactopia. A link to the software page as well as the citation (if available) have been included. AgrVATE Rapid identification of Staphylococcus aureus agr locus type and agr operon variants. Raghuram V., AgrVATE: Rapid identification of Staphylococcus aureus agr locus type and agr operon variants. AMRFinderPlus Find acquired antimicrobial resistance genes and some point mutations in protein or assembled nucleotide sequences. Feldgarden, M. et al. Validating the NCBI AMRFinder Tool and Resistance Gene Database Using Antimicrobial Resistance Genotype-Phenotype Correlations in a Collection of NARMS Isolates . Antimicrob. Agents Chemother. (2019) Aragorn Finds transfer RNA features (tRNA) Laslett D. and B. Canback, ARAGORN, a program to detect tRNA genes and tmRNA genes in nucleotide sequences. Nucleic Acids Res. 32(1):11-6. (2004) Ariba Antimicrobial Resistance Identification By Assembly Hunt, M. et al. ARIBA: rapid antimicrobial resistance genotyping directly from sequencing reads . Microb Genom 3, e000131 (2017). ART A set of simulation tools to generate synthetic next-generation sequencing reads W. Huang, L. Li, J. R. Myers, G. T. Marth, ART: a next-generation sequencing read simulator. Bioinformatics. 28, 593\u2013594 (2012). assembly-scan Generate basic stats for an assembly. Petit III, R. A. assembly-scan: generate basic stats for an assembly . Barrnap Bacterial ribosomal RNA predictor Seemann, T. Barrnap: Bacterial ribosomal RNA predictor BBTools BBTools is a suite of fast, multithreaded bioinformatics tools designed for analysis of DNA and RNA sequence data. Bushnell, B. BBMap short read aligner, and other bioinformatic tools. BCFtools Utilities for variant calling and manipulating VCFs and BCFs. Danecek, P. et al. BCFtools - Utilities for variant calling and manipulating VCFs and BCFs. Bedtools A powerful toolset for genome arithmetic. Quinlan, A. R. & Hall, I. M. BEDTools: a flexible suite of utilities for comparing genomic features . Bioinformatics 26, 841\u2013842 (2010). BLAST Basic Local Alignment Search Tool Camacho, C. et al. BLAST+: architecture and applications . BMC Bioinformatics 10, 421 (2009). Bowtie2 A fast and sensitive gapped read aligner B. Langmead, S. L. Salzberg, Fast gapped-read alignment with Bowtie 2. Nat. Methods. 9, 357\u2013359 (2012). BWA Burrow-Wheeler Aligner for short-read alignment Li, H. Aligning sequence reads, clone sequences and assembly contigs with BWA-MEM . arXiv [q-bio.GN] (2013). CD-Hit Accelerated for clustering the next-generation sequencing data Li, W. & Godzik, A. Cd-hit: a fast program for clustering and comparing large sets of protein or nucleotide sequences . Bioinformatics 22, 1658\u20131659 (2006). Fu, L., Niu, B., Zhu, Z., Wu, S. & Li, W. CD-HIT: accelerated for clustering the next-generation sequencing data . Bioinformatics 28, 3150\u20133152 (2012). CheckM Assess the quality of microbial genomes recovered from isolates, single cells, and metagenomes D. H. Parks, M. Imelfort, C. T. Skennerton, P. Hugenholtz, G. W. Tyson, CheckM: assessing the quality of microbial genomes recovered from isolates, single cells, and metagenomes. Genome Res. 25, 1043\u20131055 (2015). ClonalFramML Efficient Inference of Recombination in Whole Bacterial Genomes Didelot, X. & Wilson, D. J. ClonalFrameML: efficient inference of recombination in whole bacterial genomes. PLoS Comput. Biol. 11, e1004041 (2015) DIAMOND Accelerated BLAST compatible local sequence aligner. B. Buchfink, C. Xie, D. H. Huson, Fast and sensitive protein alignment using DIAMOND. Nat. Methods. 12, 59\u201360 (2015). eggNOG-mapper Fast genome-wide functional annotation through orthology assignment J. Huerta-Cepas, K. Forslund, L. P. Coelho, D. Szklarczyk, L. J. Jensen, C. von Mering, P. Bork, Fast Genome-Wide Functional Annotation through Orthology Assignment by eggNOG-Mapper. Mol. Biol. Evol. 34, 2115\u20132122 (2017). FastANI Fast Whole-Genome Similarity (ANI) Estimation Jain, C., Rodriguez-R, L. M., Phillippy, A. M., Konstantinidis, K. T. & Aluru, S. High throughput ANI analysis of 90K prokaryotic genomes reveals clear species boundaries. Nat. Commun. 9, 5114 (2018) FastQC A quality control analysis tool for high throughput sequencing data. Andrews, S. FastQC: a quality control tool for high throughput sequence data. . fastq-dl Download FASTQ files from SRA or ENA repositories. Petit III, R. A. fastq-dl: Download FASTQ files from SRA or ENA repositories. fastq-scan Output FASTQ summary statistics in JSON format Petit III, R. A. fastq-scan: generate summary statistics of input FASTQ sequences. FastTree 2 Approximately-maximum-likelihood phylogenetic trees Price, M. N., Dehal, P. S. & Arkin, A. P. FastTree 2 \u2013 Approximately Maximum-Likelihood Trees for Large Alignments. PLoS One 5, e9490 (2010) FLASH A fast and accurate tool to merge paired-end reads. Mago\u010d, T., and S. L. Salzberg, FLASH: fast length adjustment of short reads to improve genome assemblies. Bioinformatics 27.21 (2011): 2957-2963. freebayes Bayesian haplotype-based genetic polymorphism discovery and genotyping Garrison E., and G. Marth, Haplotype-based variant detection from short-read sequencing. arXiv preprint arXiv:1207.3907 [q-bio.GN] (2012) GNU Parallel A shell tool for executing jobs in parallel Tange, O. GNU Parallel 2018, March 2018 GTDB-Tk A toolkit for assigning objective taxonomic classifications to bacterial and archaeal genomes Chaumeil, P.-A., Mussig, A. J., Hugenholtz, P. & Parks, D. H. GTDB-Tk: a toolkit to classify genomes with the Genome Taxonomy Database. Bioinformatics (2019) hicap in silico typing of the H. influenzae cap locus Watts S.C. and Holt K.E. hicap: in silico serotyping of the Haemophilus influenzae capsule locus. Journal of Clinical Microbiology, JCM.00190-19 (2019). HMMER Biosequence analysis using profile hidden Markov models Eddy, S. R. Accelerated Profile HMM Searches. PLoS Comput. Biol. 7, e1002195 (2011) Infernal Searches DNA sequence databases for RNA structure and sequence similarities Nawrocki, E. P., and S. R. Eddy, Infernal 1.1: 100-fold faster RNA homology searches. Bioinformatics, 29(22), 2933-2935. (2013) IQ-TREE Efficient phylogenomic software by maximum likelihood L.-T. Nguyen, H.A. Schmidt, A. von Haeseler, B.Q. Minh (2015) IQ-TREE: A fast and effective stochastic algorithm for estimating maximum likelihood phylogenies. Mol. Biol. Evol., 32:268-274. S. Kalyaanamoorthy, B.Q. Minh, T.K.F. Wong, A. von Haeseler, L.S. Jermiin (2017) ModelFinder: Fast model selection for accurate phylogenetic estimates. Nat. Methods, 14:587-589. D.T. Hoang, O. Chernomor, A. von Haeseler, B.Q. Minh, L.S. Vinh (2018) UFBoot2: Improving the ultrafast bootstrap approximation. Mol. Biol. Evol., 35:518\u2013522. ISMapper IS mapping software Hawkey, J. et al. ISMapper: identifying transposase insertion sites in bacterial genomes from short read sequence data . BMC Genomics 16, 667 (2015). Lighter Fast and memory-efficient sequencing error corrector Song, L., Florea, L. and B. Langmead, Lighter: Fast and Memory-efficient Sequencing Error Correction without Counting . Genome Biol. 2014 Nov 15;15(11):509. MAFFT Multiple alignment program for amino acid or nucleotide sequences Katoh, K. & Standley, D. M. MAFFT multiple sequence alignment software version 7: improvements in performance and usability. Mol. Biol. Evol. 30, 772\u2013780 (2013) Mash Fast genome and metagenome distance estimation using MinHash Ondov, B. D. et al. Mash: fast genome and metagenome distance estimation using MinHash . Genome Biol. 17, 132 (2016). Ondov, B. D. et al. Mash Screen: High-throughput sequence containment estimation for genome discovery . bioRxiv 557314 (2019). Mashtree Create a tree using Mash distances Katz, L. S., Griswold, T., Morrison, S., Caravas, J., Zhang, S., den Bakker, H.C., Deng, X., and Carleton, H. A. Mashtree: a rapid comparison of whole genome sequence files. Journal of Open Source Software, 4(44), 1762, (2019) maskrc-svg Masks recombination as detected by ClonalFrameML or Gubbins Kwong, J. maskrc-svg - Masks recombination as detected by ClonalFrameML or Gubbins and draws an SVG. McCortex De novo genome assembly and multisample variant calling Turner, I., Garimella, K. V., Iqbal, Z. and G. McVean, Integrating long-range connectivity information into de Bruijn graphs. Bioinformatics 34, 2556\u20132565 (2018). MEGAHIT Ultra-fast and memory-efficient (meta-)genome assembler Li, D., et al. MEGAHIT: an ultra-fast single-node solution for large and complex metagenomics assembly via succinct de Bruijn graph. Bioinformatics 31.10 (2015): 1674-1676. MinCED Mining CRISPRs in Environmental Datasets Skennerton, C. MinCED: Mining CRISPRs in Environmental Datasets Minimap2 A versatile pairwise aligner for genomic and spliced nucleotide sequences Li, H. Minimap2: pairwise alignment for nucleotide sequences. Bioinformatics, 34:3094-3100. (2018) ncbi-genome-download Scripts to download genomes from the NCBI FTP servers Blin, K. ncbi-genome-download: Scripts to download genomes from the NCBI FTP servers Nextflow A DSL for data-driven computational pipelines. Di Tommaso, P., Chatzou, M., Floden, E. W., Barja, P.P., Palumbo, E., Notredame, C., 2017. Nextflow enables reproducible computational workflows. Nat. Biotechnol. 35, 316\u2013319. nhmmer DNA homology search with profile HMMs. Wheeler, T. J. & Eddy, S. R. nhmmer: DNA homology search with profile HMMs. Bioinformatics 29, 2487\u20132489 (2013) phyloFlash A pipeline to rapidly reconstruct the SSU rRNAs and explore phylogenetic composition of an illumina (meta)genomic dataset. H. R. Gruber-Vodicka, B.KB. Seah, E. Pruesse. phyloFlash \u2014 Rapid SSU rRNA profiling and targeted assembly from metagenomes. bioRxiv 521922 Pigz A parallel implementation of gzip for modern multi-processor, multi-core machines. Adler, M. pigz: A parallel implementation of gzip for modern multi-processor, multi-core machines. Jet Propulsion Laboratory (2015). Pilon An automated genome assembly improvement and variant detection tool Walker, B. J., et al. Pilon: an integrated tool for comprehensive microbial variant detection and genome assembly improvement. PloS one 9.11 (2014): e112963. PIRATE A toolbox for pangenome analysis and threshold evaluation. S. C. Bayliss, H. A. Thorpe, N. M. Coyle, S. K. Sheppard, E. J. Feil PIRATE: A fast and scalable pangenomics toolbox for clustering diverged orthologues in bacteria. Gigascience. 8 (2019) pplacer Phylogenetic placement and downstream analysis Matsen, F. A., Kodner, R. B. & Armbrust, E. V. pplacer: linear time maximum-likelihood and Bayesian phylogenetic placement of sequences onto a fixed reference tree. BMC Bioinformatics 11, 538 (2010) Prodigal Fast, reliable protein-coding gene prediction for prokaryotic genomes. Hyatt, D., et al. Prodigal: prokaryotic gene recognition and translation initiation site identification. BMC Bioinformatics 11.1 (2010): 119. Prokka Rapid prokaryotic genome annotation Seemann, T. Prokka: rapid prokaryotic genome annotation . Bioinformatics 30, 2068\u20132069 (2014). QUAST Quality Assessment Tool for Genome A. Gurevich, V. Saveliev, N. Vyahhi, G. Tesler, QUAST: quality assessment tool for genome assemblies. Bioinformatics. 29, 1072\u20131075 (2013). Racon Ultrafast consensus module for raw de novo genome assembly of long uncorrected reads R. Vaser, I. Sovi\u0107, N. Nagarajan, M. \u0160iki\u0107, Fast and accurate de novo genome assembly from long uncorrected reads. Genome Res. 27, 737\u2013746 (2017). RNAmmer Consistent and rapid annotation of ribosomal RNA genes Lagesen, K., et al. RNAmmer: consistent annotation of rRNA genes in genomic sequences. Nucleic Acids Res 35.9: 3100-3108. (2007) Roary Rapid large-scale prokaryote pan genome analysis Page, A. J. et al. Roary: rapid large-scale prokaryote pan genome analysis. Bioinformatics 31, 3691\u20133693 (2015) samclip Filter SAM file for soft and hard clipped alignments Seemann, T. Samclip: Filter SAM file for soft and hard clipped alignments Samtools Tools for manipulating next-generation sequencing data Li, H. et al. The Sequence Alignment/Map format and SAMtools . Bioinformatics 25, 2078\u20132079 (2009). Seqtk A fast and lightweight tool for processing sequences in the FASTA or FASTQ format. Li, H. Toolkit for processing sequences in FASTA/Q formats Shovill Faster assembly of Illumina reads Seemann, T. Shovill: De novo assembly pipeline for Illumina paired reads SignalP Finds signal peptide features in CDS Petersen, T. N., et al. SignalP 4.0: discriminating signal peptides from transmembrane regions. Nature methods 8.10: 785.(2011) SKESA Strategic Kmer Extension for Scrupulous Assemblies Souvorov, A., Agarwala, R. and D. J. Lipman. SKESA: strategic k-mer extension for scrupulous assemblies. Genome Biology 19:153 (2018)._ Snippy Rapid haploid variant calling and core genome alignment Seemann, T. Snippy: fast bacterial variant calling from NGS reads (2015) SnpEff Genomic variant annotations and functional effect prediction toolbox. Cingolani, P., et al. A program for annotating and predicting the effects of single nucleotide polymorphisms, SnpEff: SNPs in the genome of Drosophila melanogaster strain w1118; iso-2; iso-3. Fly, 6(2), 80-92 (2012) snp-dists Pairwise SNP distance matrix from a FASTA sequence alignment Seemann, T. snp-dists - Pairwise SNP distance matrix from a FASTA sequence alignment. SNP-sites Rapidly extracts SNPs from a multi-FASTA alignment. Page, A. J., et al. SNP-sites: rapid efficient extraction of SNPs from multi-FASTA alignments. Microbial Genomics 2.4 (2016). Sourmash Compute and compare MinHash signatures for DNA data sets. Titus Brown, C. and L. Irber sourmash: a library for MinHash sketching of DNA . JOSS 1, 27 (2016). SPAdes An assembly toolkit containing various assembly pipelines. Bankevich, A., et al. SPAdes: a new genome assembly algorithm and its applications to single-cell sequencing. Journal of computational biology 19.5 (2012): 455-477. spaTyper Computational method for finding spa types. Harmsen D., Claus H., Witte W., Rothg\u00e4nger J., Claus H., Turnwald D., and Vogel U.. Typing of methicillin-resistant Staphylococcus aureus in a university hospital setting using a novel software for spa-repeat determination and database management. J. Clin. Microbiol. 41:5442-5448 (2003). Sanchez-Herrero J. F., and Sullivan M. (2020, October 2). spaTyper: Staphylococcal protein A (spa) characterization pipeline . Zenodo. staphopia-sccmec A standalone version of Staphopia's SCCmec typing method. Petit III R. A., Read T. D., Staphylococcus aureus viewed from the perspective of 40,000+ genomes. PeerJ 6, e5261 (2018). Trimmomatic A flexible read trimming tool for Illumina NGS data Bolger, A. M., Lohse, M., and B. Usadel. Trimmomatic: a flexible trimmer for Illumina sequence data. Bioinformatics 30.15 (2014): 2114-2120. Unicycler Hybrid assembly pipeline for bacterial genomes R. R. Wick, L. M. Judd, C. L. Gorrie, K. E. Holt, Unicycler: Resolving bacterial genome assemblies from short and long sequencing reads. PLoS Comput. Biol. 13, e1005595 (2017). VCF-Annotator Add biological annotations to variants in a VCF file. Petit III, R. A. VCF-Annotator: Add biological annotations to variants in a VCF file. . Vcflib a simple C++ library for parsing and manipulating VCF files Garrison, E. Vcflib: A C++ library for parsing and manipulating VCF files Velvet Short read de novo assembler using de Bruijn graphs Zerbino, D. R., and E. Birney. Velvet: algorithms for de novo short read assembly using de Bruijn graphs. Genome research 18.5 (2008): 821-829. VSEARCH Versatile open-source tool for metagenomics Rognes, T., Flouri, T., Nichols, B., Quince, C. & Mah\u00e9, F. VSEARCH: a versatile open source tool for metagenomics. PeerJ 4, e2584 (2016) vt A tool set for short variant discovery in genetic sequence data. Tan, A., Abecasis, G. R., and H. M. Kang, Unified representation of genetic variants. Bioinformatics, 31(13), 2202-2204. (2015)","title":"Software Included In Bactopia"},{"location":"changelog/","text":"Changelog \u00b6 v1.7.0 bactopia/bactopia \"Chocobo Wand\" - 2021/04/27 \u00b6 Added \u00b6 Bactopia Tool staph_typer for agr, spa, and sccmec typing --min_coverage parameter to filter based on min coverage 'Removed' \u00b6 plasmid_blast no longer apart of main workflow v1.6.5 bactopia/bactopia \"Z's Trident\" - 2021/03/30 \u00b6 Added \u00b6 version pins to process envs Fixed \u00b6 syntax for sourmash 4.0 v1.6.4 bactopia/bactopia \"Trident +1\" - 2021/03/26 \u00b6 Added \u00b6 added Python3.6+ to all environments v1.6.3 bactopia/bactopia \"Trident\" - 2021/03/25 \u00b6 Added \u00b6 extra fields to mlst-blast.py outputs added Python3 to qc_reads environment Fixed \u00b6 rstrip on empty extra fields in mlst profile different BLAST+ software versions mismatch tbb pinnings --help and --version for bactopia tools v1.6.2 bactopia/bactopia \"Fuscina\" - 2021/03/19 \u00b6 Added \u00b6 inputs are checked to be gzipped (this does not include FOFN) --skip_amr to skip AMRFinder+ analysis new bactopia tool for hicap unicycler can be used for Illumina reads only ( --assembler unicycler ) Fixed \u00b6 AMRFinder+ software and database version mismatch check-fastqs.py syntax errors with prints ismapper tool processing of include/exclude files v1.6.1 bactopia/bactopia \"Obelisk\" - 2021/02/22 \u00b6 Fixed \u00b6 sample names with \".\" in them breaking auto variant calling contig naming incompatible with GenBank v1.6.0 bactopia/bactopia \"Harpoon\" - 2021/01/22 \u00b6 Added \u00b6 bactopia pull to pre-build Singularity images --singularity_cache parameter to set location of image downloads --registry to choose Docker registry to use (DockerHub, GitHub, Quay) --max_downloads sets maximum number of downloads (FASTQ/assembly) allowed at once --min_time sets the minimum amount of time a job should be given bactopia search now uses POST requests, and groups accessions into single query strip HTML from FASTA headers used in BLAST Dockerfiles now have conda.md5 label to determine if rebuild is necessary MD5 is updated in Dockerfile when env is updated AMRFinder+ database is now provided by bactopia datasets Parameterized profile (slurm, awsbatch, etc...) variables bactopia build will retry in case of HTTP connection issues --include_tool will build Bactopia Tool environments GitHub Actions build Docker containers on new release (or manual trigger) test that the Conda environment yamls are still valid test bactopia with conda on Linux and OSX test bactopia on Linux with Docker and Singularity Fixed \u00b6 redundant environment version files failed FASTQ/Assembly downloads no longer stop whole run --max_retry is honored now antimicrobial_resistance process honors amrdir variable change directory antimicrobial_resistance to antimicrobial-resistance rename check_staging.py to check-staging.py for consistency Bactopia not producing valid exit code on failure Removed \u00b6 --containerPath variable is replaced by --singularity_cache Native Singularity recipes, will now convert Docker to Singularity docs are now on bactopia.github.io repo v1.5.6 bactopia/bactopia \"Metal Slime Earring\" - 2021/01/13 \u00b6 Added \u00b6 tweaks to the CI (via GitHub Actions) docker containers use quay.io now docker containers now use conda-pack --nfconfig will skip the conda environment build step input accessions are checked to be Assembly or Experiment accessions improved version increment script executor profiles can be configured by parameters Fixed \u00b6 phyloflash and download_reference environment errors environment path in Bactopia Tools Dockerfile and Singularity recipes moved version from conda yaml to conda version file streamlined Docker recipes undefined --ftp_only message typo in singularity profile stderr logged to file is also printed to screen qc_reads memory used now determined by base config v1.5.5 bactopia/bactopia \"Avenger's Earring\" - 2021/01/04 \u00b6 Added \u00b6 --prefix option for bactopia prepare date is included in bactopia summary output Fixed \u00b6 removed usage personal (rpetit3) conda channel aspera connect no longer supported shovill-se is now used from Bioconda updated conda environments (phyloflash broken) v1.5.4 bactopia/bactopia \"Nemesis Earring\" - 2020/12/17 \u00b6 Fixed \u00b6 quoted arguments being broken up (e.g. --species \"Staphylococcus aureus -> --species Staphylococcus ) mashtree tool failure to download with --accessions remove ncbi-genome-download header when using --dry-run undefined name variable in plasmid_blast custom work dir causing two -w parameters bactopia search results now contains all (illumina and non-illumina) v1.5.3 bactopia/bactopia \"Morion Earring\" - 2020/12/04 \u00b6 Added \u00b6 Changelog moved to docs recursive search for bactopia prepare allow multiple FASTQs per sample (FASTQs are merged) Fixed \u00b6 unable to run bactopia datasets without parameters PLSDB blast results in invalid JSON format Error message for unaccepted run_type v1.5.2 bactopia/bactopia \"Physical Earring\" - 2020/11/18 \u00b6 Fixed \u00b6 --skip_qc causing \"file not found\" qc_reads not honoring FINAL_BP and FINAL_READS checks v1.5.1 bactopia/bactopia \"Astral Earring\" - 2020/11/17 \u00b6 Fixed \u00b6 bactopia tools not a valid project name bactopia tools --cleanup_workdir unrecognized variable v1.5.0 bactopia/bactopia \"Cassie Earring\" - 2020/11/12 \u00b6 Added \u00b6 Conda environments will check if in sync with latest version now md5sums of all conda envs Verify species-specific datasets exist separate work dir for bactopia and bactopia tools --cleanup_workdir to delete work directory after successful run default values for bactopia datasets summary.json Fallback to NCBI Assembly when eUtils is down Additional pre-process QC checks OSX/Linux conda envs for Bactopia Tools Documentation edits and updates Bactopia and Nextflow versions are now output for logging purposes option to skip QC step ( --skip_qc ) bactopia datasets can now specify assembly level bactopia tools now use reusable conda envs bactopia tools for Roary and PIRATE can now include local assemblies Fixed \u00b6 Warn user if no completed genomes are available use of --genera for ncbi-genome-download improved genome_size handling explicit file passing for AWS Batch Memory estimates now floored PLSDB blast not being executed v1.4.11 bactopia/bactopia \"Metamorph Ring\" - 2020/09/19 \u00b6 Added \u00b6 bactopia build checks if each environment is built before building Can specify bactopia build to build a specific environment Removed build numbers in Conda environment yamls Created separate Conda yamls for Linux and Mac NCBI assembly accessions will retrieve the most current version (e.g. .1, .2, .3, etc...) Fixed \u00b6 bactopia datasets trailing whitespace in species names bactopia datasets random subsample missing specified species when --limit and --include_genus used GitLab CI OSX compatibility Adaptive resource allocations Datasets are checked for existence Variant calls against references with multiple chromosomes v1.4.10 bactopia/bactopia \"Jelly Ring\" - 2020/08/25 \u00b6 Added \u00b6 card is back as a default Ariba dataset Added timestamps to versions files Fixed \u00b6 bactopia search not creating --outdir gtdb tool not using prefix in outdir naming pirate tool using pangenome alignment instead of core Use of scratch causing logs to fail v1.4.9 bactopia/bactopia \"Toreador's Ring\" - 2020/08/23 \u00b6 Added \u00b6 Support for multiple accession bactopia search (SRA) Bactopia Tools: fastani , mashtree , pirate , roary (Assembly) Fixed \u00b6 Undefined variable in mapping_query.sh ENA API endpoint for bactopia search Updated GTDB-TK to 1.3.0 to support latest downloads FastANI tool merge_results in no longer a separate step ANI is now one-to-many calculations --reassemble misapplied v1.4.8 bactopia/bactopia \"Shikaree Ring\" - 2020/08/20 \u00b6 Added \u00b6 Versions are logged for Bactopia STDOUT/STDERR logs are kept for each sample can be skipped using --skip_logs Fixed \u00b6 Long sample names breaking Prokka annotation Syntax errors in Bactopia tools null values being tested as integers Ariba card and mlst downloads not working missing parameter in GTDB Bactopia tool v1.4.7 bactopia/bactopia \"Serket Ring\" - 2020/08/17 \u00b6 Added \u00b6 --no_cache to skip caching ncbi assembly info v1.4.6 bactopia/bactopia \"Astral Ring\" - 2020/08/17 \u00b6 Added \u00b6 Option to rebuild conda envs to default location Updated fastq-dl for sra-toolkit forced interaction workaround v1.4.5 bactopia/bactopia \"Bomb Queen Ring\" - 2020/08/13 \u00b6 Fixed \u00b6 --min_basepairs and --min_reads not being honored v1.4.4 bactopia/bactopia \"Vilma's Ring\" - 2020/08/13 \u00b6 Fixed \u00b6 annotate_genome name clashes Updated fastq-dl version to support new ENA API endpoint v1.4.3 bactopia/bactopia \"Sattva Ring\" - 2020/08/13 \u00b6 Added \u00b6 --skip_ariba option in bactopia datasets Fixed \u00b6 bactopia versions and bactopia citations improper execution Convert spaces to tabs in citation doc Corrected CheckM name in program version info file CARD no longer default Ariba dataset download for bactopia datasets v1.4.2 bactopia/bactopia \"Tamas Ring\" - 2020/08/10 \u00b6 Added \u00b6 added requirement checks of --accessions in bactopia datasets improved ENA spell check for species name Fixed \u00b6 file of accessions not working with bactopia datasets Dockerfile and Singularity being missed by update-version.sh v1.4.1 bactopia/bactopia \"Rajas Ring\" - 2020/08/06 \u00b6 Added \u00b6 Links to publication (woohoo!) Can pass a Prodigal training file to bactopia datasets Fixed \u00b6 Typos in the Docs blast_primers now uses blastn and blast_genes uses megablast validExitStatus deprecation warning v1.4.0 bactopia/bactopia \"Archer's Ring\" - 2020/07/01 \u00b6 Added \u00b6 New Bactopia Tools eggnog for functional annotation using eggNOG-mapper mashtree to create a tree using Mash distances pirate to create pangenome using PIRATE ismapper for insertion site discovery Documentation for new tools and tweaks to existing BTs roary and pirate can now be run on just completed genomes Can limit number of completed genomes downloaded where applicable bactopia datasets can provide list of RefSeq accessions to download bactopia search can now use BioSample and Run accessions bactopia search can select a subset of Experiments associated with a BioSample Support for organisms with multiple MLST schemas Assembly QC via QUAST and CheckM Assemblies (local or NCBI Assembly accession) as inputs for Bactopia Long reads as supplementary to paired end reads for hybrid assembly Tools versions are locked to the minor version, not the patch Fixed \u00b6 summary will now determine absolute path of inputs fastani improved user reference import went back a version on call_variants openjdk version all bactopia tools now put nextflow info in the same folder as outputs Typos in docs Bactopia Tools now check existence of include and exclude files Lots more documentation Updated citations/tools used by Bactopia Did I mention typos? Removed \u00b6 ISMapper as part of the main pipeline (its now a tool) insertion-sequences in bactopia datasets v1.3.1 bactopia/bactopia \"Emperor Hairpin\" - 2020/04/20 \u00b6 Added \u00b6 summary tool now gives reason for rank summary tools now splits failed into exclude and qc-failure Better documentation on how --cpus works in Nextflow Efficiency info when executed on standard profile split blast_query into blast_genes , blast_primers and blast_proteins mapping_query now creates multifasta of fastas at maps at once then splits per-base coverage into separate files --nfconfig users can provide their own Nextflow config file fastani users can provide their own reference now bactopia versions will print versions for tools used by Bactopia bactopia citations will print citations for tools and datasets used by Bactopia bactopia search can filter based on total bases, mean read length, and missing FASTQs blast queries results are only JSON format for easy parsing later added --compliant option for Prokka annotation Fixed \u00b6 build-containers.sh not working with Bactopia Tools Bactopia Tools container tools missing environment.yml Typo in fastani usage Samples with multiple QC errors counted for each error Incorrect ISMapper version typo in summary SLURM profile gtdb Singularity container not mounting path to GTDB database roary missing rename in containers blast_query results overwriting one another build-containers.sh now creates a \"latest\" tag bactopia tool roary outputs results based on the given prefix renamed --addgenes to --nogenes updated ASA\u00b3P citation Typos in Bactopia Tools docs Link in README.md v1.3.0 bactopia/bactopia \"Leaping Boots\" - 2020/02/19 \u00b6 Added \u00b6 bactopia tools (BT) framework docs for each tool subcommand to execute tools bactopia tools fastani - pairwise average nucleotide identity gtdb - assigning objective taxonomic classifications phyloflash - 16s assembly, alignment and tree roary - pan-genome and core genome tree summary - summary of results --include and --exclude to modify which samples used in BT analysis update-version.sh improvements can now set how Nextflow publishes outputs (copy, symlink, etc...) via --publish_mode Warning if output directory already exists and require --force to overwrite option ( --rfam ) to turn on ncRNA annotation in Prokka reduced \"README.md\" contents, instead point to documentation Updated acknowledgements and bibtex for citations Fixed \u00b6 nextflow.config version out of sync --available_datasets accessing not existent variable --available_datasets is tested before requiring inputs Make use of tbl2asn-forever adjusted how Bactopia is executed, nextflow run no longer pulls from github v1.2.4 bactopia/bactopia \"Rabbit Charm\" - 2019/12/20 \u00b6 Added \u00b6 --conda_help to be used for conda build test --skip_fastq_check to skip check that input FASTQs meet minimum requirements Undocumented parameters to the usage Fixed \u00b6 snippy not working with samtools 1.10 NXF_HOME variable is exported to the conda env location speed of checking if conda environments are built v1.2.3 bactopia/bactopia \"Tropical Punches +1\" - 2019/12/19 \u00b6 Added \u00b6 select-references selects latest assembly accession version (BioPython/Entrez) select-references skips assemblies that have been excluded from RefSeq test to for paired-end related errors (e.g. different read counts) --min_genome_size and --max_genome_size parameter for estimated genome sizes Check is also made after assembly update-version.sh improvements Better genome size estimates using Mash for high and low coverage sequences Script to update conda environments added --conda_help to be used for conda build test Fixed \u00b6 --random_tie_break always true not using latest assembly accession for ncbi-genome-download usage of assemblies that have been excluded from RefSeq allowing PE reads with different read counts to be processed (hint... they fail pretty quickly) failure to stop analysis of sample with low read counts coverage reported as 'inf' references to cgmlst in the setup datasets non-explicit patterns in publishDir low coverage/read errors after QC were not put in root dir snippy not working with samtools 1.10 v1.2.2 bactopia/bactopia \"Tropical Punches\" - 2019/10/22 \u00b6 Added \u00b6 Size of \"work\" directory to the execution summary User controlled overwrites of existing output files Check for unknown parameters at runtime FASTQ downloads from SRA (via fastq-dl and fasterq-dump) Documentation updates Script for building containers Fixed \u00b6 bactopia command now explicitly states which tag to use for Nextflow run Version info not updated in Dockerfile and Singularity Duplicated QC'd FASTQs nextflow: docker \"Memory limited without swap\" error Removed \u00b6 cgmlst support in bactopia datasets setup.py left over from pre-conda config v1.2.1 bactopia/bactopia \"Fruit Punches\" - 2019/10/17 \u00b6 Added \u00b6 bactopia build to build Conda environments Version info pulled from nextflow.config Set default values resource allocations Documentation on new changes Automatic building of Conda environments, if none exist --nfdir to determine where bactopia is being run from Fixed \u00b6 Never ending typos --datasets now, not --dataset <-(Typo) path for outputting Nextflow reports Typo in antimicrobial_resistance.sh (task.cpus not cpus) --species is now consistent between bactopia and bactopia datasets Bug when checking if specific species dataset exists, but no species datasets exist Cleaned up version update script Cleaned up usage Removed \u00b6 --max_cpus ability to limit total cores used, access to config is being deprecated in Nextflow --max_cpus since it is redudant to --cpus now v1.2.0 bactopia/bactopia \"Beestinger\" - 2019/10/16 \u00b6 Added \u00b6 --compress to compress certain outputs, default uncompressed Species name check in bactopia datasets Use requests package instead of urllib3 Added bactopia search to query ENA for list of Illumina accessions Documentation Feedback edits Output overview Additional program acknowledgements bibtex of citations missing parameters to usage info for --genome_size parameter bactopia search usage Workflow overview blastdbcmd compatible seqid to assembly fasta allows search for entries with sample name Mask low coverage regions in consensus (subs only) fasta Added --dry_run to build conda envs one at a time (prevent parallel issues) Added Singularity recipes Added SLURM config Fixed \u00b6 Never ending typos bactopia datasets lowercase species names not found in MLST schemas bactopia version no longer calls nextflow SEQUENCE_TYPE channel groups FASTQ and assembly MINMER_QUERY channel groups FASTQ and signature Ariba MLST always running with --noclean Bugs related --compress Reduced size of per-base coverage outputs Removed -parse_seqids from makeblastdb command, caused blast queries to fail genomeCoverageBed failing on empty BAM files Removed \u00b6 --clean_cache function v1.1.0 bactopia/bactopia \"Wooden Sword +1\" - 2019/09/19 \u00b6 Added \u00b6 NCBI's amrfinder Dockerfile for main bactopia install Completed documentation! Fixed \u00b6 insertion_sequences inputs are not now grouped into single channel Unintended FASTQ duplication via poor publishDir pattern v1.0.1 bactopia/bactopia \"Wooden Sword\" - 2019/09/12 \u00b6 Added \u00b6 README.md documentation Fixed \u00b6 call_variants_auto bug fixed documentation version numbers v1.0.0 bactopia/bactopia \"Wooden Sword\" - 2019/09/04 \u00b6 Initial release of bactopia/bactopia","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#v170-bactopiabactopia-chocobo-wand-20210427","text":"","title":"v1.7.0 bactopia/bactopia \"Chocobo Wand\" - 2021/04/27"},{"location":"changelog/#added","text":"Bactopia Tool staph_typer for agr, spa, and sccmec typing --min_coverage parameter to filter based on min coverage","title":"Added"},{"location":"changelog/#removed","text":"plasmid_blast no longer apart of main workflow","title":"'Removed'"},{"location":"changelog/#v165-bactopiabactopia-zs-trident-20210330","text":"","title":"v1.6.5 bactopia/bactopia \"Z's Trident\" - 2021/03/30"},{"location":"changelog/#added_1","text":"version pins to process envs","title":"Added"},{"location":"changelog/#fixed","text":"syntax for sourmash 4.0","title":"Fixed"},{"location":"changelog/#v164-bactopiabactopia-trident-1-20210326","text":"","title":"v1.6.4 bactopia/bactopia \"Trident +1\" - 2021/03/26"},{"location":"changelog/#added_2","text":"added Python3.6+ to all environments","title":"Added"},{"location":"changelog/#v163-bactopiabactopia-trident-20210325","text":"","title":"v1.6.3 bactopia/bactopia \"Trident\" - 2021/03/25"},{"location":"changelog/#added_3","text":"extra fields to mlst-blast.py outputs added Python3 to qc_reads environment","title":"Added"},{"location":"changelog/#fixed_1","text":"rstrip on empty extra fields in mlst profile different BLAST+ software versions mismatch tbb pinnings --help and --version for bactopia tools","title":"Fixed"},{"location":"changelog/#v162-bactopiabactopia-fuscina-20210319","text":"","title":"v1.6.2 bactopia/bactopia \"Fuscina\" - 2021/03/19"},{"location":"changelog/#added_4","text":"inputs are checked to be gzipped (this does not include FOFN) --skip_amr to skip AMRFinder+ analysis new bactopia tool for hicap unicycler can be used for Illumina reads only ( --assembler unicycler )","title":"Added"},{"location":"changelog/#fixed_2","text":"AMRFinder+ software and database version mismatch check-fastqs.py syntax errors with prints ismapper tool processing of include/exclude files","title":"Fixed"},{"location":"changelog/#v161-bactopiabactopia-obelisk-20210222","text":"","title":"v1.6.1 bactopia/bactopia \"Obelisk\" - 2021/02/22"},{"location":"changelog/#fixed_3","text":"sample names with \".\" in them breaking auto variant calling contig naming incompatible with GenBank","title":"Fixed"},{"location":"changelog/#v160-bactopiabactopia-harpoon-20210122","text":"","title":"v1.6.0 bactopia/bactopia \"Harpoon\" - 2021/01/22"},{"location":"changelog/#added_5","text":"bactopia pull to pre-build Singularity images --singularity_cache parameter to set location of image downloads --registry to choose Docker registry to use (DockerHub, GitHub, Quay) --max_downloads sets maximum number of downloads (FASTQ/assembly) allowed at once --min_time sets the minimum amount of time a job should be given bactopia search now uses POST requests, and groups accessions into single query strip HTML from FASTA headers used in BLAST Dockerfiles now have conda.md5 label to determine if rebuild is necessary MD5 is updated in Dockerfile when env is updated AMRFinder+ database is now provided by bactopia datasets Parameterized profile (slurm, awsbatch, etc...) variables bactopia build will retry in case of HTTP connection issues --include_tool will build Bactopia Tool environments GitHub Actions build Docker containers on new release (or manual trigger) test that the Conda environment yamls are still valid test bactopia with conda on Linux and OSX test bactopia on Linux with Docker and Singularity","title":"Added"},{"location":"changelog/#fixed_4","text":"redundant environment version files failed FASTQ/Assembly downloads no longer stop whole run --max_retry is honored now antimicrobial_resistance process honors amrdir variable change directory antimicrobial_resistance to antimicrobial-resistance rename check_staging.py to check-staging.py for consistency Bactopia not producing valid exit code on failure","title":"Fixed"},{"location":"changelog/#removed_1","text":"--containerPath variable is replaced by --singularity_cache Native Singularity recipes, will now convert Docker to Singularity docs are now on bactopia.github.io repo","title":"Removed"},{"location":"changelog/#v156-bactopiabactopia-metal-slime-earring-20210113","text":"","title":"v1.5.6 bactopia/bactopia \"Metal Slime Earring\" - 2021/01/13"},{"location":"changelog/#added_6","text":"tweaks to the CI (via GitHub Actions) docker containers use quay.io now docker containers now use conda-pack --nfconfig will skip the conda environment build step input accessions are checked to be Assembly or Experiment accessions improved version increment script executor profiles can be configured by parameters","title":"Added"},{"location":"changelog/#fixed_5","text":"phyloflash and download_reference environment errors environment path in Bactopia Tools Dockerfile and Singularity recipes moved version from conda yaml to conda version file streamlined Docker recipes undefined --ftp_only message typo in singularity profile stderr logged to file is also printed to screen qc_reads memory used now determined by base config","title":"Fixed"},{"location":"changelog/#v155-bactopiabactopia-avengers-earring-20210104","text":"","title":"v1.5.5 bactopia/bactopia \"Avenger's Earring\" - 2021/01/04"},{"location":"changelog/#added_7","text":"--prefix option for bactopia prepare date is included in bactopia summary output","title":"Added"},{"location":"changelog/#fixed_6","text":"removed usage personal (rpetit3) conda channel aspera connect no longer supported shovill-se is now used from Bioconda updated conda environments (phyloflash broken)","title":"Fixed"},{"location":"changelog/#v154-bactopiabactopia-nemesis-earring-20201217","text":"","title":"v1.5.4 bactopia/bactopia \"Nemesis Earring\" - 2020/12/17"},{"location":"changelog/#fixed_7","text":"quoted arguments being broken up (e.g. --species \"Staphylococcus aureus -> --species Staphylococcus ) mashtree tool failure to download with --accessions remove ncbi-genome-download header when using --dry-run undefined name variable in plasmid_blast custom work dir causing two -w parameters bactopia search results now contains all (illumina and non-illumina)","title":"Fixed"},{"location":"changelog/#v153-bactopiabactopia-morion-earring-20201204","text":"","title":"v1.5.3 bactopia/bactopia \"Morion Earring\" - 2020/12/04"},{"location":"changelog/#added_8","text":"Changelog moved to docs recursive search for bactopia prepare allow multiple FASTQs per sample (FASTQs are merged)","title":"Added"},{"location":"changelog/#fixed_8","text":"unable to run bactopia datasets without parameters PLSDB blast results in invalid JSON format Error message for unaccepted run_type","title":"Fixed"},{"location":"changelog/#v152-bactopiabactopia-physical-earring-20201118","text":"","title":"v1.5.2 bactopia/bactopia \"Physical Earring\" - 2020/11/18"},{"location":"changelog/#fixed_9","text":"--skip_qc causing \"file not found\" qc_reads not honoring FINAL_BP and FINAL_READS checks","title":"Fixed"},{"location":"changelog/#v151-bactopiabactopia-astral-earring-20201117","text":"","title":"v1.5.1 bactopia/bactopia \"Astral Earring\" - 2020/11/17"},{"location":"changelog/#fixed_10","text":"bactopia tools not a valid project name bactopia tools --cleanup_workdir unrecognized variable","title":"Fixed"},{"location":"changelog/#v150-bactopiabactopia-cassie-earring-20201112","text":"","title":"v1.5.0 bactopia/bactopia \"Cassie Earring\" - 2020/11/12"},{"location":"changelog/#added_9","text":"Conda environments will check if in sync with latest version now md5sums of all conda envs Verify species-specific datasets exist separate work dir for bactopia and bactopia tools --cleanup_workdir to delete work directory after successful run default values for bactopia datasets summary.json Fallback to NCBI Assembly when eUtils is down Additional pre-process QC checks OSX/Linux conda envs for Bactopia Tools Documentation edits and updates Bactopia and Nextflow versions are now output for logging purposes option to skip QC step ( --skip_qc ) bactopia datasets can now specify assembly level bactopia tools now use reusable conda envs bactopia tools for Roary and PIRATE can now include local assemblies","title":"Added"},{"location":"changelog/#fixed_11","text":"Warn user if no completed genomes are available use of --genera for ncbi-genome-download improved genome_size handling explicit file passing for AWS Batch Memory estimates now floored PLSDB blast not being executed","title":"Fixed"},{"location":"changelog/#v1411-bactopiabactopia-metamorph-ring-20200919","text":"","title":"v1.4.11 bactopia/bactopia \"Metamorph Ring\" - 2020/09/19"},{"location":"changelog/#added_10","text":"bactopia build checks if each environment is built before building Can specify bactopia build to build a specific environment Removed build numbers in Conda environment yamls Created separate Conda yamls for Linux and Mac NCBI assembly accessions will retrieve the most current version (e.g. .1, .2, .3, etc...)","title":"Added"},{"location":"changelog/#fixed_12","text":"bactopia datasets trailing whitespace in species names bactopia datasets random subsample missing specified species when --limit and --include_genus used GitLab CI OSX compatibility Adaptive resource allocations Datasets are checked for existence Variant calls against references with multiple chromosomes","title":"Fixed"},{"location":"changelog/#v1410-bactopiabactopia-jelly-ring-20200825","text":"","title":"v1.4.10 bactopia/bactopia \"Jelly Ring\" - 2020/08/25"},{"location":"changelog/#added_11","text":"card is back as a default Ariba dataset Added timestamps to versions files","title":"Added"},{"location":"changelog/#fixed_13","text":"bactopia search not creating --outdir gtdb tool not using prefix in outdir naming pirate tool using pangenome alignment instead of core Use of scratch causing logs to fail","title":"Fixed"},{"location":"changelog/#v149-bactopiabactopia-toreadors-ring-20200823","text":"","title":"v1.4.9 bactopia/bactopia \"Toreador's Ring\" - 2020/08/23"},{"location":"changelog/#added_12","text":"Support for multiple accession bactopia search (SRA) Bactopia Tools: fastani , mashtree , pirate , roary (Assembly)","title":"Added"},{"location":"changelog/#fixed_14","text":"Undefined variable in mapping_query.sh ENA API endpoint for bactopia search Updated GTDB-TK to 1.3.0 to support latest downloads FastANI tool merge_results in no longer a separate step ANI is now one-to-many calculations --reassemble misapplied","title":"Fixed"},{"location":"changelog/#v148-bactopiabactopia-shikaree-ring-20200820","text":"","title":"v1.4.8 bactopia/bactopia \"Shikaree Ring\" - 2020/08/20"},{"location":"changelog/#added_13","text":"Versions are logged for Bactopia STDOUT/STDERR logs are kept for each sample can be skipped using --skip_logs","title":"Added"},{"location":"changelog/#fixed_15","text":"Long sample names breaking Prokka annotation Syntax errors in Bactopia tools null values being tested as integers Ariba card and mlst downloads not working missing parameter in GTDB Bactopia tool","title":"Fixed"},{"location":"changelog/#v147-bactopiabactopia-serket-ring-20200817","text":"","title":"v1.4.7 bactopia/bactopia \"Serket Ring\" - 2020/08/17"},{"location":"changelog/#added_14","text":"--no_cache to skip caching ncbi assembly info","title":"Added"},{"location":"changelog/#v146-bactopiabactopia-astral-ring-20200817","text":"","title":"v1.4.6 bactopia/bactopia \"Astral Ring\" - 2020/08/17"},{"location":"changelog/#added_15","text":"Option to rebuild conda envs to default location Updated fastq-dl for sra-toolkit forced interaction workaround","title":"Added"},{"location":"changelog/#v145-bactopiabactopia-bomb-queen-ring-20200813","text":"","title":"v1.4.5 bactopia/bactopia \"Bomb Queen Ring\" - 2020/08/13"},{"location":"changelog/#fixed_16","text":"--min_basepairs and --min_reads not being honored","title":"Fixed"},{"location":"changelog/#v144-bactopiabactopia-vilmas-ring-20200813","text":"","title":"v1.4.4 bactopia/bactopia \"Vilma's Ring\" - 2020/08/13"},{"location":"changelog/#fixed_17","text":"annotate_genome name clashes Updated fastq-dl version to support new ENA API endpoint","title":"Fixed"},{"location":"changelog/#v143-bactopiabactopia-sattva-ring-20200813","text":"","title":"v1.4.3 bactopia/bactopia \"Sattva Ring\" - 2020/08/13"},{"location":"changelog/#added_16","text":"--skip_ariba option in bactopia datasets","title":"Added"},{"location":"changelog/#fixed_18","text":"bactopia versions and bactopia citations improper execution Convert spaces to tabs in citation doc Corrected CheckM name in program version info file CARD no longer default Ariba dataset download for bactopia datasets","title":"Fixed"},{"location":"changelog/#v142-bactopiabactopia-tamas-ring-20200810","text":"","title":"v1.4.2 bactopia/bactopia \"Tamas Ring\" - 2020/08/10"},{"location":"changelog/#added_17","text":"added requirement checks of --accessions in bactopia datasets improved ENA spell check for species name","title":"Added"},{"location":"changelog/#fixed_19","text":"file of accessions not working with bactopia datasets Dockerfile and Singularity being missed by update-version.sh","title":"Fixed"},{"location":"changelog/#v141-bactopiabactopia-rajas-ring-20200806","text":"","title":"v1.4.1 bactopia/bactopia \"Rajas Ring\" - 2020/08/06"},{"location":"changelog/#added_18","text":"Links to publication (woohoo!) Can pass a Prodigal training file to bactopia datasets","title":"Added"},{"location":"changelog/#fixed_20","text":"Typos in the Docs blast_primers now uses blastn and blast_genes uses megablast validExitStatus deprecation warning","title":"Fixed"},{"location":"changelog/#v140-bactopiabactopia-archers-ring-20200701","text":"","title":"v1.4.0 bactopia/bactopia \"Archer's Ring\" - 2020/07/01"},{"location":"changelog/#added_19","text":"New Bactopia Tools eggnog for functional annotation using eggNOG-mapper mashtree to create a tree using Mash distances pirate to create pangenome using PIRATE ismapper for insertion site discovery Documentation for new tools and tweaks to existing BTs roary and pirate can now be run on just completed genomes Can limit number of completed genomes downloaded where applicable bactopia datasets can provide list of RefSeq accessions to download bactopia search can now use BioSample and Run accessions bactopia search can select a subset of Experiments associated with a BioSample Support for organisms with multiple MLST schemas Assembly QC via QUAST and CheckM Assemblies (local or NCBI Assembly accession) as inputs for Bactopia Long reads as supplementary to paired end reads for hybrid assembly Tools versions are locked to the minor version, not the patch","title":"Added"},{"location":"changelog/#fixed_21","text":"summary will now determine absolute path of inputs fastani improved user reference import went back a version on call_variants openjdk version all bactopia tools now put nextflow info in the same folder as outputs Typos in docs Bactopia Tools now check existence of include and exclude files Lots more documentation Updated citations/tools used by Bactopia Did I mention typos?","title":"Fixed"},{"location":"changelog/#removed_2","text":"ISMapper as part of the main pipeline (its now a tool) insertion-sequences in bactopia datasets","title":"Removed"},{"location":"changelog/#v131-bactopiabactopia-emperor-hairpin-20200420","text":"","title":"v1.3.1 bactopia/bactopia \"Emperor Hairpin\" - 2020/04/20"},{"location":"changelog/#added_20","text":"summary tool now gives reason for rank summary tools now splits failed into exclude and qc-failure Better documentation on how --cpus works in Nextflow Efficiency info when executed on standard profile split blast_query into blast_genes , blast_primers and blast_proteins mapping_query now creates multifasta of fastas at maps at once then splits per-base coverage into separate files --nfconfig users can provide their own Nextflow config file fastani users can provide their own reference now bactopia versions will print versions for tools used by Bactopia bactopia citations will print citations for tools and datasets used by Bactopia bactopia search can filter based on total bases, mean read length, and missing FASTQs blast queries results are only JSON format for easy parsing later added --compliant option for Prokka annotation","title":"Added"},{"location":"changelog/#fixed_22","text":"build-containers.sh not working with Bactopia Tools Bactopia Tools container tools missing environment.yml Typo in fastani usage Samples with multiple QC errors counted for each error Incorrect ISMapper version typo in summary SLURM profile gtdb Singularity container not mounting path to GTDB database roary missing rename in containers blast_query results overwriting one another build-containers.sh now creates a \"latest\" tag bactopia tool roary outputs results based on the given prefix renamed --addgenes to --nogenes updated ASA\u00b3P citation Typos in Bactopia Tools docs Link in README.md","title":"Fixed"},{"location":"changelog/#v130-bactopiabactopia-leaping-boots-20200219","text":"","title":"v1.3.0 bactopia/bactopia \"Leaping Boots\" - 2020/02/19"},{"location":"changelog/#added_21","text":"bactopia tools (BT) framework docs for each tool subcommand to execute tools bactopia tools fastani - pairwise average nucleotide identity gtdb - assigning objective taxonomic classifications phyloflash - 16s assembly, alignment and tree roary - pan-genome and core genome tree summary - summary of results --include and --exclude to modify which samples used in BT analysis update-version.sh improvements can now set how Nextflow publishes outputs (copy, symlink, etc...) via --publish_mode Warning if output directory already exists and require --force to overwrite option ( --rfam ) to turn on ncRNA annotation in Prokka reduced \"README.md\" contents, instead point to documentation Updated acknowledgements and bibtex for citations","title":"Added"},{"location":"changelog/#fixed_23","text":"nextflow.config version out of sync --available_datasets accessing not existent variable --available_datasets is tested before requiring inputs Make use of tbl2asn-forever adjusted how Bactopia is executed, nextflow run no longer pulls from github","title":"Fixed"},{"location":"changelog/#v124-bactopiabactopia-rabbit-charm-20191220","text":"","title":"v1.2.4 bactopia/bactopia \"Rabbit Charm\" - 2019/12/20"},{"location":"changelog/#added_22","text":"--conda_help to be used for conda build test --skip_fastq_check to skip check that input FASTQs meet minimum requirements Undocumented parameters to the usage","title":"Added"},{"location":"changelog/#fixed_24","text":"snippy not working with samtools 1.10 NXF_HOME variable is exported to the conda env location speed of checking if conda environments are built","title":"Fixed"},{"location":"changelog/#v123-bactopiabactopia-tropical-punches-1-20191219","text":"","title":"v1.2.3 bactopia/bactopia \"Tropical Punches +1\" - 2019/12/19"},{"location":"changelog/#added_23","text":"select-references selects latest assembly accession version (BioPython/Entrez) select-references skips assemblies that have been excluded from RefSeq test to for paired-end related errors (e.g. different read counts) --min_genome_size and --max_genome_size parameter for estimated genome sizes Check is also made after assembly update-version.sh improvements Better genome size estimates using Mash for high and low coverage sequences Script to update conda environments added --conda_help to be used for conda build test","title":"Added"},{"location":"changelog/#fixed_25","text":"--random_tie_break always true not using latest assembly accession for ncbi-genome-download usage of assemblies that have been excluded from RefSeq allowing PE reads with different read counts to be processed (hint... they fail pretty quickly) failure to stop analysis of sample with low read counts coverage reported as 'inf' references to cgmlst in the setup datasets non-explicit patterns in publishDir low coverage/read errors after QC were not put in root dir snippy not working with samtools 1.10","title":"Fixed"},{"location":"changelog/#v122-bactopiabactopia-tropical-punches-20191022","text":"","title":"v1.2.2 bactopia/bactopia \"Tropical Punches\" - 2019/10/22"},{"location":"changelog/#added_24","text":"Size of \"work\" directory to the execution summary User controlled overwrites of existing output files Check for unknown parameters at runtime FASTQ downloads from SRA (via fastq-dl and fasterq-dump) Documentation updates Script for building containers","title":"Added"},{"location":"changelog/#fixed_26","text":"bactopia command now explicitly states which tag to use for Nextflow run Version info not updated in Dockerfile and Singularity Duplicated QC'd FASTQs nextflow: docker \"Memory limited without swap\" error","title":"Fixed"},{"location":"changelog/#removed_3","text":"cgmlst support in bactopia datasets setup.py left over from pre-conda config","title":"Removed"},{"location":"changelog/#v121-bactopiabactopia-fruit-punches-20191017","text":"","title":"v1.2.1 bactopia/bactopia \"Fruit Punches\" - 2019/10/17"},{"location":"changelog/#added_25","text":"bactopia build to build Conda environments Version info pulled from nextflow.config Set default values resource allocations Documentation on new changes Automatic building of Conda environments, if none exist --nfdir to determine where bactopia is being run from","title":"Added"},{"location":"changelog/#fixed_27","text":"Never ending typos --datasets now, not --dataset <-(Typo) path for outputting Nextflow reports Typo in antimicrobial_resistance.sh (task.cpus not cpus) --species is now consistent between bactopia and bactopia datasets Bug when checking if specific species dataset exists, but no species datasets exist Cleaned up version update script Cleaned up usage","title":"Fixed"},{"location":"changelog/#removed_4","text":"--max_cpus ability to limit total cores used, access to config is being deprecated in Nextflow --max_cpus since it is redudant to --cpus now","title":"Removed"},{"location":"changelog/#v120-bactopiabactopia-beestinger-20191016","text":"","title":"v1.2.0 bactopia/bactopia \"Beestinger\" - 2019/10/16"},{"location":"changelog/#added_26","text":"--compress to compress certain outputs, default uncompressed Species name check in bactopia datasets Use requests package instead of urllib3 Added bactopia search to query ENA for list of Illumina accessions Documentation Feedback edits Output overview Additional program acknowledgements bibtex of citations missing parameters to usage info for --genome_size parameter bactopia search usage Workflow overview blastdbcmd compatible seqid to assembly fasta allows search for entries with sample name Mask low coverage regions in consensus (subs only) fasta Added --dry_run to build conda envs one at a time (prevent parallel issues) Added Singularity recipes Added SLURM config","title":"Added"},{"location":"changelog/#fixed_28","text":"Never ending typos bactopia datasets lowercase species names not found in MLST schemas bactopia version no longer calls nextflow SEQUENCE_TYPE channel groups FASTQ and assembly MINMER_QUERY channel groups FASTQ and signature Ariba MLST always running with --noclean Bugs related --compress Reduced size of per-base coverage outputs Removed -parse_seqids from makeblastdb command, caused blast queries to fail genomeCoverageBed failing on empty BAM files","title":"Fixed"},{"location":"changelog/#removed_5","text":"--clean_cache function","title":"Removed"},{"location":"changelog/#v110-bactopiabactopia-wooden-sword-1-20190919","text":"","title":"v1.1.0 bactopia/bactopia \"Wooden Sword +1\" - 2019/09/19"},{"location":"changelog/#added_27","text":"NCBI's amrfinder Dockerfile for main bactopia install Completed documentation!","title":"Added"},{"location":"changelog/#fixed_29","text":"insertion_sequences inputs are not now grouped into single channel Unintended FASTQ duplication via poor publishDir pattern","title":"Fixed"},{"location":"changelog/#v101-bactopiabactopia-wooden-sword-20190912","text":"","title":"v1.0.1 bactopia/bactopia \"Wooden Sword\" - 2019/09/12"},{"location":"changelog/#added_28","text":"README.md documentation","title":"Added"},{"location":"changelog/#fixed_30","text":"call_variants_auto bug fixed documentation version numbers","title":"Fixed"},{"location":"changelog/#v100-bactopiabactopia-wooden-sword-20190904","text":"Initial release of bactopia/bactopia","title":"v1.0.0 bactopia/bactopia \"Wooden Sword\" - 2019/09/04"},{"location":"datasets/","text":"Build Datasets \u00b6 Bactopia can make use of many existing public datasets, as well as private datasets. The process of downloading, building, and (or) configuring these datasets for Bactopia has been automated. Highly recommended to complete this step! This step is completely optional, but it is highly recommended that you do not. By skipping this step of setting up public datasets, Bactopia will be limited to analyses like quality control, assembly, and 31-mer counting. Included Datasets \u00b6 Some datasets included are applicable to all bacterial species and some are specific to a bacterial species. If specified at runtime, Bactopia will recognize the datasets and execute the appropriate analyses. General \u00b6 Ariba's getref Reference Datasets Allows reference datasets (resistance, virulence, and plamids) to be automatically downloaded and configured for usage by Ariba RefSeq Mash Sketch ~100,000 genomes and plasmids from NCBI RefSeq, used to give an idea of what is your sequencing data (e.g. Are the sequences what you expected?) GenBank Sourmash Signatures ~87,000 microbial genomes (includes viral and fungal) from NCBI GenBank, also gives an idea of what is your sequencing data. PLSDB Mash Sketch & BLAST Includes meta data/annotations, Mash sketches, and BLAST database files of all plasmids stored in PLSDB. Species Specific \u00b6 PubMLST.org MLST Schemas Multi-locus sequence typing (MLST) allelic profiles and seqeunces for a many different bacterial species (and even a few eukaryotes!). Clustered RefSeq Proteins For the given bacterial species, completed RefSeq genomes are downloaded and then the proteins are clustered and formatted for usage with Prokka. Minmer Sketch of RefSeq Genomes Using the completed genomes downloaded for clustering proteins a Mash sketch and Sourmash signature is created for these genomes. These sketches can then be used for automatic selection of reference genomes for variant calling. Optional User Populated Folders A few folders for things such as calling variants, insertion sequences and primers are created that the user can manually populate. More information is available below! Setting Up \u00b6 Included in Bactopia is the setup-datasets.py script (located in the bin folder) to automate the process of downloading and/or building these datasets. Quick Start \u00b6 bactopia datasets This will set up Ariba datasets ( card and vfdb_core ), RefSeq Mash sketch, GenBank Sourmash Signatures, and PLSDB in the newly created datasets folder. By default, datasets is used for the output directory, but this can be changed with --outdir . A Single Bacterial Species \u00b6 bactopia datasets --species \"Haemophilus influenzae\" --include_genus Multiple Bacterial Species \u00b6 You can also set up datasets for multiple bacterial species at a time. There are two options to do so. Comma-Separated \u00b6 At runtime, you can separate the the different species bactopia datasets --species \"Haemophilus influenzae,Staphylococcus aureus\" --include_genus Text File \u00b6 In order to do so, you will need to create a text file where each line is the name of a species to set up. For example, you could create a species.txt file and include the following species in it. Haemophilus influenzae Staphylococcus aureus Mycobacterium tuberculosis The new command becomes: bactopia datasets --species species.txt --include_genus This will setup the MLST schema (if available) and a protein cluster FASTA file for each species in species.txt . Usage \u00b6 bactopia datasets [-h] [--outdir STR] [--skip_ariba] [--ariba STR] [--species STR] [--skip_mlst] [--skip_prokka] [--include_genus] [--assembly_level {all,complete,chromosome,scaffold,contig}] [--limit INT] [--accessions STR] [--identity FLOAT] [--overlap FLOAT] [--max_memory INT] [--fast_cluster] [--skip_minmer] [--skip_plsdb] [--prodigal_tf STR] [--reference STR] [--mapping STR] [--genes STR] [--proteins STR] [--primers STR] [--force_optional] [--cpus INT] [--clear_cache] [--force] [--force_ariba] [--force_mlst] [--force_prokka] [--force_minmer] [--force_plsdb] [--keep_files] [--available_datasets] [--depends] [--version] [--verbose] [--silent] bactopia datasets - Setup public datasets for Bactopia optional arguments: -h, --help show this help message and exit --outdir STR Directory to write output. (Default ./datasets) Ariba Reference Datasets: --skip_ariba Skip setup of Ariba datasets --ariba STR Comma separated list of Ariba datasets to download and setup. Available datasets include: argannot, card, ncbi, megares, plasmidfinder, resfinder, srst2_argannot, vfdb_core, vfdb_full, virulencefinder (Default: \"vfdb_core,card\") Use --available_datasets to see the full list. Bacterial Species: --species STR Download available MLST schemas and completed genomes for a given species or a list of species in a text file. --skip_mlst Skip setup of MLST schemas for each species Custom Prokka Protein FASTA: --skip_prokka Skip creation of a Prokka formatted fasta for each species --include_genus Include all genus members in the Prokka proteins FASTA --assembly_level {all,complete,chromosome,scaffold,contig} Assembly levels of genomes to download (Default: complete). --limit INT If available completed genomes exceeds a given limit, a random subsample will be taken. (Default 1000) --accessions STR A list of RefSeq accessions to download. --identity FLOAT CD-HIT (-c) sequence identity threshold. (Default: 0.9) --overlap FLOAT CD-HIT (-s) length difference cutoff. (Default: 0.8) --max_memory INT CD-HIT (-M) memory limit (in MB). (Default: unlimited --fast_cluster Use CD-HIT's (-g 0) fast clustering algorithm, instead of the accurate but slow algorithm. Minmer Datasets: --skip_minmer Skip download of pre-computed minmer datasets (mash, sourmash) PLSDB (Plasmid) BLAST/Sketch: --skip_plsdb Skip download of pre-computed PLSDB datbases (blast, mash) Optional User Provided Datasets: --prodigal_tf STR A pre-built Prodigal training file to add to the species annotation folder. Requires a single species (--species) and will replace existing training files. --reference STR A reference genome (FASTA/GenBank (preferred)) file or directory to be added to the optional folder for variant calling. Requires a single species (--species). --mapping STR A reference sequence (FASTA) file or directory to be added to the optional folder for mapping. Requires a single species (--species). --genes STR A gene sequence (FASTA) file or directory to be added to the optional folder for BLAST. Requires a single species (--species). --proteins STR A protein sequence (FASTA) file or directory to be added to the optional folder for BLAST. Requires a single species (--species). --primers STR A primer sequence (FASTA) file or directory to be added to the optional folder for BLAST. Requires a single species (--species). --force_optional Overwrite any existing files in the optional folders Custom Options: --cpus INT Number of cpus to use. (Default: 1) --clear_cache Remove any existing cache. --force Forcibly overwrite existing datasets. --force_ariba Forcibly overwrite existing Ariba datasets. --force_mlst Forcibly overwrite existing MLST datasets. --force_prokka Forcibly overwrite existing Prokka datasets. --force_minmer Forcibly overwrite existing minmer datasets. --force_plsdb Forcibly overwrite existing PLSDB datasets. --keep_files Keep all downloaded and intermediate files. --available_datasets List Ariba reference datasets and MLST schemas available for setup. --depends Verify dependencies are installed. Adjust Verbosity: --version show program's version number and exit --verbose Print debug related text. --silent Only critical errors will be printed. example usage: bactopia datasets bactopia datasets --ariba 'vfdb_core' bactopia datasets --species 'Staphylococcus aureus' --include_genus Useful Parameters \u00b6 --clear_cache \u00b6 To prevent a PubMLST.org query every run, a list of available schemas is cached to $HOME/.bactopia/datasets.json . The cache expires after 15 days, but in case a new species has been made available --clear_cache will force a query of PubMLST.org. --cpus \u00b6 Increasing --cpus (it defaults to 1) is useful for speeding up the download and clustering steps. --force* \u00b6 If a dataset exists, it will only be overwritten if one of the --force parameters are used. --include_genus \u00b6 Completed RefSeq genomes are downloaded for a given species to be used for protein clustering. --include_genus will also download completed RefSeq genomes for each genus member. --assembly_level \u00b6 By default, only completed genomes are downloaded. --assembly_level allows you to set the minimum assembly level (e.g. complete, scaffold, contigs, etc...) to download. --limit \u00b6 For some species of bacteria there might be thousands of completed genomes available. For dataset creation, downloading thousands of completed genomes will be time consuming and like take up a significant amount of storage. To help in such cases --limit can be used to limit the downloads to a random subset of genomes. The default value for --limit has been set to 1000 genomes. In cases where --include_genus is used, the random subsample will always include at least one genome from the given --species value. --accessions \u00b6 In cases where a random subset of completed genomes is not ideal, you can provide your own curated list of genomes to download with --accessions . The file should have a single NCBI RefSeq Assembly accession (E.g GCF_000008865) per line. --keep_files \u00b6 Many intermediate files are downloaded/created (e.g. completed genomes) and deleted during the building process, use --keep_files to retain these files. Tweaking CD-HIT \u00b6 There are parameters ( --identity , --overlap , --max_memory , and --fast_cluster ) to tweak CD-HIT if you find it necessary. Please keep in mind, the only goal of the protein clustering step is to help speed up Prokka, by providing a decent set of proteins to annotate against first. Datasets Folder Overview \u00b6 After creating datasets you will have a directory structure that Bactopia recognizes. Based on the available datasets Bactopia will queue up the associated analyses. Here is the directory structure for the Bactopia Datasets. Some of these include files from public datasets that can be used directly, but there are also other folders you can populate yourself to fit your needs. ${DATASET_FOLDER} \u251c\u2500\u2500 ariba \u251c\u2500\u2500 minmer \u251c\u2500\u2500 plasmid \u2514\u2500\u2500 species-specific \u2514\u2500\u2500 ${SPECIES} \u251c\u2500\u2500 annotation \u2502 \u251c\u2500\u2500 cdhit-stats.txt \u2502 \u251c\u2500\u2500 genome_size.json \u2502 \u251c\u2500\u2500 ncbi-metadata.txt \u2502 \u251c\u2500\u2500 proteins.faa \u2502 \u251c\u2500\u2500 proteins.faa.clstr \u2502 \u2514\u2500\u2500 proteins-updated.txt \u251c\u2500\u2500 minmer \u2502 \u251c\u2500\u2500 minmer-updated.txt \u2502 \u2514\u2500\u2500 refseq-genomes.msh \u251c\u2500\u2500 mlst \u2502 \u2514\u2500\u2500 ${SCHEMA} \u2502 \u251c\u2500\u2500 ariba.tar.gz \u2502 \u251c\u2500\u2500 blastdb.tar.gz \u2502 \u2514\u2500\u2500 mlst-updated.txt \u2514\u2500\u2500 optional \u251c\u2500\u2500 blast \u2502 \u251c\u2500\u2500 genes \u2502 \u2502 \u2514\u2500\u2500 ${NAME}.fasta \u2502 \u251c\u2500\u2500 primers \u2502 \u2502 \u2514\u2500\u2500 ${NAME}.fasta \u2502 \u2514\u2500\u2500 proteins \u2502 \u2514\u2500\u2500 ${NAME}.fasta \u251c\u2500\u2500 insertion-sequences \u2502 \u2514\u2500\u2500 ${NAME}.fasta \u251c\u2500\u2500 mapping-sequences \u2502 \u2514\u2500\u2500 ${NAME}.fasta \u2514\u2500\u2500 reference-genomes \u2514\u2500\u2500 ${NAME}.{gbk|fasta} General Datasets \u00b6 General datasets can be used for all bacterial samples. There are three general dataset folders: ariba , minmer and plasmid . The ariba folder contains pre-formatted datasets available from Ariba's getref Reference Datasets . The minmer folder contains a RefSeq Mash Sketch and GenBank Sourmash Signatures of more than 100,000 genomes. Finally, the plasmid folder contains a PLSDB Mash Sketch & BLAST database from a curated set of plasmids. Changing files in ariba , minmer and plasmid is not recommended These directories are for general analysis and have been precomputed. Modifying these files may cause errors during analysis. Species Specific Datasets \u00b6 Bactopia allows the datasets to be created for a specific species. The following sections outline the species specific datasets. annotation \u00b6 Completed RefSeq genomes are downloaded and then the proteins are clustered and formatted for usage with Prokka. The results from this clustering is stored in the annotation folder. ${DATASET_FOLDER} \u2514\u2500\u2500 species-specific \u2514\u2500\u2500 ${SPECIES} \u2514\u2500\u2500 annotation \u251c\u2500\u2500 cdhit-stats.txt \u251c\u2500\u2500 genome_size.json \u251c\u2500\u2500 ncbi-metadata.txt \u251c\u2500\u2500 prodigal.tf \u251c\u2500\u2500 proteins.faa \u251c\u2500\u2500 proteins.faa.clstr \u2514\u2500\u2500 proteins-updated.txt Filename Description cdhit-stats.txt General statistics associated with CD-HIT clustering genome_size.json A list of genome size for each downloaded RefSeq genome ncbi-metadata.txt NCBI Assembly metadata associated with the downloaded RefSeq genomes prodigal.tf A pre-built species specific Prodigal training file provided with --prodigal_tf proteins.faa Set of Prokka formatted proteins proteins.faa.clstr Description of the clusters created by CD-HIT proteins-updated.txt Information on the last time the protein set was updated You can add your curated protein set here If you have a set of proteins you would like to use for annotation, you can name it proteins.faa and place it in the annotation folder. In order for your set of proteins to be used by Prokka, you must make sure you follow the Prokka FASTA database format . An alternative is to use the --accessions parameter and give bactopia datasets the list of RefSeq accessions when the dataset is created. In doing so the custom protein set will be automatically formatted using the genomes you specified. minmer \u00b6 By default, a Mash sketch is created for the completed genomes downloaded for clustering proteins. These sketches are then be used for automatic selection of reference genomes for variant calling. ${DATASET_FOLDER} \u2514\u2500\u2500 species-specific \u2514\u2500\u2500 ${SPECIES} \u2514\u2500\u2500 minmer \u251c\u2500\u2500 minmer-updated.txt \u2514\u2500\u2500 refseq-genomes.msh Filename Description minmer-updated.txt Information on the last time the mash sketch was updated refseq-genomes.msh A Mash sketch (k=31) of the RefSeq completed genomes You can add your curated RefSeq sketch here You can replace refseq-genomes.msh with a custom set of RefSeq genomes to be used for automatic reference selection. The only requirements to do so are that only RefSeq genomes (start with GCF) are used and the mash sketch uses a k-mer length of 31 ( -k 31 ). This will allow it to be compatible with Bactopia. An alternative is to use the --accessions parameter and give bactopia datasets the list of RefSeq accessions when the dataset is created. In doing so the mash sketch will be automatically created. mlst \u00b6 The mlst folder contains MLST schemas that have been formatted to be used by Ariba and BLAST . ${DATASET_FOLDER} \u2514\u2500\u2500 species-specific \u2514\u2500\u2500 ${SPECIES} \u2514\u2500\u2500 mlst \u2514\u2500\u2500 ${SCHEMA} \u251c\u2500\u2500 ariba.tar.gz \u251c\u2500\u2500 blastdb.tar.gz \u2514\u2500\u2500 mlst-updated.txt Filename Description ariba.tar.gz An Ariba formatted MLST dataset for a given schema blastdb.tar.gz A BLAST formatted MLST dataset for a given schema mlst-updated.txt Contains time stamp for the last time the MSLT dataset was updated How does Bactopia handle organisms with multiple MLST schemas? In a few cases, an organism might have multiple MLST schemas available (Example: E. coli ). In such cases, each MLST schema is downloaded and set up. Bactopia will also call sequence types against each schema. Changing files in mlst is not recommended The MLST schemas have been pre-formatted for your usage. There might be rare cases where you would like to provide your own schema. If this is the case it is recommended you take a look at: What about MLST not hosted at pubmlst.org? then follow the directory structure for mlst . optional \u00b6 Built into the Bactopia dataset structure is the optional folder that you, the user, can populate for species specific analysis. These could include specific genes you might want BLASTed against your samples or a specific reference you want all your samples mapped to and variants called. blast \u00b6 ${DATASET_FOLDER} \u2514\u2500\u2500 species-specific \u2514\u2500\u2500 ${SPECIES} \u2514\u2500\u2500 optional \u2514\u2500\u2500 blast \u251c\u2500\u2500 genes \u2502 \u2514\u2500\u2500 ${NAME}.fasta \u251c\u2500\u2500 primers \u2502 \u2514\u2500\u2500 ${NAME}.fasta \u2514\u2500\u2500 proteins \u2514\u2500\u2500 ${NAME}.fasta In the blast directory there are three more directories! The genes folder is where you can place gene seqeunces (nucleotides) in FASTA format to query against assemblies using blastn . The primers folder is where you can place primer sequences (nucleotides) in FASTA format to query against assemblies using blastn , but with primer-specific parameters and cut-offs. Finally, the proteins (as you probably guessed!) is where you can place protein sequnces (amino acids) in FASTA format to query against assemblies using blastp . mapping-sequences \u00b6 ${DATASET_FOLDER} \u2514\u2500\u2500 species-specific \u2514\u2500\u2500 ${SPECIES} \u2514\u2500\u2500 optional \u2514\u2500\u2500 mapping-sequences \u2514\u2500\u2500 ${NAME}.fasta In the mapping-sequences directory you can place FASTA files of any nucleotide sequence you would like FASTQ reads to be mapped against using BWA . This can be useful if you are interested if whether a certain region or gene is covered or not. reference-genomes \u00b6 ${DATASET_FOLDER} \u2514\u2500\u2500 species-specific \u2514\u2500\u2500 ${SPECIES} \u2514\u2500\u2500 optional \u2514\u2500\u2500 reference-genomes \u2514\u2500\u2500 ${NAME}.{gbk|fasta} In the reference-genomes directory you can put a GenBank (preferred!) or FASTA file of a reference genome you would like variants to be called against using Snippy .","title":"Build Datasets"},{"location":"datasets/#build-datasets","text":"Bactopia can make use of many existing public datasets, as well as private datasets. The process of downloading, building, and (or) configuring these datasets for Bactopia has been automated. Highly recommended to complete this step! This step is completely optional, but it is highly recommended that you do not. By skipping this step of setting up public datasets, Bactopia will be limited to analyses like quality control, assembly, and 31-mer counting.","title":"Build Datasets"},{"location":"datasets/#included-datasets","text":"Some datasets included are applicable to all bacterial species and some are specific to a bacterial species. If specified at runtime, Bactopia will recognize the datasets and execute the appropriate analyses.","title":"Included Datasets"},{"location":"datasets/#general","text":"Ariba's getref Reference Datasets Allows reference datasets (resistance, virulence, and plamids) to be automatically downloaded and configured for usage by Ariba RefSeq Mash Sketch ~100,000 genomes and plasmids from NCBI RefSeq, used to give an idea of what is your sequencing data (e.g. Are the sequences what you expected?) GenBank Sourmash Signatures ~87,000 microbial genomes (includes viral and fungal) from NCBI GenBank, also gives an idea of what is your sequencing data. PLSDB Mash Sketch & BLAST Includes meta data/annotations, Mash sketches, and BLAST database files of all plasmids stored in PLSDB.","title":"General"},{"location":"datasets/#species-specific","text":"PubMLST.org MLST Schemas Multi-locus sequence typing (MLST) allelic profiles and seqeunces for a many different bacterial species (and even a few eukaryotes!). Clustered RefSeq Proteins For the given bacterial species, completed RefSeq genomes are downloaded and then the proteins are clustered and formatted for usage with Prokka. Minmer Sketch of RefSeq Genomes Using the completed genomes downloaded for clustering proteins a Mash sketch and Sourmash signature is created for these genomes. These sketches can then be used for automatic selection of reference genomes for variant calling. Optional User Populated Folders A few folders for things such as calling variants, insertion sequences and primers are created that the user can manually populate. More information is available below!","title":"Species Specific"},{"location":"datasets/#setting-up","text":"Included in Bactopia is the setup-datasets.py script (located in the bin folder) to automate the process of downloading and/or building these datasets.","title":"Setting Up"},{"location":"datasets/#quick-start","text":"bactopia datasets This will set up Ariba datasets ( card and vfdb_core ), RefSeq Mash sketch, GenBank Sourmash Signatures, and PLSDB in the newly created datasets folder. By default, datasets is used for the output directory, but this can be changed with --outdir .","title":"Quick Start"},{"location":"datasets/#a-single-bacterial-species","text":"bactopia datasets --species \"Haemophilus influenzae\" --include_genus","title":"A Single Bacterial Species"},{"location":"datasets/#multiple-bacterial-species","text":"You can also set up datasets for multiple bacterial species at a time. There are two options to do so.","title":"Multiple Bacterial Species"},{"location":"datasets/#comma-separated","text":"At runtime, you can separate the the different species bactopia datasets --species \"Haemophilus influenzae,Staphylococcus aureus\" --include_genus","title":"Comma-Separated"},{"location":"datasets/#text-file","text":"In order to do so, you will need to create a text file where each line is the name of a species to set up. For example, you could create a species.txt file and include the following species in it. Haemophilus influenzae Staphylococcus aureus Mycobacterium tuberculosis The new command becomes: bactopia datasets --species species.txt --include_genus This will setup the MLST schema (if available) and a protein cluster FASTA file for each species in species.txt .","title":"Text File"},{"location":"datasets/#usage","text":"bactopia datasets [-h] [--outdir STR] [--skip_ariba] [--ariba STR] [--species STR] [--skip_mlst] [--skip_prokka] [--include_genus] [--assembly_level {all,complete,chromosome,scaffold,contig}] [--limit INT] [--accessions STR] [--identity FLOAT] [--overlap FLOAT] [--max_memory INT] [--fast_cluster] [--skip_minmer] [--skip_plsdb] [--prodigal_tf STR] [--reference STR] [--mapping STR] [--genes STR] [--proteins STR] [--primers STR] [--force_optional] [--cpus INT] [--clear_cache] [--force] [--force_ariba] [--force_mlst] [--force_prokka] [--force_minmer] [--force_plsdb] [--keep_files] [--available_datasets] [--depends] [--version] [--verbose] [--silent] bactopia datasets - Setup public datasets for Bactopia optional arguments: -h, --help show this help message and exit --outdir STR Directory to write output. (Default ./datasets) Ariba Reference Datasets: --skip_ariba Skip setup of Ariba datasets --ariba STR Comma separated list of Ariba datasets to download and setup. Available datasets include: argannot, card, ncbi, megares, plasmidfinder, resfinder, srst2_argannot, vfdb_core, vfdb_full, virulencefinder (Default: \"vfdb_core,card\") Use --available_datasets to see the full list. Bacterial Species: --species STR Download available MLST schemas and completed genomes for a given species or a list of species in a text file. --skip_mlst Skip setup of MLST schemas for each species Custom Prokka Protein FASTA: --skip_prokka Skip creation of a Prokka formatted fasta for each species --include_genus Include all genus members in the Prokka proteins FASTA --assembly_level {all,complete,chromosome,scaffold,contig} Assembly levels of genomes to download (Default: complete). --limit INT If available completed genomes exceeds a given limit, a random subsample will be taken. (Default 1000) --accessions STR A list of RefSeq accessions to download. --identity FLOAT CD-HIT (-c) sequence identity threshold. (Default: 0.9) --overlap FLOAT CD-HIT (-s) length difference cutoff. (Default: 0.8) --max_memory INT CD-HIT (-M) memory limit (in MB). (Default: unlimited --fast_cluster Use CD-HIT's (-g 0) fast clustering algorithm, instead of the accurate but slow algorithm. Minmer Datasets: --skip_minmer Skip download of pre-computed minmer datasets (mash, sourmash) PLSDB (Plasmid) BLAST/Sketch: --skip_plsdb Skip download of pre-computed PLSDB datbases (blast, mash) Optional User Provided Datasets: --prodigal_tf STR A pre-built Prodigal training file to add to the species annotation folder. Requires a single species (--species) and will replace existing training files. --reference STR A reference genome (FASTA/GenBank (preferred)) file or directory to be added to the optional folder for variant calling. Requires a single species (--species). --mapping STR A reference sequence (FASTA) file or directory to be added to the optional folder for mapping. Requires a single species (--species). --genes STR A gene sequence (FASTA) file or directory to be added to the optional folder for BLAST. Requires a single species (--species). --proteins STR A protein sequence (FASTA) file or directory to be added to the optional folder for BLAST. Requires a single species (--species). --primers STR A primer sequence (FASTA) file or directory to be added to the optional folder for BLAST. Requires a single species (--species). --force_optional Overwrite any existing files in the optional folders Custom Options: --cpus INT Number of cpus to use. (Default: 1) --clear_cache Remove any existing cache. --force Forcibly overwrite existing datasets. --force_ariba Forcibly overwrite existing Ariba datasets. --force_mlst Forcibly overwrite existing MLST datasets. --force_prokka Forcibly overwrite existing Prokka datasets. --force_minmer Forcibly overwrite existing minmer datasets. --force_plsdb Forcibly overwrite existing PLSDB datasets. --keep_files Keep all downloaded and intermediate files. --available_datasets List Ariba reference datasets and MLST schemas available for setup. --depends Verify dependencies are installed. Adjust Verbosity: --version show program's version number and exit --verbose Print debug related text. --silent Only critical errors will be printed. example usage: bactopia datasets bactopia datasets --ariba 'vfdb_core' bactopia datasets --species 'Staphylococcus aureus' --include_genus","title":"Usage"},{"location":"datasets/#useful-parameters","text":"","title":"Useful Parameters"},{"location":"datasets/#-clear_cache","text":"To prevent a PubMLST.org query every run, a list of available schemas is cached to $HOME/.bactopia/datasets.json . The cache expires after 15 days, but in case a new species has been made available --clear_cache will force a query of PubMLST.org.","title":"--clear_cache"},{"location":"datasets/#-cpus","text":"Increasing --cpus (it defaults to 1) is useful for speeding up the download and clustering steps.","title":"--cpus"},{"location":"datasets/#-force","text":"If a dataset exists, it will only be overwritten if one of the --force parameters are used.","title":"--force*"},{"location":"datasets/#-include_genus","text":"Completed RefSeq genomes are downloaded for a given species to be used for protein clustering. --include_genus will also download completed RefSeq genomes for each genus member.","title":"--include_genus"},{"location":"datasets/#-assembly_level","text":"By default, only completed genomes are downloaded. --assembly_level allows you to set the minimum assembly level (e.g. complete, scaffold, contigs, etc...) to download.","title":"--assembly_level"},{"location":"datasets/#-limit","text":"For some species of bacteria there might be thousands of completed genomes available. For dataset creation, downloading thousands of completed genomes will be time consuming and like take up a significant amount of storage. To help in such cases --limit can be used to limit the downloads to a random subset of genomes. The default value for --limit has been set to 1000 genomes. In cases where --include_genus is used, the random subsample will always include at least one genome from the given --species value.","title":"--limit"},{"location":"datasets/#-accessions","text":"In cases where a random subset of completed genomes is not ideal, you can provide your own curated list of genomes to download with --accessions . The file should have a single NCBI RefSeq Assembly accession (E.g GCF_000008865) per line.","title":"--accessions"},{"location":"datasets/#-keep_files","text":"Many intermediate files are downloaded/created (e.g. completed genomes) and deleted during the building process, use --keep_files to retain these files.","title":"--keep_files"},{"location":"datasets/#tweaking-cd-hit","text":"There are parameters ( --identity , --overlap , --max_memory , and --fast_cluster ) to tweak CD-HIT if you find it necessary. Please keep in mind, the only goal of the protein clustering step is to help speed up Prokka, by providing a decent set of proteins to annotate against first.","title":"Tweaking CD-HIT"},{"location":"datasets/#datasets-folder-overview","text":"After creating datasets you will have a directory structure that Bactopia recognizes. Based on the available datasets Bactopia will queue up the associated analyses. Here is the directory structure for the Bactopia Datasets. Some of these include files from public datasets that can be used directly, but there are also other folders you can populate yourself to fit your needs. ${DATASET_FOLDER} \u251c\u2500\u2500 ariba \u251c\u2500\u2500 minmer \u251c\u2500\u2500 plasmid \u2514\u2500\u2500 species-specific \u2514\u2500\u2500 ${SPECIES} \u251c\u2500\u2500 annotation \u2502 \u251c\u2500\u2500 cdhit-stats.txt \u2502 \u251c\u2500\u2500 genome_size.json \u2502 \u251c\u2500\u2500 ncbi-metadata.txt \u2502 \u251c\u2500\u2500 proteins.faa \u2502 \u251c\u2500\u2500 proteins.faa.clstr \u2502 \u2514\u2500\u2500 proteins-updated.txt \u251c\u2500\u2500 minmer \u2502 \u251c\u2500\u2500 minmer-updated.txt \u2502 \u2514\u2500\u2500 refseq-genomes.msh \u251c\u2500\u2500 mlst \u2502 \u2514\u2500\u2500 ${SCHEMA} \u2502 \u251c\u2500\u2500 ariba.tar.gz \u2502 \u251c\u2500\u2500 blastdb.tar.gz \u2502 \u2514\u2500\u2500 mlst-updated.txt \u2514\u2500\u2500 optional \u251c\u2500\u2500 blast \u2502 \u251c\u2500\u2500 genes \u2502 \u2502 \u2514\u2500\u2500 ${NAME}.fasta \u2502 \u251c\u2500\u2500 primers \u2502 \u2502 \u2514\u2500\u2500 ${NAME}.fasta \u2502 \u2514\u2500\u2500 proteins \u2502 \u2514\u2500\u2500 ${NAME}.fasta \u251c\u2500\u2500 insertion-sequences \u2502 \u2514\u2500\u2500 ${NAME}.fasta \u251c\u2500\u2500 mapping-sequences \u2502 \u2514\u2500\u2500 ${NAME}.fasta \u2514\u2500\u2500 reference-genomes \u2514\u2500\u2500 ${NAME}.{gbk|fasta}","title":"Datasets Folder Overview"},{"location":"datasets/#general-datasets","text":"General datasets can be used for all bacterial samples. There are three general dataset folders: ariba , minmer and plasmid . The ariba folder contains pre-formatted datasets available from Ariba's getref Reference Datasets . The minmer folder contains a RefSeq Mash Sketch and GenBank Sourmash Signatures of more than 100,000 genomes. Finally, the plasmid folder contains a PLSDB Mash Sketch & BLAST database from a curated set of plasmids. Changing files in ariba , minmer and plasmid is not recommended These directories are for general analysis and have been precomputed. Modifying these files may cause errors during analysis.","title":"General Datasets"},{"location":"datasets/#species-specific-datasets","text":"Bactopia allows the datasets to be created for a specific species. The following sections outline the species specific datasets.","title":"Species Specific Datasets"},{"location":"datasets/#annotation","text":"Completed RefSeq genomes are downloaded and then the proteins are clustered and formatted for usage with Prokka. The results from this clustering is stored in the annotation folder. ${DATASET_FOLDER} \u2514\u2500\u2500 species-specific \u2514\u2500\u2500 ${SPECIES} \u2514\u2500\u2500 annotation \u251c\u2500\u2500 cdhit-stats.txt \u251c\u2500\u2500 genome_size.json \u251c\u2500\u2500 ncbi-metadata.txt \u251c\u2500\u2500 prodigal.tf \u251c\u2500\u2500 proteins.faa \u251c\u2500\u2500 proteins.faa.clstr \u2514\u2500\u2500 proteins-updated.txt Filename Description cdhit-stats.txt General statistics associated with CD-HIT clustering genome_size.json A list of genome size for each downloaded RefSeq genome ncbi-metadata.txt NCBI Assembly metadata associated with the downloaded RefSeq genomes prodigal.tf A pre-built species specific Prodigal training file provided with --prodigal_tf proteins.faa Set of Prokka formatted proteins proteins.faa.clstr Description of the clusters created by CD-HIT proteins-updated.txt Information on the last time the protein set was updated You can add your curated protein set here If you have a set of proteins you would like to use for annotation, you can name it proteins.faa and place it in the annotation folder. In order for your set of proteins to be used by Prokka, you must make sure you follow the Prokka FASTA database format . An alternative is to use the --accessions parameter and give bactopia datasets the list of RefSeq accessions when the dataset is created. In doing so the custom protein set will be automatically formatted using the genomes you specified.","title":"annotation"},{"location":"datasets/#minmer","text":"By default, a Mash sketch is created for the completed genomes downloaded for clustering proteins. These sketches are then be used for automatic selection of reference genomes for variant calling. ${DATASET_FOLDER} \u2514\u2500\u2500 species-specific \u2514\u2500\u2500 ${SPECIES} \u2514\u2500\u2500 minmer \u251c\u2500\u2500 minmer-updated.txt \u2514\u2500\u2500 refseq-genomes.msh Filename Description minmer-updated.txt Information on the last time the mash sketch was updated refseq-genomes.msh A Mash sketch (k=31) of the RefSeq completed genomes You can add your curated RefSeq sketch here You can replace refseq-genomes.msh with a custom set of RefSeq genomes to be used for automatic reference selection. The only requirements to do so are that only RefSeq genomes (start with GCF) are used and the mash sketch uses a k-mer length of 31 ( -k 31 ). This will allow it to be compatible with Bactopia. An alternative is to use the --accessions parameter and give bactopia datasets the list of RefSeq accessions when the dataset is created. In doing so the mash sketch will be automatically created.","title":"minmer"},{"location":"datasets/#mlst","text":"The mlst folder contains MLST schemas that have been formatted to be used by Ariba and BLAST . ${DATASET_FOLDER} \u2514\u2500\u2500 species-specific \u2514\u2500\u2500 ${SPECIES} \u2514\u2500\u2500 mlst \u2514\u2500\u2500 ${SCHEMA} \u251c\u2500\u2500 ariba.tar.gz \u251c\u2500\u2500 blastdb.tar.gz \u2514\u2500\u2500 mlst-updated.txt Filename Description ariba.tar.gz An Ariba formatted MLST dataset for a given schema blastdb.tar.gz A BLAST formatted MLST dataset for a given schema mlst-updated.txt Contains time stamp for the last time the MSLT dataset was updated How does Bactopia handle organisms with multiple MLST schemas? In a few cases, an organism might have multiple MLST schemas available (Example: E. coli ). In such cases, each MLST schema is downloaded and set up. Bactopia will also call sequence types against each schema. Changing files in mlst is not recommended The MLST schemas have been pre-formatted for your usage. There might be rare cases where you would like to provide your own schema. If this is the case it is recommended you take a look at: What about MLST not hosted at pubmlst.org? then follow the directory structure for mlst .","title":"mlst"},{"location":"datasets/#optional","text":"Built into the Bactopia dataset structure is the optional folder that you, the user, can populate for species specific analysis. These could include specific genes you might want BLASTed against your samples or a specific reference you want all your samples mapped to and variants called.","title":"optional"},{"location":"datasets/#blast","text":"${DATASET_FOLDER} \u2514\u2500\u2500 species-specific \u2514\u2500\u2500 ${SPECIES} \u2514\u2500\u2500 optional \u2514\u2500\u2500 blast \u251c\u2500\u2500 genes \u2502 \u2514\u2500\u2500 ${NAME}.fasta \u251c\u2500\u2500 primers \u2502 \u2514\u2500\u2500 ${NAME}.fasta \u2514\u2500\u2500 proteins \u2514\u2500\u2500 ${NAME}.fasta In the blast directory there are three more directories! The genes folder is where you can place gene seqeunces (nucleotides) in FASTA format to query against assemblies using blastn . The primers folder is where you can place primer sequences (nucleotides) in FASTA format to query against assemblies using blastn , but with primer-specific parameters and cut-offs. Finally, the proteins (as you probably guessed!) is where you can place protein sequnces (amino acids) in FASTA format to query against assemblies using blastp .","title":"blast"},{"location":"datasets/#mapping-sequences","text":"${DATASET_FOLDER} \u2514\u2500\u2500 species-specific \u2514\u2500\u2500 ${SPECIES} \u2514\u2500\u2500 optional \u2514\u2500\u2500 mapping-sequences \u2514\u2500\u2500 ${NAME}.fasta In the mapping-sequences directory you can place FASTA files of any nucleotide sequence you would like FASTQ reads to be mapped against using BWA . This can be useful if you are interested if whether a certain region or gene is covered or not.","title":"mapping-sequences"},{"location":"datasets/#reference-genomes","text":"${DATASET_FOLDER} \u2514\u2500\u2500 species-specific \u2514\u2500\u2500 ${SPECIES} \u2514\u2500\u2500 optional \u2514\u2500\u2500 reference-genomes \u2514\u2500\u2500 ${NAME}.{gbk|fasta} In the reference-genomes directory you can put a GenBank (preferred!) or FASTA file of a reference genome you would like variants to be called against using Snippy .","title":"reference-genomes"},{"location":"installation/","text":"Installation \u00b6 Bactopia has a a lot of tools built into its workflow. As you can imagine, all these tools lead to numerous dependencies, and navigating dependencies can often turn into a very frustrating process. With this in mind, from the onset Bactopia was developed to only include programs that are installable using Conda . Conda is an open source package management system and environment management system that runs on Windows, macOS and Linux. In other words, it makes it super easy to get the tools you need installed! The official Conda documentation is a good starting point for getting started with Conda. Bactopia has been tested using the Miniconda installer , but the Anaconda installer should work the same. Containers (Docker and Singularity) are also available. Bioconda \u00b6 Once you have Conda all set up, you are ready to create an environment for Bactopia. To do so, you can use the following command: conda create -n bactopia -c conda-forge -c bioconda bactopia After a few minutes you will have a new conda environment suitably named bactopia . To activate this environment, you will can use the following command: conda activate bactopia And voil\u00e0, you are all set to get started processing your data! But first, it is highly recommended that you take the time to Build Datasets that Bactopia can take advantage of. OSX has limited support I have developed Bactopia primarily for Linux, but I recognize it is useable on Mac OSX. Currently the support for OSX will be limited due to not having significant resources available for testing OSX extensively. My current setup, a mid-2013 MacBook, only allows me to maintain the Conda YAMLS for OSX. Please keep this in mind when using Bactopia on OSX. I will still try to help out if you run into any issues! Windows is not supported, please use Windows Subsystem for Linux Bactopia will never support Windows natively due to dependencies. To use Bactopia on a Windows 10 machine, you will need to set up Windows Subsystem for Linux (WSL). This would allow you to run Bactopia inside the Linux subsystem. I have not tested Bactopia on WSL, but assume it should work fine. I have limited resources to test Bactopia in WSL, but if you give it a go and run into any issues please reach out! Container \u00b6 A Docker and Singularity container has been created that is based off the Conda install. # Docker docker pull bactopia/bactopia # Singularity singularity pull library://rpetit3/bactopia/bactopia These might not be available Recent changes to DockerHub and Singularity policies have made the availability of these containers questionable. While I will try my best to make sure they are available, please understand if they are not. If they are not available, I maintain the Dockerfile and Singularity files which can be used to build the containers locally.","title":"Installation"},{"location":"installation/#installation","text":"Bactopia has a a lot of tools built into its workflow. As you can imagine, all these tools lead to numerous dependencies, and navigating dependencies can often turn into a very frustrating process. With this in mind, from the onset Bactopia was developed to only include programs that are installable using Conda . Conda is an open source package management system and environment management system that runs on Windows, macOS and Linux. In other words, it makes it super easy to get the tools you need installed! The official Conda documentation is a good starting point for getting started with Conda. Bactopia has been tested using the Miniconda installer , but the Anaconda installer should work the same. Containers (Docker and Singularity) are also available.","title":"Installation"},{"location":"installation/#bioconda","text":"Once you have Conda all set up, you are ready to create an environment for Bactopia. To do so, you can use the following command: conda create -n bactopia -c conda-forge -c bioconda bactopia After a few minutes you will have a new conda environment suitably named bactopia . To activate this environment, you will can use the following command: conda activate bactopia And voil\u00e0, you are all set to get started processing your data! But first, it is highly recommended that you take the time to Build Datasets that Bactopia can take advantage of. OSX has limited support I have developed Bactopia primarily for Linux, but I recognize it is useable on Mac OSX. Currently the support for OSX will be limited due to not having significant resources available for testing OSX extensively. My current setup, a mid-2013 MacBook, only allows me to maintain the Conda YAMLS for OSX. Please keep this in mind when using Bactopia on OSX. I will still try to help out if you run into any issues! Windows is not supported, please use Windows Subsystem for Linux Bactopia will never support Windows natively due to dependencies. To use Bactopia on a Windows 10 machine, you will need to set up Windows Subsystem for Linux (WSL). This would allow you to run Bactopia inside the Linux subsystem. I have not tested Bactopia on WSL, but assume it should work fine. I have limited resources to test Bactopia in WSL, but if you give it a go and run into any issues please reach out!","title":"Bioconda"},{"location":"installation/#container","text":"A Docker and Singularity container has been created that is based off the Conda install. # Docker docker pull bactopia/bactopia # Singularity singularity pull library://rpetit3/bactopia/bactopia These might not be available Recent changes to DockerHub and Singularity policies have made the availability of these containers questionable. While I will try my best to make sure they are available, please understand if they are not. If they are not available, I maintain the Dockerfile and Singularity files which can be used to build the containers locally.","title":"Container"},{"location":"output-overview/","text":"Overview of Bactopia Output \u00b6 After a successful run, Bactopia will have produced numerous output files. Just how many output files depends on the input datasets used (e.g. none, general datasets, species specific datasets, user populated datasets). Here is the complete directory structure that is possible (using all available dataset options) with Bactopia. ${SAMPLE_NAME}/ \u251c\u2500\u2500 annotation \u251c\u2500\u2500 antimicrobial_resistance \u251c\u2500\u2500 ariba \u251c\u2500\u2500 assembly \u251c\u2500\u2500 blast \u251c\u2500\u2500 kmers \u251c\u2500\u2500 logs \u251c\u2500\u2500 mapping \u251c\u2500\u2500 minmers \u251c\u2500\u2500 mlst \u251c\u2500\u2500 quality-control \u251c\u2500\u2500 variants \u2514\u2500\u2500 ${SAMPLE_NAME}-genome-size.txt For each type of analysis in Bactopia, a separate directory is created to hold the results. All samples processed by Bactopia will have this directory structure. The only difference is the usage of ${SAMPLE_NAME} as a prefix for naming some output files. Directories \u00b6 The following sections include a list of expected outputs as well as a brief description of each output file. There are instances where additional files (e.g. --keep_all_files and --ariba_noclean ) may be encountered. These files aren't described below, just the defaults. Also, using --compress will add a gz extension, but the original extension is maintained and its description still applies. Developer Descriptions Take Priority If a developer described their software's outputs, their description was used with a link back to the software's documentation (major thanks for taking the time to do that!). In some cases there may have been slight formatting modifications made. In any case, if descriptions are not original credit will be properly given to the source. annotation \u00b6 The annotation directory will contain the outputs from Prokka annotation. These outputs include FASTA (proteins and genes), GFF3, GenBank, and many more. By default the included Prokka databases are used for annotation. However, if a Species Specific Dataset was a created the RefSeq clustered proteins are used first for annotation. File descriptions were directly taken from Prokka's Output Files section and slight modifications were made to the order of rows. ${SAMPLE_NAME}/ \u2514\u2500\u2500 annotation \u251c\u2500\u2500 ${SAMPLE_NAME}.err \u251c\u2500\u2500 ${SAMPLE_NAME}.faa \u251c\u2500\u2500 ${SAMPLE_NAME}.ffn \u251c\u2500\u2500 ${SAMPLE_NAME}.fna \u251c\u2500\u2500 ${SAMPLE_NAME}.fsa \u251c\u2500\u2500 ${SAMPLE_NAME}.gbk \u251c\u2500\u2500 ${SAMPLE_NAME}.gff \u251c\u2500\u2500 ${SAMPLE_NAME}.log \u251c\u2500\u2500 ${SAMPLE_NAME}.sqn \u251c\u2500\u2500 ${SAMPLE_NAME}.tbl \u251c\u2500\u2500 ${SAMPLE_NAME}.tsv \u2514\u2500\u2500 ${SAMPLE_NAME}.txt Extension Description .err Unacceptable annotations - the NCBI discrepancy report. .faa Protein FASTA file of the translated CDS sequences. .ffn Nucleotide FASTA file of all the prediction transcripts (CDS, rRNA, tRNA, tmRNA, misc_RNA) .fna Nucleotide FASTA file of the input contig sequences. .fsa Nucleotide FASTA file of the input contig sequences, used by \"tbl2asn\" to create the .sqn file. It is mostly the same as the .fna file, but with extra Sequin tags in the sequence description lines. .gbk This is a standard GenBank file derived from the master .gff. If the input to prokka was a multi-FASTA, then this will be a multi-GenBank, with one record for each sequence. .gff This is the master annotation in GFF3 format, containing both sequences and annotations. It can be viewed directly in Artemis or IGV. .log Contains all the output that Prokka produced during its run. This is a record of what settings you used. .sqn An ASN1 format \"Sequin\" file for submission to GenBank. It needs to be edited to set the correct taxonomy, authors, related publication etc. .tbl Feature Table file, used by \"tbl2asn\" to create the .sqn file. .tsv Tab-separated file of all features: locus_tag,ftype,len_bp,gene,EC_number,COG,product .txt Statistics relating to the annotated features found. antimicrobial_resistance \u00b6 The antimicrobial_resistance directory will contain the output from NCBI's AMRFinderPlus . The results of AMRFinderPlus using genes as and input, and proteins as an input are available. More information about the output format is available from the AMRFinderPlus Wiki . ${SAMPLE_NAME}/ \u2514\u2500\u2500 antimicrobial_resistance/ \u251c\u2500\u2500 ${SAMPLE_NAME}-gene-report.txt \u2514\u2500\u2500 ${SAMPLE_NAME}-protein-report.txt Extension Description -gene-report.txt Results of using gene sequences as an input -protein-report.txt Results of using protein sequences as an input ariba \u00b6 The ariba directory will contain the results of any Ariba analysis (excluding MLST). Only the Ariba databases created during the dataset setup are used for analysis. For each Ariba database (e.g. card or vfdb ), a separate folder with the name of the database is included in the ariba folder. The file descriptions below were modified from Ariba's wiki entries for run and summary . ${SAMPLE_NAME}/ \u2514\u2500\u2500 ariba \u2514\u2500\u2500 ARIBA_DATABASE_NAME \u251c\u2500\u2500 assembled_genes.fa.gz \u251c\u2500\u2500 assembled_seqs.fa.gz \u251c\u2500\u2500 assemblies.fa.gz \u251c\u2500\u2500 debug.report.tsv \u251c\u2500\u2500 log.clusters.gz \u251c\u2500\u2500 report.tsv \u251c\u2500\u2500 summary.csv \u2514\u2500\u2500 version_info.txt Filename Description assembled_genes.fa.gz A gzipped FASTA file of only assembled gene sequences (with extensions). assembled_seqs.fa.gz A gzipped FASTA of the assembled sequences (genes and non-coding). assemblies.fa.gz A gzipped FASTA file of the assemblies (complete, unedited, contigs). debug.report.tsv The complete list of clusters, including those that did not pass filtering. log.clusters.gz Detailed logging for the progress of each cluster. report.tsv A detailed report file of clusters which passed filtering. summary.csv A more condensed summary of the report.tsv version_info.txt Information on the versions of ARIBA and its dependencies at runtime. assembly \u00b6 The assembly folder contains the results of the sample's assembly. standard \u00b6 The standard assembly is managed by Shovill and by default SKESA is used for assembly. Alternative assemblers include SPAdes , MEGAHIT , and Velvet . Depending on the choice of assembler, additional output files (e.g. assembly graphs) may be given. Files descriptions with some modifications were directly taken from Shovill's Output Files section as well as the FLASH usage . ${SAMPLE_NAME}/ \u2514\u2500\u2500 assembly \u251c\u2500\u2500 cointigs.fa \u251c\u2500\u2500 flash.hist \u251c\u2500\u2500 flash.histogram \u251c\u2500\u2500 shovill.corrections \u251c\u2500\u2500 shovill.log \u251c\u2500\u2500 ${SAMPLE_NAME}.fna \u2514\u2500\u2500 ${SAMPLE_NAME}.fna.json Filename Description contigs.fa Final assembly without renamed headers. flash.hist Numeric histogram of merged read lengths. flash.histogram Visual histogram of merged read lengths shovill.log Full log file for bug reporting shovill.corrections List of post-assembly corrections ${SAMPLE_NAME}.fna The final assembly, with renamed header to include sample name ${SAMPLE_NAME}.fna.json Summary statistics of the assembly FASTA inputs are not reassembled by default In the case where an assembly is given as an input, the only files that will be available are ${SAMPLE_NAME}.fna (the original unmodified assembly) and ${SAMPLE_NAME}.fna.json . If --reassemble is also given, then all the files seen above will be available. hybrid \u00b6 If long reads are available to supplement input paired-end Illumina reads, a hybrid assembly can be created using Unicycler . Files descriptions with some modifications were directly taken from Unicycler's Output Files . ${SAMPLE_NAME}/ \u2514\u2500\u2500 assembly \u251c\u2500\u2500 001_best_spades_graph.gfa \u251c\u2500\u2500 002_overlaps_removed.gfa \u251c\u2500\u2500 003_long_read_assembly.gfa \u251c\u2500\u2500 004_bridges_applied.gfa \u251c\u2500\u2500 005_final_clean.gfa \u251c\u2500\u2500 006_polished.gfa \u251c\u2500\u2500 007_rotated.gfa \u251c\u2500\u2500 assembly.fasta \u251c\u2500\u2500 assembly.gfa \u251c\u2500\u2500 ${SAMPLE_NAME}.fna \u251c\u2500\u2500 ${SAMPLE_NAME}.fna.json \u2514\u2500\u2500 unicycler.log Filename Description 001_best_spades_graph.gfa The best SPAdes short-read assembly graph, with a bit of graph clean-up 002_overlaps_removed.gfa Overlap-free version of the SPAdes graph, with some more graph clean-up 003_long_read_assembly.gfa Assembly graph after long read assembly 004_bridges_applied.gfa Bridges applied, before any cleaning or merging 005_final_clean.gfa Assembly graph after more redundant contigs removed 006_polished.gfa Assembly graph after a round of Pilon polishing 007_rotated.gfa Assembly graph after ircular replicons rotated and/or flipped to a start position assembly.fasta The final assembly in FASTA format (same contigs names as in assembly.gfa) assembly.gfa The final assembly in GFA v1 graph format ${SAMPLE_NAME}.fna The final assembly with renamed header to include sample name ${SAMPLE_NAME}.fna.json Summary statistics of the assembly unicycler.log Unicycler log file (same info as stdout) quality reports \u00b6 Each assembly will have its biological and technical quality assessed with CheckM and QUAST . This assessment is done no matter the input type (paired, single, hybrid, or assembly). Files descriptions with some modifications were directly taken from CheckM's Usage and QUAST's Output Files . assembly/ \u251c\u2500\u2500 checkm \u2502 \u251c\u2500\u2500 bins/ \u2502 \u251c\u2500\u2500 checkm-genes.aln \u2502 \u251c\u2500\u2500 checkm.log \u2502 \u251c\u2500\u2500 checkm-results.txt \u2502 \u251c\u2500\u2500 lineage.ms \u2502 \u2514\u2500\u2500 storage/ \u2514\u2500\u2500 quast \u251c\u2500\u2500 basic_stats/ \u251c\u2500\u2500 icarus.html \u251c\u2500\u2500 icarus_viewers \u2502 \u2514\u2500\u2500 contig_size_viewer.html \u251c\u2500\u2500 predicted_genes \u2502 \u251c\u2500\u2500 GCF_003431365_glimmer_genes.gff.gz \u2502 \u2514\u2500\u2500 GCF_003431365_glimmer.stderr \u251c\u2500\u2500 quast.log \u251c\u2500\u2500 report.{html|pdf|tex|tsv|txt} \u251c\u2500\u2500 transposed_report.tex \u251c\u2500\u2500 transposed_report.tsv \u2514\u2500\u2500 transposed_report.txt CheckM Outputs Filename Description bins/ A folder with inputs (e.g. proteins) for processing by CheckM checkm-genes.aln Alignment of multi-copy genes and their AAI identity checkm.log The output log of CheckM checkm-results.txt Final results of CheckM's lineage_wf lineage.ms Output file describing marker set for each bin storage/ A folder with intermediate results from CheckM processing QUAST Outputs Filename Description basic_stats A folder with plots of assembly metrics (e.g. GC content, NGx, Nx) icarus.html Icarus main menu with links to interactive viewers. icarus_viewers/ Additional reports for Icarus predicted_genes/ Predicted gene output quast.log Detailed information about the QUAST run report.{html|pdf } Assessement summary including all tables and plots report.{tex|tsv|txt} Assessment summary in multiple different formats transposed_report.{tex|tsv|txt} Transposed version of the assessment summary blast \u00b6 The blast directory contains the BLAST results and a BLAST database of the sample assembly. Each of the User Populated BLAST Sequences (gene, primer, or protein) is BLASTed against the sample assembly. Also if setup , annotated genes are BLASTed against the PLSDB BLAST database. By default, results are returned in tabular format. ${SAMPLE_NAME}/ \u2514\u2500\u2500 blast \u251c\u2500\u2500 blastdb \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}.nhr \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}.nin \u2502 \u2514\u2500\u2500 ${SAMPLE_NAME}.nsq \u251c\u2500\u2500 genes \u2502 \u2514\u2500\u2500 ${INPUT_NAME}.txt \u251c\u2500\u2500 primers \u2502 \u2514\u2500\u2500 ${INPUT_NAME}.txt \u251c\u2500\u2500 proteins \u2502 \u2514\u2500\u2500 ${INPUT_NAME}.txt \u2514\u2500\u2500 ${SAMPLE_NAME}-plsdb.txt Extension Description .nhr Sample assembly BLAST database header file .nin Sample assembly BLAST database index file .nsq Sample assembly BLAST database sequence file -plsdb.txt The BLAST results against the PLSDB BALST database assembly. .txt The BLAST results of user input sequence(s) against the sample assembly. genome-size \u00b6 For every sample ${SAMPLE_NAME}-genome-size.txt file is created. This file contains the genome size that was used for analysis. Genome size is used throughout Bactopia for various tasks including error correction, subsampling, and assembly. By default, the genome size is estimated with Mash, but users have the option to provide their own value or completely disable genome size related features. Learn more about changing the genome size at Basic Usage - Genome Size kmers \u00b6 The kmers directory contains McCortex 31-mer counts of the cleaned up FASTQ sequences. ${SAMPLE_NAME}/ \u2514\u2500\u2500 kmers \u2514\u2500\u2500 ${SAMPLE_NAME}.ctx Extension Description .ctx A Cortex graph file of the 31-mer counts logs \u00b6 The logs folder will contain useful files for debugging or reviewing what was executed. For each process (e.g. annotation or assembly) the STDOUT and STDERR is log, as well as the time of execution and program versions. These outputs are completely optional, and can be disabled using --skip_logs at runtime. ${SAMPLE_NAME}/ \u2514\u2500\u2500 logs/ \u251c\u2500\u2500 ${PROCESS_NAME} \u2502 \u251c\u2500\u2500 ${PROCESS_NAME}.err \u2502 \u251c\u2500\u2500 ${PROCESS_NAME}.out \u2502 \u251c\u2500\u2500 ${PROCESS_NAME}.sh \u2502 \u251c\u2500\u2500 ${PROCESS_NAME}.trace \u2502 \u251c\u2500\u2500 ${PROCESS_NAME}.versions \u2502 \u251c\u2500\u2500 ${PROGRAM}.err \u2502 \u2514\u2500\u2500 ${PROGRAM}.out \u2514\u2500\u2500 bactopia.versions Filename Description ${PROCESS_NAME}.err Any STDERR captured by the process. ${PROCESS_NAME}.out Any STDERR captured by the process. ${PROCESS_NAME}.sh The shell script that process used. ${PROCESS_NAME}.trace Compute resource usage by the process (this will not always be available) ${PROCESS_NAME}.versions Date and program versions used by the process ${PROGRAM}.err STDERR captured for a specific program. ${PROGRAM}.err STDOUT captured for a specific program. bactopia.versions Date and Bactopia/Nextflow versions used Example versions \u00b6 Here is an example of the bactopia.versions file. # Timestamp 2020-11-11T11:12:31-05:00 # Bactopia Version bactopia 1.4.11 # Nextflow Version nextflow 20.07.1 All the .versions files will follow this format. The first line is always # Timestamp followed by the output of date . Then each line beginning with # will represent a new program and its version. mapping \u00b6 The mapping-sequences directory contains BWA (bwa-mem) mapping results for each of the User Populated Mapping Sequences . ${SAMPLE_NAME}/ \u2514\u2500\u2500 mapping \u2514\u2500\u2500 ${MAPPING_INPUT} \u251c\u2500\u2500 ${MAPPING_INPUT}.bam \u2514\u2500\u2500 ${MAPPING_INPUT}.coverage.txt Extension Description .bam The alignments in BAM format. .coverage.txt The per-base coverage of the mapping results minmers \u00b6 The minmers directory contains Mash and Sourmash sketches of the cleaned FASTQs. If setup, it also contains the results of queries against RefSeq, GenBank and PLSDB ${SAMPLE_NAME}/ \u2514\u2500\u2500 minmers \u251c\u2500\u2500 ${SAMPLE_NAME}-genbank-k21.txt \u251c\u2500\u2500 ${SAMPLE_NAME}-genbank-k31.txt \u251c\u2500\u2500 ${SAMPLE_NAME}-genbank-k51.txt \u251c\u2500\u2500 ${SAMPLE_NAME}-k21.msh \u251c\u2500\u2500 ${SAMPLE_NAME}-k31.msh \u251c\u2500\u2500 ${SAMPLE_NAME}-plsdb-k21.txt \u251c\u2500\u2500 ${SAMPLE_NAME}-refseq-k21.txt \u2514\u2500\u2500 ${SAMPLE_NAME}.sig Extension Description -genbank-k(21|31|51).txt Sourmash LCA Gather results against Sourmash GenBank Signature (k=21,31,51) -k(21|31).msh A Mash sketch (k=21,31) of the sample -plsdb-k21.txt Mash Screen results against PLSDB Mash Sketch -refseq-k21.txt Mash Screen results against Mash Refseq Sketch .sig A Sourmash signature (k=21,31,51) of the sample mlst \u00b6 If a Species Specific Dataset has been set up, the mlst directory will contain Ariba and BLAST results for a PubMLST.org schema. For most organisms there is only one MLST schema available, and it will be labeled as default . In cases where a organism has multiple schemas available they will be named following pubMLST's naming. ${SAMPLE_NAME}/ \u2514\u2500\u2500 mlst \u2514\u2500\u2500 ${SCHEMA} \u251c\u2500\u2500 ariba \u2502 \u251c\u2500\u2500 assembled_genes.fa.gz \u2502 \u251c\u2500\u2500 assembled_seqs.fa.gz \u2502 \u251c\u2500\u2500 assemblies.fa.gz \u2502 \u251c\u2500\u2500 debug.report.tsv \u2502 \u251c\u2500\u2500 log.clusters.gz \u2502 \u251c\u2500\u2500 mlst_report.details.tsv \u2502 \u251c\u2500\u2500 mlst_report.tsv \u2502 \u251c\u2500\u2500 report.tsv \u2502 \u2514\u2500\u2500 version_info.txt \u2514\u2500\u2500 blast \u2514\u2500\u2500 ${SAMPLE_NAME}-blast.json Filename Description assembled_genes.fa.gz A gzipped FASTA file of only assembled gene sequences (with extensions). assembled_seqs.fa.gz A gzipped FASTA of the assembled sequences (genes and non-coding). assemblies.fa.gz A gzipped FASTA file of the assemblies (complete, unedited, contigs). debug.report.tsv The complete list of clusters, including those that did not pass filtering. log.clusters.gz Detailed logging for the progress of each cluster. mlst_report.details.tsv A more detailed summary of the allele calls. mlst_report.tsv A summary of the allele calls and identified sequence type. report.tsv A detailed report file of clusters which passed filtering. summary.csv A more condensed summary of the report.tsv version_info.txt Information on the versions of ARIBA and its dependencies at runtime. -blast.json Allele calls and identified sequence type based on BLAST quality-control \u00b6 The quality-control directory contains the cleaned up FASTQs ( BBTools and Lighter ) and summary statitics ( FastQC and Fastq-Scan ) before and after cleanup. ${SAMPLE_NAME}/ \u2514\u2500\u2500 quality-control \u251c\u2500\u2500 logs \u2502 \u251c\u2500\u2500 bbduk-adapter.log \u2502 \u2514\u2500\u2500 bbduk-phix.log \u251c\u2500\u2500 ${SAMPLE_NAME}(|_R1|_R2).fastq.gz \u2514\u2500\u2500 summary-(original|final) \u251c\u2500\u2500 ${SAMPLE_NAME}(|_R1|_R2)-(original|final)_fastqc.html \u251c\u2500\u2500 ${SAMPLE_NAME}(|_R1|_R2)-(original|final)_fastqc.zip \u2514\u2500\u2500 ${SAMPLE_NAME}(|_R1|_R2)-(original|final).json Extension Description -adapter.log A description of how many reads were filtered during the adapter removal step -phix.log A description of how many reads were filtered during the PhiX removal step .fastq.gz The cleaned up FASTQ(s), _R1 and _R2 for paired-end reads, and an empty string for single-end reads. _fastqc.html The FastQC html report of the original and final FASTQ(s) _fastqc.zip The zipped FastQC full report of the original and final FASTQ(s) .json Summary statistics (e.g. qualities and read lengths) of the original and final FASTQ(s) variants \u00b6 The variants directory contains the results of Snippy variant calls against one or more reference genomes. There are two subdirectories auto and user . The auto directory includes variants calls against automatically selected reference genome(s) based on nearest Mash distance to RefSeq completed genomes. This process only happens if a Species Specific Dataset was a created. By default, only a single reference genome (nearest) is selected. This feature can be disabled ( --disable_auto_variants ) or the number of genomes changed ( --max_references INT ). The user directory contains variant calls against for each of the User Populated Reference Genomes . The following description of files was directly taken from Snippy's Output Files section. Slight modifications were made to the order of rows. ${SAMPLE_NAME}/ \u2514\u2500\u2500 variants \u2514\u2500\u2500 (auto|user) \u2514\u2500\u2500 ${REFERENCE_NAME} \u251c\u2500\u2500 ${SAMPLE_NAME}.aligned.fa \u251c\u2500\u2500 ${SAMPLE_NAME}.annotated.vcf \u251c\u2500\u2500 ${SAMPLE_NAME}.bam \u251c\u2500\u2500 ${SAMPLE_NAME}.bam.bai \u251c\u2500\u2500 ${SAMPLE_NAME}.bed \u251c\u2500\u2500 ${SAMPLE_NAME}.consensus.fa \u251c\u2500\u2500 ${SAMPLE_NAME}.consensus.subs.fa \u251c\u2500\u2500 ${SAMPLE_NAME}.consensus.subs.masked.fa \u251c\u2500\u2500 ${SAMPLE_NAME}.coverage.txt \u251c\u2500\u2500 ${SAMPLE_NAME}.csv \u251c\u2500\u2500 ${SAMPLE_NAME}.filt.vcf \u251c\u2500\u2500 ${SAMPLE_NAME}.gff \u251c\u2500\u2500 ${SAMPLE_NAME}.html \u251c\u2500\u2500 ${SAMPLE_NAME}.log \u251c\u2500\u2500 ${SAMPLE_NAME}.raw.vcf \u251c\u2500\u2500 ${SAMPLE_NAME}.subs.vcf \u251c\u2500\u2500 ${SAMPLE_NAME}.tab \u251c\u2500\u2500 ${SAMPLE_NAME}.txt \u2514\u2500\u2500 ${SAMPLE_NAME}.vcf Extension Description .aligned.fa A version of the reference but with - at position with depth=0 and N for 0 < depth < --mincov ( does not have variants ) .annotated.vcf The final variant calls with additional annotations from Reference genome's GenBank file .bam The alignments in BAM format. Includes unmapped, multimapping reads. Excludes duplicates. .bam.bai Index for the .bam file .bed The variants in BED format .consensus.fa A version of the reference genome with all variants instantiated .consensus.subs.fa A version of the reference genome with only substitution variants instantiated .consensus.subs.masked.fa A version of the reference genome with only substitution variants instantiated and low-coverage regions masked .coverage.txt The per-base coverage of each position in the reference genome .csv A comma-separated version of the .tab file .filt.vcf The filtered variant calls from Freebayes .gff The variants in GFF3 format .html A HTML version of the .tab file .log A log file with the commands run and their outputs .raw.vcf The unfiltered variant calls from Freebayes .subs.vcf Only substitution variants from the final annotated variants .tab A simple tab-separated summary of all the variants .txt A summary of the Snippy run. .vcf The final annotated variants in VCF format","title":"Output Overview"},{"location":"output-overview/#overview-of-bactopia-output","text":"After a successful run, Bactopia will have produced numerous output files. Just how many output files depends on the input datasets used (e.g. none, general datasets, species specific datasets, user populated datasets). Here is the complete directory structure that is possible (using all available dataset options) with Bactopia. ${SAMPLE_NAME}/ \u251c\u2500\u2500 annotation \u251c\u2500\u2500 antimicrobial_resistance \u251c\u2500\u2500 ariba \u251c\u2500\u2500 assembly \u251c\u2500\u2500 blast \u251c\u2500\u2500 kmers \u251c\u2500\u2500 logs \u251c\u2500\u2500 mapping \u251c\u2500\u2500 minmers \u251c\u2500\u2500 mlst \u251c\u2500\u2500 quality-control \u251c\u2500\u2500 variants \u2514\u2500\u2500 ${SAMPLE_NAME}-genome-size.txt For each type of analysis in Bactopia, a separate directory is created to hold the results. All samples processed by Bactopia will have this directory structure. The only difference is the usage of ${SAMPLE_NAME} as a prefix for naming some output files.","title":"Overview of Bactopia Output"},{"location":"output-overview/#directories","text":"The following sections include a list of expected outputs as well as a brief description of each output file. There are instances where additional files (e.g. --keep_all_files and --ariba_noclean ) may be encountered. These files aren't described below, just the defaults. Also, using --compress will add a gz extension, but the original extension is maintained and its description still applies. Developer Descriptions Take Priority If a developer described their software's outputs, their description was used with a link back to the software's documentation (major thanks for taking the time to do that!). In some cases there may have been slight formatting modifications made. In any case, if descriptions are not original credit will be properly given to the source.","title":"Directories"},{"location":"output-overview/#annotation","text":"The annotation directory will contain the outputs from Prokka annotation. These outputs include FASTA (proteins and genes), GFF3, GenBank, and many more. By default the included Prokka databases are used for annotation. However, if a Species Specific Dataset was a created the RefSeq clustered proteins are used first for annotation. File descriptions were directly taken from Prokka's Output Files section and slight modifications were made to the order of rows. ${SAMPLE_NAME}/ \u2514\u2500\u2500 annotation \u251c\u2500\u2500 ${SAMPLE_NAME}.err \u251c\u2500\u2500 ${SAMPLE_NAME}.faa \u251c\u2500\u2500 ${SAMPLE_NAME}.ffn \u251c\u2500\u2500 ${SAMPLE_NAME}.fna \u251c\u2500\u2500 ${SAMPLE_NAME}.fsa \u251c\u2500\u2500 ${SAMPLE_NAME}.gbk \u251c\u2500\u2500 ${SAMPLE_NAME}.gff \u251c\u2500\u2500 ${SAMPLE_NAME}.log \u251c\u2500\u2500 ${SAMPLE_NAME}.sqn \u251c\u2500\u2500 ${SAMPLE_NAME}.tbl \u251c\u2500\u2500 ${SAMPLE_NAME}.tsv \u2514\u2500\u2500 ${SAMPLE_NAME}.txt Extension Description .err Unacceptable annotations - the NCBI discrepancy report. .faa Protein FASTA file of the translated CDS sequences. .ffn Nucleotide FASTA file of all the prediction transcripts (CDS, rRNA, tRNA, tmRNA, misc_RNA) .fna Nucleotide FASTA file of the input contig sequences. .fsa Nucleotide FASTA file of the input contig sequences, used by \"tbl2asn\" to create the .sqn file. It is mostly the same as the .fna file, but with extra Sequin tags in the sequence description lines. .gbk This is a standard GenBank file derived from the master .gff. If the input to prokka was a multi-FASTA, then this will be a multi-GenBank, with one record for each sequence. .gff This is the master annotation in GFF3 format, containing both sequences and annotations. It can be viewed directly in Artemis or IGV. .log Contains all the output that Prokka produced during its run. This is a record of what settings you used. .sqn An ASN1 format \"Sequin\" file for submission to GenBank. It needs to be edited to set the correct taxonomy, authors, related publication etc. .tbl Feature Table file, used by \"tbl2asn\" to create the .sqn file. .tsv Tab-separated file of all features: locus_tag,ftype,len_bp,gene,EC_number,COG,product .txt Statistics relating to the annotated features found.","title":"annotation"},{"location":"output-overview/#antimicrobial_resistance","text":"The antimicrobial_resistance directory will contain the output from NCBI's AMRFinderPlus . The results of AMRFinderPlus using genes as and input, and proteins as an input are available. More information about the output format is available from the AMRFinderPlus Wiki . ${SAMPLE_NAME}/ \u2514\u2500\u2500 antimicrobial_resistance/ \u251c\u2500\u2500 ${SAMPLE_NAME}-gene-report.txt \u2514\u2500\u2500 ${SAMPLE_NAME}-protein-report.txt Extension Description -gene-report.txt Results of using gene sequences as an input -protein-report.txt Results of using protein sequences as an input","title":"antimicrobial_resistance"},{"location":"output-overview/#ariba","text":"The ariba directory will contain the results of any Ariba analysis (excluding MLST). Only the Ariba databases created during the dataset setup are used for analysis. For each Ariba database (e.g. card or vfdb ), a separate folder with the name of the database is included in the ariba folder. The file descriptions below were modified from Ariba's wiki entries for run and summary . ${SAMPLE_NAME}/ \u2514\u2500\u2500 ariba \u2514\u2500\u2500 ARIBA_DATABASE_NAME \u251c\u2500\u2500 assembled_genes.fa.gz \u251c\u2500\u2500 assembled_seqs.fa.gz \u251c\u2500\u2500 assemblies.fa.gz \u251c\u2500\u2500 debug.report.tsv \u251c\u2500\u2500 log.clusters.gz \u251c\u2500\u2500 report.tsv \u251c\u2500\u2500 summary.csv \u2514\u2500\u2500 version_info.txt Filename Description assembled_genes.fa.gz A gzipped FASTA file of only assembled gene sequences (with extensions). assembled_seqs.fa.gz A gzipped FASTA of the assembled sequences (genes and non-coding). assemblies.fa.gz A gzipped FASTA file of the assemblies (complete, unedited, contigs). debug.report.tsv The complete list of clusters, including those that did not pass filtering. log.clusters.gz Detailed logging for the progress of each cluster. report.tsv A detailed report file of clusters which passed filtering. summary.csv A more condensed summary of the report.tsv version_info.txt Information on the versions of ARIBA and its dependencies at runtime.","title":"ariba"},{"location":"output-overview/#assembly","text":"The assembly folder contains the results of the sample's assembly.","title":"assembly"},{"location":"output-overview/#standard","text":"The standard assembly is managed by Shovill and by default SKESA is used for assembly. Alternative assemblers include SPAdes , MEGAHIT , and Velvet . Depending on the choice of assembler, additional output files (e.g. assembly graphs) may be given. Files descriptions with some modifications were directly taken from Shovill's Output Files section as well as the FLASH usage . ${SAMPLE_NAME}/ \u2514\u2500\u2500 assembly \u251c\u2500\u2500 cointigs.fa \u251c\u2500\u2500 flash.hist \u251c\u2500\u2500 flash.histogram \u251c\u2500\u2500 shovill.corrections \u251c\u2500\u2500 shovill.log \u251c\u2500\u2500 ${SAMPLE_NAME}.fna \u2514\u2500\u2500 ${SAMPLE_NAME}.fna.json Filename Description contigs.fa Final assembly without renamed headers. flash.hist Numeric histogram of merged read lengths. flash.histogram Visual histogram of merged read lengths shovill.log Full log file for bug reporting shovill.corrections List of post-assembly corrections ${SAMPLE_NAME}.fna The final assembly, with renamed header to include sample name ${SAMPLE_NAME}.fna.json Summary statistics of the assembly FASTA inputs are not reassembled by default In the case where an assembly is given as an input, the only files that will be available are ${SAMPLE_NAME}.fna (the original unmodified assembly) and ${SAMPLE_NAME}.fna.json . If --reassemble is also given, then all the files seen above will be available.","title":"standard"},{"location":"output-overview/#hybrid","text":"If long reads are available to supplement input paired-end Illumina reads, a hybrid assembly can be created using Unicycler . Files descriptions with some modifications were directly taken from Unicycler's Output Files . ${SAMPLE_NAME}/ \u2514\u2500\u2500 assembly \u251c\u2500\u2500 001_best_spades_graph.gfa \u251c\u2500\u2500 002_overlaps_removed.gfa \u251c\u2500\u2500 003_long_read_assembly.gfa \u251c\u2500\u2500 004_bridges_applied.gfa \u251c\u2500\u2500 005_final_clean.gfa \u251c\u2500\u2500 006_polished.gfa \u251c\u2500\u2500 007_rotated.gfa \u251c\u2500\u2500 assembly.fasta \u251c\u2500\u2500 assembly.gfa \u251c\u2500\u2500 ${SAMPLE_NAME}.fna \u251c\u2500\u2500 ${SAMPLE_NAME}.fna.json \u2514\u2500\u2500 unicycler.log Filename Description 001_best_spades_graph.gfa The best SPAdes short-read assembly graph, with a bit of graph clean-up 002_overlaps_removed.gfa Overlap-free version of the SPAdes graph, with some more graph clean-up 003_long_read_assembly.gfa Assembly graph after long read assembly 004_bridges_applied.gfa Bridges applied, before any cleaning or merging 005_final_clean.gfa Assembly graph after more redundant contigs removed 006_polished.gfa Assembly graph after a round of Pilon polishing 007_rotated.gfa Assembly graph after ircular replicons rotated and/or flipped to a start position assembly.fasta The final assembly in FASTA format (same contigs names as in assembly.gfa) assembly.gfa The final assembly in GFA v1 graph format ${SAMPLE_NAME}.fna The final assembly with renamed header to include sample name ${SAMPLE_NAME}.fna.json Summary statistics of the assembly unicycler.log Unicycler log file (same info as stdout)","title":"hybrid"},{"location":"output-overview/#quality-reports","text":"Each assembly will have its biological and technical quality assessed with CheckM and QUAST . This assessment is done no matter the input type (paired, single, hybrid, or assembly). Files descriptions with some modifications were directly taken from CheckM's Usage and QUAST's Output Files . assembly/ \u251c\u2500\u2500 checkm \u2502 \u251c\u2500\u2500 bins/ \u2502 \u251c\u2500\u2500 checkm-genes.aln \u2502 \u251c\u2500\u2500 checkm.log \u2502 \u251c\u2500\u2500 checkm-results.txt \u2502 \u251c\u2500\u2500 lineage.ms \u2502 \u2514\u2500\u2500 storage/ \u2514\u2500\u2500 quast \u251c\u2500\u2500 basic_stats/ \u251c\u2500\u2500 icarus.html \u251c\u2500\u2500 icarus_viewers \u2502 \u2514\u2500\u2500 contig_size_viewer.html \u251c\u2500\u2500 predicted_genes \u2502 \u251c\u2500\u2500 GCF_003431365_glimmer_genes.gff.gz \u2502 \u2514\u2500\u2500 GCF_003431365_glimmer.stderr \u251c\u2500\u2500 quast.log \u251c\u2500\u2500 report.{html|pdf|tex|tsv|txt} \u251c\u2500\u2500 transposed_report.tex \u251c\u2500\u2500 transposed_report.tsv \u2514\u2500\u2500 transposed_report.txt CheckM Outputs Filename Description bins/ A folder with inputs (e.g. proteins) for processing by CheckM checkm-genes.aln Alignment of multi-copy genes and their AAI identity checkm.log The output log of CheckM checkm-results.txt Final results of CheckM's lineage_wf lineage.ms Output file describing marker set for each bin storage/ A folder with intermediate results from CheckM processing QUAST Outputs Filename Description basic_stats A folder with plots of assembly metrics (e.g. GC content, NGx, Nx) icarus.html Icarus main menu with links to interactive viewers. icarus_viewers/ Additional reports for Icarus predicted_genes/ Predicted gene output quast.log Detailed information about the QUAST run report.{html|pdf } Assessement summary including all tables and plots report.{tex|tsv|txt} Assessment summary in multiple different formats transposed_report.{tex|tsv|txt} Transposed version of the assessment summary","title":"quality reports"},{"location":"output-overview/#blast","text":"The blast directory contains the BLAST results and a BLAST database of the sample assembly. Each of the User Populated BLAST Sequences (gene, primer, or protein) is BLASTed against the sample assembly. Also if setup , annotated genes are BLASTed against the PLSDB BLAST database. By default, results are returned in tabular format. ${SAMPLE_NAME}/ \u2514\u2500\u2500 blast \u251c\u2500\u2500 blastdb \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}.nhr \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}.nin \u2502 \u2514\u2500\u2500 ${SAMPLE_NAME}.nsq \u251c\u2500\u2500 genes \u2502 \u2514\u2500\u2500 ${INPUT_NAME}.txt \u251c\u2500\u2500 primers \u2502 \u2514\u2500\u2500 ${INPUT_NAME}.txt \u251c\u2500\u2500 proteins \u2502 \u2514\u2500\u2500 ${INPUT_NAME}.txt \u2514\u2500\u2500 ${SAMPLE_NAME}-plsdb.txt Extension Description .nhr Sample assembly BLAST database header file .nin Sample assembly BLAST database index file .nsq Sample assembly BLAST database sequence file -plsdb.txt The BLAST results against the PLSDB BALST database assembly. .txt The BLAST results of user input sequence(s) against the sample assembly.","title":"blast"},{"location":"output-overview/#genome-size","text":"For every sample ${SAMPLE_NAME}-genome-size.txt file is created. This file contains the genome size that was used for analysis. Genome size is used throughout Bactopia for various tasks including error correction, subsampling, and assembly. By default, the genome size is estimated with Mash, but users have the option to provide their own value or completely disable genome size related features. Learn more about changing the genome size at Basic Usage - Genome Size","title":"genome-size"},{"location":"output-overview/#kmers","text":"The kmers directory contains McCortex 31-mer counts of the cleaned up FASTQ sequences. ${SAMPLE_NAME}/ \u2514\u2500\u2500 kmers \u2514\u2500\u2500 ${SAMPLE_NAME}.ctx Extension Description .ctx A Cortex graph file of the 31-mer counts","title":"kmers"},{"location":"output-overview/#logs","text":"The logs folder will contain useful files for debugging or reviewing what was executed. For each process (e.g. annotation or assembly) the STDOUT and STDERR is log, as well as the time of execution and program versions. These outputs are completely optional, and can be disabled using --skip_logs at runtime. ${SAMPLE_NAME}/ \u2514\u2500\u2500 logs/ \u251c\u2500\u2500 ${PROCESS_NAME} \u2502 \u251c\u2500\u2500 ${PROCESS_NAME}.err \u2502 \u251c\u2500\u2500 ${PROCESS_NAME}.out \u2502 \u251c\u2500\u2500 ${PROCESS_NAME}.sh \u2502 \u251c\u2500\u2500 ${PROCESS_NAME}.trace \u2502 \u251c\u2500\u2500 ${PROCESS_NAME}.versions \u2502 \u251c\u2500\u2500 ${PROGRAM}.err \u2502 \u2514\u2500\u2500 ${PROGRAM}.out \u2514\u2500\u2500 bactopia.versions Filename Description ${PROCESS_NAME}.err Any STDERR captured by the process. ${PROCESS_NAME}.out Any STDERR captured by the process. ${PROCESS_NAME}.sh The shell script that process used. ${PROCESS_NAME}.trace Compute resource usage by the process (this will not always be available) ${PROCESS_NAME}.versions Date and program versions used by the process ${PROGRAM}.err STDERR captured for a specific program. ${PROGRAM}.err STDOUT captured for a specific program. bactopia.versions Date and Bactopia/Nextflow versions used","title":"logs"},{"location":"output-overview/#example-versions","text":"Here is an example of the bactopia.versions file. # Timestamp 2020-11-11T11:12:31-05:00 # Bactopia Version bactopia 1.4.11 # Nextflow Version nextflow 20.07.1 All the .versions files will follow this format. The first line is always # Timestamp followed by the output of date . Then each line beginning with # will represent a new program and its version.","title":"Example versions"},{"location":"output-overview/#mapping","text":"The mapping-sequences directory contains BWA (bwa-mem) mapping results for each of the User Populated Mapping Sequences . ${SAMPLE_NAME}/ \u2514\u2500\u2500 mapping \u2514\u2500\u2500 ${MAPPING_INPUT} \u251c\u2500\u2500 ${MAPPING_INPUT}.bam \u2514\u2500\u2500 ${MAPPING_INPUT}.coverage.txt Extension Description .bam The alignments in BAM format. .coverage.txt The per-base coverage of the mapping results","title":"mapping"},{"location":"output-overview/#minmers","text":"The minmers directory contains Mash and Sourmash sketches of the cleaned FASTQs. If setup, it also contains the results of queries against RefSeq, GenBank and PLSDB ${SAMPLE_NAME}/ \u2514\u2500\u2500 minmers \u251c\u2500\u2500 ${SAMPLE_NAME}-genbank-k21.txt \u251c\u2500\u2500 ${SAMPLE_NAME}-genbank-k31.txt \u251c\u2500\u2500 ${SAMPLE_NAME}-genbank-k51.txt \u251c\u2500\u2500 ${SAMPLE_NAME}-k21.msh \u251c\u2500\u2500 ${SAMPLE_NAME}-k31.msh \u251c\u2500\u2500 ${SAMPLE_NAME}-plsdb-k21.txt \u251c\u2500\u2500 ${SAMPLE_NAME}-refseq-k21.txt \u2514\u2500\u2500 ${SAMPLE_NAME}.sig Extension Description -genbank-k(21|31|51).txt Sourmash LCA Gather results against Sourmash GenBank Signature (k=21,31,51) -k(21|31).msh A Mash sketch (k=21,31) of the sample -plsdb-k21.txt Mash Screen results against PLSDB Mash Sketch -refseq-k21.txt Mash Screen results against Mash Refseq Sketch .sig A Sourmash signature (k=21,31,51) of the sample","title":"minmers"},{"location":"output-overview/#mlst","text":"If a Species Specific Dataset has been set up, the mlst directory will contain Ariba and BLAST results for a PubMLST.org schema. For most organisms there is only one MLST schema available, and it will be labeled as default . In cases where a organism has multiple schemas available they will be named following pubMLST's naming. ${SAMPLE_NAME}/ \u2514\u2500\u2500 mlst \u2514\u2500\u2500 ${SCHEMA} \u251c\u2500\u2500 ariba \u2502 \u251c\u2500\u2500 assembled_genes.fa.gz \u2502 \u251c\u2500\u2500 assembled_seqs.fa.gz \u2502 \u251c\u2500\u2500 assemblies.fa.gz \u2502 \u251c\u2500\u2500 debug.report.tsv \u2502 \u251c\u2500\u2500 log.clusters.gz \u2502 \u251c\u2500\u2500 mlst_report.details.tsv \u2502 \u251c\u2500\u2500 mlst_report.tsv \u2502 \u251c\u2500\u2500 report.tsv \u2502 \u2514\u2500\u2500 version_info.txt \u2514\u2500\u2500 blast \u2514\u2500\u2500 ${SAMPLE_NAME}-blast.json Filename Description assembled_genes.fa.gz A gzipped FASTA file of only assembled gene sequences (with extensions). assembled_seqs.fa.gz A gzipped FASTA of the assembled sequences (genes and non-coding). assemblies.fa.gz A gzipped FASTA file of the assemblies (complete, unedited, contigs). debug.report.tsv The complete list of clusters, including those that did not pass filtering. log.clusters.gz Detailed logging for the progress of each cluster. mlst_report.details.tsv A more detailed summary of the allele calls. mlst_report.tsv A summary of the allele calls and identified sequence type. report.tsv A detailed report file of clusters which passed filtering. summary.csv A more condensed summary of the report.tsv version_info.txt Information on the versions of ARIBA and its dependencies at runtime. -blast.json Allele calls and identified sequence type based on BLAST","title":"mlst"},{"location":"output-overview/#quality-control","text":"The quality-control directory contains the cleaned up FASTQs ( BBTools and Lighter ) and summary statitics ( FastQC and Fastq-Scan ) before and after cleanup. ${SAMPLE_NAME}/ \u2514\u2500\u2500 quality-control \u251c\u2500\u2500 logs \u2502 \u251c\u2500\u2500 bbduk-adapter.log \u2502 \u2514\u2500\u2500 bbduk-phix.log \u251c\u2500\u2500 ${SAMPLE_NAME}(|_R1|_R2).fastq.gz \u2514\u2500\u2500 summary-(original|final) \u251c\u2500\u2500 ${SAMPLE_NAME}(|_R1|_R2)-(original|final)_fastqc.html \u251c\u2500\u2500 ${SAMPLE_NAME}(|_R1|_R2)-(original|final)_fastqc.zip \u2514\u2500\u2500 ${SAMPLE_NAME}(|_R1|_R2)-(original|final).json Extension Description -adapter.log A description of how many reads were filtered during the adapter removal step -phix.log A description of how many reads were filtered during the PhiX removal step .fastq.gz The cleaned up FASTQ(s), _R1 and _R2 for paired-end reads, and an empty string for single-end reads. _fastqc.html The FastQC html report of the original and final FASTQ(s) _fastqc.zip The zipped FastQC full report of the original and final FASTQ(s) .json Summary statistics (e.g. qualities and read lengths) of the original and final FASTQ(s)","title":"quality-control"},{"location":"output-overview/#variants","text":"The variants directory contains the results of Snippy variant calls against one or more reference genomes. There are two subdirectories auto and user . The auto directory includes variants calls against automatically selected reference genome(s) based on nearest Mash distance to RefSeq completed genomes. This process only happens if a Species Specific Dataset was a created. By default, only a single reference genome (nearest) is selected. This feature can be disabled ( --disable_auto_variants ) or the number of genomes changed ( --max_references INT ). The user directory contains variant calls against for each of the User Populated Reference Genomes . The following description of files was directly taken from Snippy's Output Files section. Slight modifications were made to the order of rows. ${SAMPLE_NAME}/ \u2514\u2500\u2500 variants \u2514\u2500\u2500 (auto|user) \u2514\u2500\u2500 ${REFERENCE_NAME} \u251c\u2500\u2500 ${SAMPLE_NAME}.aligned.fa \u251c\u2500\u2500 ${SAMPLE_NAME}.annotated.vcf \u251c\u2500\u2500 ${SAMPLE_NAME}.bam \u251c\u2500\u2500 ${SAMPLE_NAME}.bam.bai \u251c\u2500\u2500 ${SAMPLE_NAME}.bed \u251c\u2500\u2500 ${SAMPLE_NAME}.consensus.fa \u251c\u2500\u2500 ${SAMPLE_NAME}.consensus.subs.fa \u251c\u2500\u2500 ${SAMPLE_NAME}.consensus.subs.masked.fa \u251c\u2500\u2500 ${SAMPLE_NAME}.coverage.txt \u251c\u2500\u2500 ${SAMPLE_NAME}.csv \u251c\u2500\u2500 ${SAMPLE_NAME}.filt.vcf \u251c\u2500\u2500 ${SAMPLE_NAME}.gff \u251c\u2500\u2500 ${SAMPLE_NAME}.html \u251c\u2500\u2500 ${SAMPLE_NAME}.log \u251c\u2500\u2500 ${SAMPLE_NAME}.raw.vcf \u251c\u2500\u2500 ${SAMPLE_NAME}.subs.vcf \u251c\u2500\u2500 ${SAMPLE_NAME}.tab \u251c\u2500\u2500 ${SAMPLE_NAME}.txt \u2514\u2500\u2500 ${SAMPLE_NAME}.vcf Extension Description .aligned.fa A version of the reference but with - at position with depth=0 and N for 0 < depth < --mincov ( does not have variants ) .annotated.vcf The final variant calls with additional annotations from Reference genome's GenBank file .bam The alignments in BAM format. Includes unmapped, multimapping reads. Excludes duplicates. .bam.bai Index for the .bam file .bed The variants in BED format .consensus.fa A version of the reference genome with all variants instantiated .consensus.subs.fa A version of the reference genome with only substitution variants instantiated .consensus.subs.masked.fa A version of the reference genome with only substitution variants instantiated and low-coverage regions masked .coverage.txt The per-base coverage of each position in the reference genome .csv A comma-separated version of the .tab file .filt.vcf The filtered variant calls from Freebayes .gff The variants in GFF3 format .html A HTML version of the .tab file .log A log file with the commands run and their outputs .raw.vcf The unfiltered variant calls from Freebayes .subs.vcf Only substitution variants from the final annotated variants .tab A simple tab-separated summary of all the variants .txt A summary of the Snippy run. .vcf The final annotated variants in VCF format","title":"variants"},{"location":"quick-start/","text":"Quick Start \u00b6 Here we go! No time to waste, let's get the ball rolling! Why are you still reading this?!? Go! Go! Go! Installation \u00b6 conda create -y -n bactopia -c conda-forge -c bioconda bactopia conda activate bactopia Build Dataset \u00b6 bactopia datasets This create a folder ./datasets and will build the following datasets: CARD VFDB RefSeq Mash Sketch GenBank Sourmash Signatures PLSDB Mash Sketch & BLAST More information about these datasets is available at Build Datasets . Run Bactopia! \u00b6 On the first launch of Bactopia it will install the Conda environments, so expect some delays in doing so! Single Sample \u00b6 Paired-End \u00b6 bactopia --R1 SEQS_R1.fastq.gz \\ --R2 SEQS_R2.fastq.gz \\ --sample SAMPLE_NAME \\ --datasets datasets/ \\ --outdir OUTDIR In the command above, be sure to replace SEQS_R1.fastq.gz and SEQS_R2.fastq.gz with the name of your FASTQ files. You will also want to replace SAMPLE_NAME with your sample's name and OUTDIR with a directory name you would like to use for results. Single-End \u00b6 bactopia --SE SEQS.fastq.gz --sample SAMPLE_NAME --datasets datasets/ --outdir OUTDIR In the command above, be sure to replace SEQS.fastq.gz with the name of your FASTQ file. You will also want to replace SAMPLE_NAME with your sample's name and OUTDIR with a directory name you would like to use for results. Multiple Samples \u00b6 bactopia prepare directory-of-fastqs/ > fastqs.txt bactopia --fastqs fastqs.txt --datasets datasets --outdir OUTDIR In the command above, be sure to replace OUTDIR with a directory name you would like to use for results.","title":"Quick Start"},{"location":"quick-start/#quick-start","text":"Here we go! No time to waste, let's get the ball rolling! Why are you still reading this?!? Go! Go! Go!","title":"Quick Start"},{"location":"quick-start/#installation","text":"conda create -y -n bactopia -c conda-forge -c bioconda bactopia conda activate bactopia","title":"Installation"},{"location":"quick-start/#build-dataset","text":"bactopia datasets This create a folder ./datasets and will build the following datasets: CARD VFDB RefSeq Mash Sketch GenBank Sourmash Signatures PLSDB Mash Sketch & BLAST More information about these datasets is available at Build Datasets .","title":"Build Dataset"},{"location":"quick-start/#run-bactopia","text":"On the first launch of Bactopia it will install the Conda environments, so expect some delays in doing so!","title":"Run Bactopia!"},{"location":"quick-start/#single-sample","text":"","title":"Single Sample"},{"location":"quick-start/#paired-end","text":"bactopia --R1 SEQS_R1.fastq.gz \\ --R2 SEQS_R2.fastq.gz \\ --sample SAMPLE_NAME \\ --datasets datasets/ \\ --outdir OUTDIR In the command above, be sure to replace SEQS_R1.fastq.gz and SEQS_R2.fastq.gz with the name of your FASTQ files. You will also want to replace SAMPLE_NAME with your sample's name and OUTDIR with a directory name you would like to use for results.","title":"Paired-End"},{"location":"quick-start/#single-end","text":"bactopia --SE SEQS.fastq.gz --sample SAMPLE_NAME --datasets datasets/ --outdir OUTDIR In the command above, be sure to replace SEQS.fastq.gz with the name of your FASTQ file. You will also want to replace SAMPLE_NAME with your sample's name and OUTDIR with a directory name you would like to use for results.","title":"Single-End"},{"location":"quick-start/#multiple-samples","text":"bactopia prepare directory-of-fastqs/ > fastqs.txt bactopia --fastqs fastqs.txt --datasets datasets --outdir OUTDIR In the command above, be sure to replace OUTDIR with a directory name you would like to use for results.","title":"Multiple Samples"},{"location":"troubleshooting/","text":"Troubleshooting Bactopia \u00b6 It was bound to happen, an error has occurred or a bug has shown itself. Now let's see if we can fix it! Don't see your error/bug? Post an issue on GitHub If you've encountered an error or bug not seen here, please post an issue at Bactopia GitHub Issues . This will help greatly to track down the error and fix it! Past Errors \u00b6 These should have been fixed. The following errors should have been fixed. If you are still receiving them, please make sure you are using the most up to date version of Bactopia. If you are, and you are still recieving one of these errors, please reopen the associated issue on GitHub. Thanks! Failed to create Conda Environment \u00b6 This was fixed in v1.2.1 A new function bactopia build was introduced that builds the Conda environments outside of Nextflow. If you are still receiving this error please reopen the Better handling of conda environments? issue. Occasionally on the first run of Bactopia you will encounter this error: Caused by: Failed to create Conda environment command: conda env create --prefix /data/apps/bactopia/conda/cache/envs/bactopia-gather_fastqs-8bddd22dc63ec39a71c4ea8fd7704f7a --file /data/apps/bactopia/conda/gather_fastqs.yml status : 1 message: InvalidArchiveError(\"Error with archive /home/rpetit/miniconda3/envs/bactopia/pkgs/python-3.7.3-h33d41f4_1.tar.bz2. You probably need to delete and re-download or re-create this file. Message from libarchive was:\\n\\nFailed to create dir 'lib'\",) While it may look like this is related to Nextflow, it is actually a Conda error that occurs when installing multiple environments at once which Nextflow likes to do. This can also occur from a timeout or loss of internet connectivity (under a different error name).","title":"Troubleshooting"},{"location":"troubleshooting/#troubleshooting-bactopia","text":"It was bound to happen, an error has occurred or a bug has shown itself. Now let's see if we can fix it! Don't see your error/bug? Post an issue on GitHub If you've encountered an error or bug not seen here, please post an issue at Bactopia GitHub Issues . This will help greatly to track down the error and fix it!","title":"Troubleshooting Bactopia"},{"location":"troubleshooting/#past-errors","text":"These should have been fixed. The following errors should have been fixed. If you are still receiving them, please make sure you are using the most up to date version of Bactopia. If you are, and you are still recieving one of these errors, please reopen the associated issue on GitHub. Thanks!","title":"Past Errors"},{"location":"troubleshooting/#failed-to-create-conda-environment","text":"This was fixed in v1.2.1 A new function bactopia build was introduced that builds the Conda environments outside of Nextflow. If you are still receiving this error please reopen the Better handling of conda environments? issue. Occasionally on the first run of Bactopia you will encounter this error: Caused by: Failed to create Conda environment command: conda env create --prefix /data/apps/bactopia/conda/cache/envs/bactopia-gather_fastqs-8bddd22dc63ec39a71c4ea8fd7704f7a --file /data/apps/bactopia/conda/gather_fastqs.yml status : 1 message: InvalidArchiveError(\"Error with archive /home/rpetit/miniconda3/envs/bactopia/pkgs/python-3.7.3-h33d41f4_1.tar.bz2. You probably need to delete and re-download or re-create this file. Message from libarchive was:\\n\\nFailed to create dir 'lib'\",) While it may look like this is related to Nextflow, it is actually a Conda error that occurs when installing multiple environments at once which Nextflow likes to do. This can also occur from a timeout or loss of internet connectivity (under a different error name).","title":"Failed to create Conda Environment"},{"location":"tutorial/","text":"You should now have a directory named datasets that has all the available datasets to be used by Bactopia.# Tutorial For this tutorial, we will attempt to replicate the Staphopia analysis pipeline with Bactopia. We will use S. aureus samples associated with cystic fibrosis lung infections that were recently published (details below, shameless self plug!) and are available from BioProject accession PRJNA480016 . Bernardy, Eryn E., et al. \"Whole-Genome Sequences of Staphylococcus aureus Isolates from Cystic Fibrosis Lung Infections.\" Microbiol Resour Announc 8.3 (2019): e01564-18. Overall the goal of the tutorial is to: Build datasets Acquire Staphopia datasets Use Bactopia to process: A sample from SRA/ENA Multiple samples from SRA/ENA Single local sample Multiple local samples using FOFN Bactopia Should Be Installed This tutorial assumes you have already installed Bactopia. If you have not, please check out how to at Installation . Build Datasets \u00b6 First let's create a directory to work in and activate our Bactopia environment. mkdir bactopia-tutorial cd bactopia-tutorial conda activate bactopia Now we are ready to build our datasets! bactopia datasets \\ --ariba \"vfdb_core,card\" \\ --species \"Staphylococcus aureus\" \\ --include_genus \\ --cpus 4 Let's review what is happening here. --ariba \"vfdb_core,card\" says to download and setup the VFDB Core and the CARD databases to be used by Ariba. --species \"Staphylococcus aureus\" will download MLST schemas associated with S. aureus it will also download completed S. aureus genomes (RefSeq only) that are used to create a set of protein set for annotation, a Mash sketch for automatic variant calling to the nearest neighbor, and calculate genome size statistics. --include_genus will also download completed genomes from the Staphylococcus genus that will be used for the protein set. These completed genomes are not used for the sketch creation or genome size calculation. --cpus 4 will use 4 cpus for downloading and the clustering step. Adjust this number according to your setup! These datasets will be built into the default datasets/ folder which can be changed using --outdir Use CARD over MEGARes Staphopia v1 made use of MEGARes, for the purposes of this tutorial we are going to use the CARD database instead. If all goes well, the newly created datasets are now available in the folder datasets/ . We have now completed the dataset creation step! Pat yourself on the back! Next we'll supplement these datasets with some optional S. aureus specific datasets. Acquire Staphopia Datasets \u00b6 Staphopia includes a few optional datasets such as S. aureus N315 reference genome and SCCmec sequences (primers, proteins, full cassettes). We will acquire these files using the Bactopia Datasets GitHub repository. For this tutorial a we'll be using the Staphylococcus aureus dataset repository. Now let's clone the repository. git clone https://github.com/bactopia-datasets/staphylococcus-aureus.git Next we'll copy the files into our recently built datasets folder and delete the staphylococcus-aureus repository since we no longer need it. cp -r staphylococcus-aureus/species-specific/ datasets/ rm -rf staphylococcus-aureus/ ~Voil\u00e0! That should be it. You should now have the S. aureus datasets included with your recently built datasets (e.g. S. aureus protein clusters, RefSeq sketch, etc...) Running Bactopia \u00b6 OK! Get your servers started up! It is time to get processing! Samples on SRA \u00b6 Single Sample \u00b6 Let's start this by downloading a single sample from the Sequence Read Archive (SRA), and processing it through Bactopia. bactopia --accession SRX4563634 \\ --datasets datasets/ \\ --species \"Staphylococcus aureus\" \\ --coverage 100 \\ --genome_size median \\ --cpus 2 \\ --outdir ena-single-sample So, what's happening here? --accession SRX4563634 is telling Bactopia to download FASTQs associated with Exeriment accession SRX4563634. --datasets datasets/ tells Bactopia your pre-built datasets are in the folder datasets . --species \"Staphylococcus aureus\" tells Bactopia, within the datasets folder, use the species specific dataset for S. aureus . --coverage 100 will limit the cleaned up FASTQ file to an estimated 100x coverage based on the genome size. --genome_size median tells Bactopia to use the median genome size of completed S. aureus genomes. The minimum, maximum, median, and mean genome sizes were calculated during the dataset building step. If a genome size was not given, it would have been estimated by Mash. --cpus 2 tells Bactopia to use a maximum of 2 cpus per process. Adjust this parameter to fit your setup! --outdir ena-single-sample tells Bactopia to dump the results into the ena-single-sample folder. Please keep in mind, this will not stop Nextflow from creating files (.nextflow, trace.txt, etc...) and directories (work and .nextflow/) within your current directory. Use --use_ena to download from ENA If you append --use_ena to the command above the FASTQ files for SRX4563634 will be downloaded from the European Nucleotide Archive (ENA) instead of SRA. Once you launch this command, sit back, relax and watch the Nextflow give realtime updates for SRX4563634's analysis! The approximate completion time is ~15-30 minutes depending on the number of cpus given and download times from ENA. Once complete, the results from numerous tools available to you in ena-single-sample/SRX4563634/ . Multiple Samples \u00b6 Now we are going to have Bactopia download and process 5 samples from ENA. To do this we can use the bactopia search function. bactopia search PRJNA480016 --limit 5 This will produce three files: ena-accessions.txt , ena-results.txt and ena-summary.txt . To learn more about these files see Generating Accession List . For this tutorial, ena-accessions.txt is the file we need. It contains five Experiment accessions, a single one per line. Just like this: SRX4563688 SRX4563687 SRX4563686 SRX4563689 SRX4563690 Note: you may have 5 different accessions from the PRJNA480016 project. To process these samples, we will adjust our command used previously. bactopia --accessions ena-accessions.txt \\ --datasets datasets/ \\ --species \"Staphylococcus aureus\" \\ --coverage 100 \\ --genome_size median \\ --cpus 2 \\ --outdir ena-multiple-samples Instead of --accession we are now using --accessions ena-accessions.txt which tells Bactopia to read ena-accessions.txt , and download each Experiment accession from SRA (for ENA add --use_ena ) and then process it. At this point, you might want to go for a walk or make yourself a coffee! This step has an approximate completion time of ~45-120 minutes , which again is fully dependent on the cpus used and the download times from SRA (or ENA). Once this is complete, the results for all five samples will be found in the ena-multiple-samples directory. Each sample will have there own folder of results. Local Samples \u00b6 So for the local samples, we're going to recycle some of the samples we downloaded from SRA/ENA. First let's make a directory to put the FASTQs into: mkdir fastqs Now let's move some the FASTQs from our SRX4563634 sample into this folder. cp ena-single-sample/SRX4563634/quality-control/SRX4563634*.fastq.gz fastqs/ Finally let's also make a single-end version of SRX4563634. cat fastqs/SRX4563634*.fastq.gz > fastqs/SRX4563634-SE.fastq.gz OK! Now we are ready to continue the tutorial! Single Sample \u00b6 Again we'll mostly be using the same parameters as previous, but with a few new ones. To process a single sample you can use the --R1 / --R2 (paired-end), --SE (single-end), and --sample parameters. Paired-End \u00b6 For paired-end reads you will want to use --R1 , --R2 , and --sample . For this paired-end example we'll use SRX4563634 again which we've copied to the fastqs folder. bactopia --R1 fastqs/SRX4563634_R1.fastq.gz \\ --R2 fastqs/SRX4563634_R2.fastq.gz \\ --sample SRX4563634 \\ --datasets datasets/ \\ --species \"Staphylococcus aureus\" \\ --coverage 100 \\ --genome_size median \\ --cpus 2 \\ --outdir local-single-sample Now Bactopia will recognize the --R1 and --R2 parameters as paired-end reads and process. The --sample is required and will be used for naming the output. Similar to the single SRA/ENA sample, the approximate completion time is ~15-30 minutes depending on the number of cpus given. Once complete, results can be found in local-single-sample/SRX4563634/ . Single-End \u00b6 In the case of Illumina reads, you're very unlikely to produce single-end reads, but they do exist in the wild (early days of Illumina!). Nevertheless, because single-end reads do exist, single-end support was built into Bactopia. To analyze single-end reads, the --SE parameter will replace --R1 and --R2 . bactopia --SE fastqs/SRX4563634-SE.fastq.gz \\ --sample SRX4563634-SE \\ --datasets datasets/ \\ --species \"Staphylococcus aureus\" \\ --coverage 100 \\ --genome_size median \\ --cpus 2 \\ --outdir local-single-sample Now SRX4563634-SE will be processed as a single-end sample. For single-end processing there are some paired-end only analyses (e.g. error correction, insertion sequences) that will be skipped. This leads to single-end samples being processed a little bit faster than pair-end samples. But, the approximate completion time is still ~15-30 minutes . Once complete, you'll the results from numerous tools available to you in local-single-sample/SRX4563634-SE/ . If you made it this far, you're almost done! Multiple Samples (FOFN) \u00b6 Here we go! The final way you can process samples in Bactopia! Bactopia allows you to give a text file describing the input samples. This file of file names (FOFN), contains sample names and location to associated FASTQs. The Bactopia FOFN format is described in detail at Basic Usage -> Multiple Samples . First we'll need to prepare a FOFN describing the FASTQ files in our fastqs folder. We can use bactopia prepare to do so: bactopia prepare fastqs/ > fastqs.txt This command will try to create a FOFN for you. For this turorial, the FASTQ names are pretty straight forward and should produce a correct FOFN (or at least it should! ... hopefully!). If that wasn't the case for you, there are ways to tweak bactopia prepare . Now we can use the --fastqs parameters to process samples in the FOFN. bactopia --fastqs fastqs.txt \\ --datasets datasets/ \\ --species \"Staphylococcus aureus\" \\ --coverage 100 \\ --genome_size median \\ --cpus 2 \\ --outdir local-multiple-samples We no longer need --R1 , --R2 , --SE , or --sample as the values for these parameters can be determined from the FOFN. Here it is, the final wait! This step has an approximate completion time of ~45-120 minutes . So, you will definitely want to go for a walk or make yourself a coffee! You've earned it! Once this is complete, the results for each sample (within their own folder) will be found in the local-multiple-samples directory. FOFN is more cpu efficient, making it faster The real benefit of using the FOFN method to process multiple samples is Nextflow's queue system will make better use of cpus. Processing multiple samples one at a time (via --R1 / --R2 or --SE ) will lead more instances of jobs waiting on other jobs to finish, during which cpus aren't being used. What's next? \u00b6 That should do it! Hopefully you have succeeded (yay! \ud83c\udf89) and would like to use Bactopia on your own data! In this tutorial we covered how to build datasets ( bactopia datasets ) and how process samples. We also covered the bactopia search and bactopia prepare to prepare file for multiple sample processing. If your ran into any issues, please let me know by submitting a GitHub Issue .","title":"Tutorial"},{"location":"tutorial/#build-datasets","text":"First let's create a directory to work in and activate our Bactopia environment. mkdir bactopia-tutorial cd bactopia-tutorial conda activate bactopia Now we are ready to build our datasets! bactopia datasets \\ --ariba \"vfdb_core,card\" \\ --species \"Staphylococcus aureus\" \\ --include_genus \\ --cpus 4 Let's review what is happening here. --ariba \"vfdb_core,card\" says to download and setup the VFDB Core and the CARD databases to be used by Ariba. --species \"Staphylococcus aureus\" will download MLST schemas associated with S. aureus it will also download completed S. aureus genomes (RefSeq only) that are used to create a set of protein set for annotation, a Mash sketch for automatic variant calling to the nearest neighbor, and calculate genome size statistics. --include_genus will also download completed genomes from the Staphylococcus genus that will be used for the protein set. These completed genomes are not used for the sketch creation or genome size calculation. --cpus 4 will use 4 cpus for downloading and the clustering step. Adjust this number according to your setup! These datasets will be built into the default datasets/ folder which can be changed using --outdir Use CARD over MEGARes Staphopia v1 made use of MEGARes, for the purposes of this tutorial we are going to use the CARD database instead. If all goes well, the newly created datasets are now available in the folder datasets/ . We have now completed the dataset creation step! Pat yourself on the back! Next we'll supplement these datasets with some optional S. aureus specific datasets.","title":"Build Datasets"},{"location":"tutorial/#acquire-staphopia-datasets","text":"Staphopia includes a few optional datasets such as S. aureus N315 reference genome and SCCmec sequences (primers, proteins, full cassettes). We will acquire these files using the Bactopia Datasets GitHub repository. For this tutorial a we'll be using the Staphylococcus aureus dataset repository. Now let's clone the repository. git clone https://github.com/bactopia-datasets/staphylococcus-aureus.git Next we'll copy the files into our recently built datasets folder and delete the staphylococcus-aureus repository since we no longer need it. cp -r staphylococcus-aureus/species-specific/ datasets/ rm -rf staphylococcus-aureus/ ~Voil\u00e0! That should be it. You should now have the S. aureus datasets included with your recently built datasets (e.g. S. aureus protein clusters, RefSeq sketch, etc...)","title":"Acquire Staphopia Datasets"},{"location":"tutorial/#running-bactopia","text":"OK! Get your servers started up! It is time to get processing!","title":"Running Bactopia"},{"location":"tutorial/#samples-on-sra","text":"","title":"Samples on SRA"},{"location":"tutorial/#single-sample","text":"Let's start this by downloading a single sample from the Sequence Read Archive (SRA), and processing it through Bactopia. bactopia --accession SRX4563634 \\ --datasets datasets/ \\ --species \"Staphylococcus aureus\" \\ --coverage 100 \\ --genome_size median \\ --cpus 2 \\ --outdir ena-single-sample So, what's happening here? --accession SRX4563634 is telling Bactopia to download FASTQs associated with Exeriment accession SRX4563634. --datasets datasets/ tells Bactopia your pre-built datasets are in the folder datasets . --species \"Staphylococcus aureus\" tells Bactopia, within the datasets folder, use the species specific dataset for S. aureus . --coverage 100 will limit the cleaned up FASTQ file to an estimated 100x coverage based on the genome size. --genome_size median tells Bactopia to use the median genome size of completed S. aureus genomes. The minimum, maximum, median, and mean genome sizes were calculated during the dataset building step. If a genome size was not given, it would have been estimated by Mash. --cpus 2 tells Bactopia to use a maximum of 2 cpus per process. Adjust this parameter to fit your setup! --outdir ena-single-sample tells Bactopia to dump the results into the ena-single-sample folder. Please keep in mind, this will not stop Nextflow from creating files (.nextflow, trace.txt, etc...) and directories (work and .nextflow/) within your current directory. Use --use_ena to download from ENA If you append --use_ena to the command above the FASTQ files for SRX4563634 will be downloaded from the European Nucleotide Archive (ENA) instead of SRA. Once you launch this command, sit back, relax and watch the Nextflow give realtime updates for SRX4563634's analysis! The approximate completion time is ~15-30 minutes depending on the number of cpus given and download times from ENA. Once complete, the results from numerous tools available to you in ena-single-sample/SRX4563634/ .","title":"Single Sample"},{"location":"tutorial/#multiple-samples","text":"Now we are going to have Bactopia download and process 5 samples from ENA. To do this we can use the bactopia search function. bactopia search PRJNA480016 --limit 5 This will produce three files: ena-accessions.txt , ena-results.txt and ena-summary.txt . To learn more about these files see Generating Accession List . For this tutorial, ena-accessions.txt is the file we need. It contains five Experiment accessions, a single one per line. Just like this: SRX4563688 SRX4563687 SRX4563686 SRX4563689 SRX4563690 Note: you may have 5 different accessions from the PRJNA480016 project. To process these samples, we will adjust our command used previously. bactopia --accessions ena-accessions.txt \\ --datasets datasets/ \\ --species \"Staphylococcus aureus\" \\ --coverage 100 \\ --genome_size median \\ --cpus 2 \\ --outdir ena-multiple-samples Instead of --accession we are now using --accessions ena-accessions.txt which tells Bactopia to read ena-accessions.txt , and download each Experiment accession from SRA (for ENA add --use_ena ) and then process it. At this point, you might want to go for a walk or make yourself a coffee! This step has an approximate completion time of ~45-120 minutes , which again is fully dependent on the cpus used and the download times from SRA (or ENA). Once this is complete, the results for all five samples will be found in the ena-multiple-samples directory. Each sample will have there own folder of results.","title":"Multiple Samples"},{"location":"tutorial/#local-samples","text":"So for the local samples, we're going to recycle some of the samples we downloaded from SRA/ENA. First let's make a directory to put the FASTQs into: mkdir fastqs Now let's move some the FASTQs from our SRX4563634 sample into this folder. cp ena-single-sample/SRX4563634/quality-control/SRX4563634*.fastq.gz fastqs/ Finally let's also make a single-end version of SRX4563634. cat fastqs/SRX4563634*.fastq.gz > fastqs/SRX4563634-SE.fastq.gz OK! Now we are ready to continue the tutorial!","title":"Local Samples"},{"location":"tutorial/#single-sample_1","text":"Again we'll mostly be using the same parameters as previous, but with a few new ones. To process a single sample you can use the --R1 / --R2 (paired-end), --SE (single-end), and --sample parameters.","title":"Single Sample"},{"location":"tutorial/#paired-end","text":"For paired-end reads you will want to use --R1 , --R2 , and --sample . For this paired-end example we'll use SRX4563634 again which we've copied to the fastqs folder. bactopia --R1 fastqs/SRX4563634_R1.fastq.gz \\ --R2 fastqs/SRX4563634_R2.fastq.gz \\ --sample SRX4563634 \\ --datasets datasets/ \\ --species \"Staphylococcus aureus\" \\ --coverage 100 \\ --genome_size median \\ --cpus 2 \\ --outdir local-single-sample Now Bactopia will recognize the --R1 and --R2 parameters as paired-end reads and process. The --sample is required and will be used for naming the output. Similar to the single SRA/ENA sample, the approximate completion time is ~15-30 minutes depending on the number of cpus given. Once complete, results can be found in local-single-sample/SRX4563634/ .","title":"Paired-End"},{"location":"tutorial/#single-end","text":"In the case of Illumina reads, you're very unlikely to produce single-end reads, but they do exist in the wild (early days of Illumina!). Nevertheless, because single-end reads do exist, single-end support was built into Bactopia. To analyze single-end reads, the --SE parameter will replace --R1 and --R2 . bactopia --SE fastqs/SRX4563634-SE.fastq.gz \\ --sample SRX4563634-SE \\ --datasets datasets/ \\ --species \"Staphylococcus aureus\" \\ --coverage 100 \\ --genome_size median \\ --cpus 2 \\ --outdir local-single-sample Now SRX4563634-SE will be processed as a single-end sample. For single-end processing there are some paired-end only analyses (e.g. error correction, insertion sequences) that will be skipped. This leads to single-end samples being processed a little bit faster than pair-end samples. But, the approximate completion time is still ~15-30 minutes . Once complete, you'll the results from numerous tools available to you in local-single-sample/SRX4563634-SE/ . If you made it this far, you're almost done!","title":"Single-End"},{"location":"tutorial/#multiple-samples-fofn","text":"Here we go! The final way you can process samples in Bactopia! Bactopia allows you to give a text file describing the input samples. This file of file names (FOFN), contains sample names and location to associated FASTQs. The Bactopia FOFN format is described in detail at Basic Usage -> Multiple Samples . First we'll need to prepare a FOFN describing the FASTQ files in our fastqs folder. We can use bactopia prepare to do so: bactopia prepare fastqs/ > fastqs.txt This command will try to create a FOFN for you. For this turorial, the FASTQ names are pretty straight forward and should produce a correct FOFN (or at least it should! ... hopefully!). If that wasn't the case for you, there are ways to tweak bactopia prepare . Now we can use the --fastqs parameters to process samples in the FOFN. bactopia --fastqs fastqs.txt \\ --datasets datasets/ \\ --species \"Staphylococcus aureus\" \\ --coverage 100 \\ --genome_size median \\ --cpus 2 \\ --outdir local-multiple-samples We no longer need --R1 , --R2 , --SE , or --sample as the values for these parameters can be determined from the FOFN. Here it is, the final wait! This step has an approximate completion time of ~45-120 minutes . So, you will definitely want to go for a walk or make yourself a coffee! You've earned it! Once this is complete, the results for each sample (within their own folder) will be found in the local-multiple-samples directory. FOFN is more cpu efficient, making it faster The real benefit of using the FOFN method to process multiple samples is Nextflow's queue system will make better use of cpus. Processing multiple samples one at a time (via --R1 / --R2 or --SE ) will lead more instances of jobs waiting on other jobs to finish, during which cpus aren't being used.","title":"Multiple Samples (FOFN)"},{"location":"tutorial/#whats-next","text":"That should do it! Hopefully you have succeeded (yay! \ud83c\udf89) and would like to use Bactopia on your own data! In this tutorial we covered how to build datasets ( bactopia datasets ) and how process samples. We also covered the bactopia search and bactopia prepare to prepare file for multiple sample processing. If your ran into any issues, please let me know by submitting a GitHub Issue .","title":"What's next?"},{"location":"usage-basic/","text":"Basic Usage For Bactopia \u00b6 Bactopia is a wrapper around many different tools. Each of these tools may (or may not) have there own configurable parameters for you to tweak. In order to facilitate getting started with Bactopia, this section has been limited to discussion of only a few parameters. However, if you are interested in the full list of configurable parameters in Bactopia, please check out the Complete Usage section. Usage \u00b6 Required Parameters: ### For Procesessing Multiple Samples --fastqs STR An input file containing the sample name and absolute paths to FASTQ/FASTAs to process ### For Processing A Single Sample --R1 STR First set of reads for paired end in compressed (gzip) FASTQ format --R2 STR Second set of reads for paired end in compressed (gzip) FASTQ format --SE STR Single end set of reads in compressed (gzip) FASTQ format --hybrid The SE should be treated as long reads for hybrid assembly. --sample STR The name of the input sequences ### For Downloading from SRA/ENA or NCBI Assembly **Note: Assemblies will have error free Illumina reads simulated for processing.** --accessions An input file containing ENA/SRA Experiment accessions or NCBI Assembly accessions to be processed --accession A single ENA/SRA Experiment accession or NCBI Assembly accession to be processed ### For Processing an Assembly **Note: The assembly will have error free Illumina reads simulated for processing.** --assembly STR A assembled genome in compressed FASTA format. --reassemble The simulated reads will be used to create a new assembly. Default: Use the original assembly, do not reassemble Dataset Parameters: --datasets DIR The path to available datasets that have already been set up --species STR Determines which species-specific dataset to use for the input sequencing Optional Parameters: --coverage INT Reduce samples to a given coverage Default: 100x --genome_size INT Expected genome size (bp) for all samples, a value of '0' will disable read error correction and read subsampling. Special values (requires --species): 'min': uses minimum completed genome size of species 'median': uses median completed genome size of species 'mean': uses mean completed genome size of species 'max': uses max completed genome size of species Default: Mash estimate --outdir DIR Directory to write results to Default: . Nextflow Queue Parameters: At execution, Nextflow creates a queue and the number of slots in the queue is determined by the total number of cores on the system. When a task is submitted to the queue, the total number of slots it occupies is determined by the value set by \"--cpus\". This can have a significant effect on the efficiency of the Nextflow's queue system. If \"--cpus\" is set to a value that is equal to the number of cores availabe, in most cases only a single task will be able to run because its occupying all available slots. When in doubt, \"--cpus 4\" is a safe bet, it is also the default value if you don't use \"--cpus\". --max_time INT The maximum number of minutes a single task should run before being halted. Default: 240 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single task. Default: 64 Gb --cpus INT Number of processors made available to a single task. Default: 4 -qs Nextflow queue size. This parameter is very useful to limit the total number of processors used on desktops, laptops or shared resources. Default: Nextflow defaults to the total number of processors on your system. Nextflow Related Parameters: --infodir DIR Directory to write Nextflow summary files to Default: ./bactopia-info --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --nfconfig STR A Nextflow compatible config file for custom profiles. This allows you to create profiles specific to your environment (e.g. SGE, AWS, SLURM, etc...). This config file is loaded last and will overwrite existing variables if set. Default: Bactopia's default configs --nfdir Print directory Nextflow has pulled Bactopia to --overwrite Nextflow will overwrite existing output files. Default: false --conatainerPath Path to Singularity containers to be used by the 'slurm' profile. Default: /opt/bactopia/singularity --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: false -resume Nextflow will attempt to resume a previous run. Please notice it is only a single '-' --cleanup_workdir After Bactopia is successfully executed, the work firectory will be deleted. Warning: by doing this you lose the ability to resume workflows. Useful Parameters: --skip_logs Logs for each process per sample will not be kept. --available_datasets Print a list of available datasets found based on location given by \"--datasets\" --example_fastqs Print example of expected input for FASTQs file --check_fastqs Verify \"--fastqs\" produces the expected inputs --compress Compress (gzip) select outputs (e.g. annotation, variant calls) to reduce overall storage footprint. --keep_all_files Keeps all analysis files created. By default, intermediate files are removed. This will not affect the ability to resume Nextflow runs, and only occurs at the end of the process. --version Print workflow version information --help Show this message and exit --help_all Show a complete list of adjustable parameters Inputs \u00b6 Bactopia has multiple approaches to specify your input sequences. Bactopia can process Illumina FASTQs, assemblies, and long reads for hybrid assembly. Illumina FASTQs a can be your local FASTQs or a Experiment accession to download associated FASTQs from the European Nucleotide Archive (ENA) . Likewise assemblies can be local, or a GenBank/RefSeq accession to download from NCBI Assembly. Input assemblies will have Illumina reads simulated so that the complete Bactopia pipeline run. By default, the assembly will not be reassembled. Which approach really depends on what you need to achieve! The following sections describe methods to process single samples, multiple samples, downloading samples from the ENA. Local \u00b6 Single Sample \u00b6 When you only need to process a single sample at a time, Bactopia allows that! You only have to the sample name ( --sample ) and the whether the read set is paired-end ( --R1 and --R2 ), single-end ( --SE ), Illumina paired-end + long reads ( --hybrid ), or an assembly ( --assembly ). Use --R1, --R2 for Paired-End FASTQs bactopia --sample my-sample --R1 /path/to/my-sample_R1.fastq.gz --R2 /path/to/my-sample_R2.fastq.gz Use --SE for Single-End FASTQs bactopia --sample my-sample --SE /path/to/my-sample.fastq.gz Use --R1, --R2, --SE, and --hybrid for Paired-End FASTQs with Long Reads At the assembly step, Unicycler will be used to create a hybrid assembly using the paired-end reads and the long reads. bactopia --sample my-sample --R1 /path/to/my-sample_R1.fastq.gz \\ --R2 /path/to/my-sample_R2.fastq.gz \\ --SE /path/to/my-sample.fastq.gz \\ --hybrid Use --assembly for an assembled FASTA Assemblies will have 2x250bp Illumina reads simulated without insertions or deletions in the sequence and a minimum PHRED score of Q33. By default, the input assembly will be used for all downstream analyses (e.g. annotation) which use an assembly. If the --reassemble parameter is given, then the a assembly will be created from the simulated reads. bactopia --sample my-sample --assembly /path/to/my-sample.fna.gz Multiple Samples \u00b6 For multiple samples, you must create a file with information about the inputs, a file of filenames (FOFN). This file specifies sample names and location of FASTQs/FASTAs to be processed. Using this information, paired-end, single-end, hybrid or assembly information can be extracted as well as naming output files. While this is an additional step for you, the user, it helps to avoid potential pattern matching errors. Most importantly, by taking this approach, you can process hundreds of samples in a single command. There is also the added benefit of knowing which FASTQs were analysed and their location at a later time! Use --fastqs for Multiple Samples bactopia --fastqs my-samples.txt The FOFN Format \u00b6 You can use the --example_fastqs to get an example of the expected structure for the input FASTQs FOFN. bactopia --example_fastqs N E X T F L O W ~ version 19.01.0 Launching `/home/rpetit/illumina-cleanup/bin/illumina-cleanup` [naughty_borg] - revision: 0416ba407c Printing example input for \"--fastqs\" sample runtype r1 r2 extra SA103113 assembly /example/SA103113.fna.gz SA110685 hybrid /example/SA110685_R1.fastq.gz /SA110685_R2.fastq.gz /example/SA110685.fastq.gz SA123186 paired-end /example/SA123186_R1.fastq.gz /example/SA123186_R2.fastq.gz SA123456 single-end /example/SA12345.fastq.gz The expected structure is a tab-delimited table with three columns: sample : A unique prefix, or unique name, to be used for naming output files runtype : Informs Bactopia what type of input the sample is r1 : If paired-end, the first pair of reads, else the single-end reads r2 : If paired-end, the second pair of reads extra : Either the assembly or long reads associated with a sample. These five columns are used as the header for the file. In other words, all input FOFNs require their first line to be: sample runtype r1 r2 extra All lines after the header line, contain unique sample names and location(s) to associated FASTQ file(s). Absolute paths should be used to prevent any file not found errors due to the relative path changing. In the example above, four samples would be processed by Bactopia. SA103113 would have simulated reads crreated from the assembly SA110685 would have a hybrid assembly created using the paired-end reads and long-reads SA123186 would be processed as paired-end reads SA123456 would be processed as single-end reads Generating A FOFN \u00b6 bactopia prepare has been included to help aid (hopefully!) the process of creating a FOFN for your samples. This script will attempt to find FASTQ files in a given directory and output the expected FOFN format. It will also output any potential issues associated with the pattern matching. Verify accuracy of FOFN This is currently an experimental function. There are likely bugs to be ironed out. Please be sure to give the resulting FOFN a quick look over. Usage \u00b6 usage: bactopia prepare [-h] [-f STR] [-a STR] [--fastq_seperator STR] [--fastq_pattern STR] [--assembly_pattern STR] [--long_reads] [--version] STR bactopia prepare - Read a directory and prepare a FOFN of FASTQs/FASTAs positional arguments: STR Directory where FASTQ files are stored optional arguments: -h, --help show this help message and exit -f STR, --fastq_ext STR Extension of the FASTQs. Default: .fastq.gz -a STR, --assembly_ext STR Extension of the FASTA assemblies. Default: .fna.gz --fastq_seperator STR Split FASTQ name on the last occurrence of the separator. Default: _ --fastq_pattern STR Glob pattern to match FASTQs. Default: *.fastq.gz --pe1_pattern STR Designates difference first set of paired-end reads. Default: ([Aa]|[Rr]1) (R1, r1, 1, A, a) --pe2_pattern STR Designates difference second set of paired-end reads. Default: ([Bb]|[Rr]2) (R2, r2, 2, AB b) --assembly_pattern STR Glob pattern to match assembly FASTAs. Default: *.fna.gz -r, --recursive Directories will be traversed recursively --long_reads Single-end reads should be treated as long reads --merge Flag samples with multiple read sets to be merged by Bactopia --version show program's version number and exit Validating FOFN \u00b6 When a FOFN is given, the first thing Bactopia does is verify all FASTQ files are found. If everything checks out, each sample will then be processed, otherwise a list of samples with errors will be output to STDERR. If you would like to only validate your FOFN (and not run the full pipeline), you can use the --check_fastqs parameter. Without Errors \u00b6 N E X T F L O W ~ version 20.01.0 Launching `/home/rpetit3/repos/bactopia/main.nf` [gigantic_meitner] - revision: 6a0fbfbd9c Printing what would have been processed. Each line consists of an array of five elements: [SAMPLE_NAME, RUNTYPE, IS_SINGLE_END, [FASTQ_1, FASTQ_2], EXTRA] Found: [SA103113, assembly, false, [null, null], /example/SA103113.fna.gz] [SA110685, hybrid, false, [/example/SA110685_R1.fastq.gz, /example/SA110685_R2.fastq.gz], /example/SA110685.fastq.gz] [SA123186, paired-end, false, [/example/SA123186_R1.fastq.gz, /example/SA123186_R2.fastq.gz], null] [SA12345, single-end, true, [/example/SA12345.fastq.gz], null] Each sample has passed validation and is put into a three element array: sample - the name for this sample is_single_end - the reads are single-end (true) or paired-end (false) fastq_array - the fastqs associated with the sample This array is then automatically queued up for proccessing by Nextflow. With errors \u00b6 N E X T F L O W ~ version 20.01.0 Launching `/home/rpetit3/repos/bactopia/main.nf` [special_ampere] - revision: 6a0fbfbd9c LINE 4:ERROR: Please verify /example-bad/SA123186_R1.fastq.gz exists, and try again LINE 4:ERROR: Please verify /example-bad/SA123186_R2.fastq.gz exists, and try again LINE 5:ERROR: Please verify /example-bad/SA12345.fastq.gz exists, and try again Sample name \"SA123186\" is not unique, please revise sample names Verify sample names are unique and/or FASTA/FASTQ paths are correct See \"--example_fastqs\" for an example Exiting In the above example, there are multiple errors. Lines 4 and 5 ( LINE 4:ERROR or LINE 5:ERROR ) suggest that based on the given paths the FASTQs do not exist. The sample name SA123186 has been used multiple times, and must be corrected. ENA & SRA \u00b6 There are a lot of publicly avilable sequences available from the European Nucleotide Archive (ENA) and the Sequence Read Archive (SRA). There's a good chance you might want to include some of those sequences in your analysis! If that sounds like you, Bactopia has that built in for you! You can give a single Experiment accession ( --accession ) or a file where each line is a single Experiment accession ( --accessions ). Bactopia will then query ENA to determine Run accession(s) associated with the given Experiment accession and proceed download the corresponding FASTQ files from either the SRA (default) or ENA ( --use_ena ). After the download is completed, it will be processed through Bactopia. Use --accession for a Single Experiment Accession SRA: bactopia --accession SRX476958 ENA: bactopia --accession SRX476958 --use_ena Use --accessions for Multiple Experiment Accessions SRA: bactopia --accessions my-accessions.txt ENA: bactopia --accessions my-accessions.txt --use_ena What happens when an Experiment has multiple Runs? In cases where a single Experiment might have multiple Run accessions associated with it, the FASTQ files from each Run are merged into a single set of sequences. Generating Accession List \u00b6 bactopia search has been made to help assist in generating a list of Experiment accessions to be procesed by Bactopia (via --accessions ). Users can provide a Taxon ID (e.g. 1280), a binary name (e.g. Staphylococcus aureus), a Study accession (e.g. PRJNA480016), a BioSample accession (e.g. SAMN01737350), or a Run accession (e.g. SRR578340). This value is then queried against ENA's Data Warehouse API ), and a list of all Experiment accessions associated with the query is returned. Usage \u00b6 usage: bactopia search [-h] [--exact_taxon] [--outdir OUTPUT_DIRECTORY] [--prefix PREFIX] [--limit INT] [--version] STR bactopia search - Search ENA for associated WGS samples positional arguments: STR Taxon ID or Study, BioSample, or Run accession optional arguments: -h, --help show this help message and exit --exact_taxon Exclude Taxon ID descendents. --outdir OUTPUT_DIRECTORY Directory to write output. (Default: .) --prefix PREFIX Prefix to use for output file names. (Default: ena) --limit INT Maximum number of results to return. (Default: 1000000) --version show program's version number and exit example usage: bactopia search PRJNA480016 --limit 20 bactopia search 1280 --exact_taxon --limit 20' bactopia search \"staphylococcus aureus\" --limit 20 bactopia search SAMN01737350 bactopia search SRR578340 Example \u00b6 bactopia search PRJNA480016 --limit 5 When completed three files are produced: ena-accessions.txt - Contains a list of Experiment accessions to be processed. SRX4563686 SRX4563689 SRX4563687 SRX4563690 SRX4563688 Input for Bactopia This file can be used in conjunction with the --accessions parameter for Bactopia processing. ena-results.txt - Contains the full results of the API query. This includes multiples fields (sample_accession, tax_id, sample_alias, center_name, etc...) ena-summary.txt - Contains a small summary of the completed request QUERY: (study_accession=PRJNA480016 OR secondary_study_accession=PRJNA480016) LIMIT: 5 RESULTS: 5 (./ena-results.txt) ILLUMINA ACCESSIONS: 5 (./ena-accessions.txt) --cleanup_workdir \u00b6 After you run Bactopia, you will notice a directory called work . This directory is where Nextflow runs all the processes and stores the intermediate files. After a process completes successfully, the appropriate results are pulled out and placed in the sample's result folder. The work directory can grow very large very quickly! Please keep this in mind when using Bactopia. To help prevent the build up of the work directory you can use --cleanup_workdir to delete intermediate files after a successful execution of Bactopia. Bactopia and Bactopia Tools use separate work directories Inside the work directory there will be separate subfolders that correspond to a Bactopia run or a specific Bactopia Tool run. This allows you to more easily identify which are ok to delete. The work directory is always ok to delete after a successful run. --cpus \u00b6 At execution, Nextflow creates a queue and the number of slots in the queue is determined by the total number of cores on the system. So if you have a 24-core system, that means Nextflow will have a queue with 24-slots available. This feature kind of makes --cpus a little misleading. Typically when you give --cpus you are saying \"use this amount of cpus\" . But that is not the case for Nextflow and Bactopia. When you use --cpus what you are actually saying is \"for any particular task, use this amount of slots\" . Commands within a task processors will use the amount specified by --cpus . --cpus can have a significant effect on the efficiency of Bactopia So for example if you have a system with 24-cores. This command, bactopia ... --cpus 24 , says for any particular task, use 24 slots . Nextflow will give tasks in Bactopia 24 slots out of 24 available (24-core machine). In other words the queue can one have one task running at once because each task occupies 24 slots. On the other hand, bactopia ... --cpus 4 says for any particular task, use 4 slots . Now, for Nextflow will give each task 4 slots out of 24 slots. Which means 6 tasks can be running at once. This can lead to much better efficiency because less jobs are stuck waiting in line. There are some tasks in Bactopia that will only ever use a single slot because they are single-core tasks. But for example the annotation step will always use the number of slots specified by --cpus . If the --cpus is too high, the annotation will get bogged down, which causes tasks dependent on annotation to also get bogged down. When in doubt --cpus 4 is a safe value. This is also the default value for Bactopia. -qs \u00b6 The -qs parameter is short for queue size . As described above for --cpus , the default value for -qs is set to the total number of cores on the system. This parameter allows you to adjust the maximum number of cores Nextflow can use at any given moment. -qs allows you to play nicely on shared resources From the example above, if you have a system with 24-cores. The default queue size if 24 slots. bactopia ... --cpus 4 says for any particular task, use a maximum of 4 slots . Nextflow will give each task 4 slots out of 24 slots. But there might be other people also using the server. bactopia ... --cpus 4 -qs 12 says for any particular task, use a maximum of 4 slots, but don't use more than 12 slots . Nextflow will give each task 4 slots out of 12 slots. Now instead of using all the cores on the server, the maximum that can be used in 12. -qs might need adjusting for job schedulers. The default value for -qs is set to 100 when using a job scheduler (e.g. SLURM, AWS Batch). There may be times when you need adjust this to meet your needs. For example, if using AWS Batch you might want to increase the value to have more jobs processed at once (e.g. 100 vs 500). --genome_size \u00b6 Throughout the Bactopia workflow a genome size is used for various tasks. By default, a genome size is estimated using Mash. However, users can provide their own value for genome size, use values based on Species Specific Datasets , or completely disable it. Value Result empty Mash is used to estimate the genome size integer Uses the genome size (e.g. --genome_size 2800000 ) provided by the user 0 Read error correct and read subsampling will be disabled. min Requires --species , the minimum completed genome size for a species is used median Requires --species , the median completed genome size for a species is used mean Requires --species , the mean completed genome size for a species is used max Requires --species , the maximum completed genome size for a species is used Mash may not be the most accurate estimate Mash is very convenient to quickly estimate a genome size, but it may not be the most accurate in all cases and will differ between samples. It is recommended that when possible a known genome size or one based off completed genomes should be used. --nfconfig \u00b6 A key feature of Nextflow is you can provide your own config files. What this boils down to you can easily set Bactopia to run on your environment. With --nfconfig you can tell Bactopia to import your config file. --nfconfig has been set up so that it is the last config file to be loaded by Nextflow. This means that if your config file contains variables (e.g. params or profiles) already set they will be overwritten by your values. Nextflow goes into great details on how to create configuration files. Please check the following links for adjustsments you be interested in making. Scope Description env Set any environment variables that might be required params Change the default values of command line arguments process Adjust perprocess configurations such as containers, conda envs, or resource usage profile Create predefined profiles for your Executor There are many other scopes that you might be interested in checking out. You are most like going to want to create a custom profile. By doing so you can specify it at runtime ( -profile myProfile ) and Nextflow will be excuted based on that profile. Often times your custom profile will include information on the executor (queues, allocations, apths, etc...). If you need help please reach out ! If you're using the standard profile (did not specify -profile 'xyz') this might not be necessary. -resume \u00b6 Bactopia relies on Nextflow's Resume Feature to resume runs. You can tell Bactopia to resume by adding -resume to your command line. When -resume is used, Nextflow will review the cache and determine if the previous run is resumable. If the previous run is not resumable, execution will start at the beginning. --keep_all_files \u00b6 In some processes, Bactopia will delete large intermediate files (e.g. multiple uncompressed FASTQs) only after a process successfully completes. Since this a per-process function, it does not affect Nextflow's ability to resume ( -resume )a workflow. You can deactivate this feature using --keep_all_files . Please, keep in mind the work directory is already large, this will make it 2-3 times larger.","title":"Basic Usage"},{"location":"usage-basic/#basic-usage-for-bactopia","text":"Bactopia is a wrapper around many different tools. Each of these tools may (or may not) have there own configurable parameters for you to tweak. In order to facilitate getting started with Bactopia, this section has been limited to discussion of only a few parameters. However, if you are interested in the full list of configurable parameters in Bactopia, please check out the Complete Usage section.","title":"Basic Usage For Bactopia"},{"location":"usage-basic/#usage","text":"Required Parameters: ### For Procesessing Multiple Samples --fastqs STR An input file containing the sample name and absolute paths to FASTQ/FASTAs to process ### For Processing A Single Sample --R1 STR First set of reads for paired end in compressed (gzip) FASTQ format --R2 STR Second set of reads for paired end in compressed (gzip) FASTQ format --SE STR Single end set of reads in compressed (gzip) FASTQ format --hybrid The SE should be treated as long reads for hybrid assembly. --sample STR The name of the input sequences ### For Downloading from SRA/ENA or NCBI Assembly **Note: Assemblies will have error free Illumina reads simulated for processing.** --accessions An input file containing ENA/SRA Experiment accessions or NCBI Assembly accessions to be processed --accession A single ENA/SRA Experiment accession or NCBI Assembly accession to be processed ### For Processing an Assembly **Note: The assembly will have error free Illumina reads simulated for processing.** --assembly STR A assembled genome in compressed FASTA format. --reassemble The simulated reads will be used to create a new assembly. Default: Use the original assembly, do not reassemble Dataset Parameters: --datasets DIR The path to available datasets that have already been set up --species STR Determines which species-specific dataset to use for the input sequencing Optional Parameters: --coverage INT Reduce samples to a given coverage Default: 100x --genome_size INT Expected genome size (bp) for all samples, a value of '0' will disable read error correction and read subsampling. Special values (requires --species): 'min': uses minimum completed genome size of species 'median': uses median completed genome size of species 'mean': uses mean completed genome size of species 'max': uses max completed genome size of species Default: Mash estimate --outdir DIR Directory to write results to Default: . Nextflow Queue Parameters: At execution, Nextflow creates a queue and the number of slots in the queue is determined by the total number of cores on the system. When a task is submitted to the queue, the total number of slots it occupies is determined by the value set by \"--cpus\". This can have a significant effect on the efficiency of the Nextflow's queue system. If \"--cpus\" is set to a value that is equal to the number of cores availabe, in most cases only a single task will be able to run because its occupying all available slots. When in doubt, \"--cpus 4\" is a safe bet, it is also the default value if you don't use \"--cpus\". --max_time INT The maximum number of minutes a single task should run before being halted. Default: 240 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single task. Default: 64 Gb --cpus INT Number of processors made available to a single task. Default: 4 -qs Nextflow queue size. This parameter is very useful to limit the total number of processors used on desktops, laptops or shared resources. Default: Nextflow defaults to the total number of processors on your system. Nextflow Related Parameters: --infodir DIR Directory to write Nextflow summary files to Default: ./bactopia-info --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --nfconfig STR A Nextflow compatible config file for custom profiles. This allows you to create profiles specific to your environment (e.g. SGE, AWS, SLURM, etc...). This config file is loaded last and will overwrite existing variables if set. Default: Bactopia's default configs --nfdir Print directory Nextflow has pulled Bactopia to --overwrite Nextflow will overwrite existing output files. Default: false --conatainerPath Path to Singularity containers to be used by the 'slurm' profile. Default: /opt/bactopia/singularity --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: false -resume Nextflow will attempt to resume a previous run. Please notice it is only a single '-' --cleanup_workdir After Bactopia is successfully executed, the work firectory will be deleted. Warning: by doing this you lose the ability to resume workflows. Useful Parameters: --skip_logs Logs for each process per sample will not be kept. --available_datasets Print a list of available datasets found based on location given by \"--datasets\" --example_fastqs Print example of expected input for FASTQs file --check_fastqs Verify \"--fastqs\" produces the expected inputs --compress Compress (gzip) select outputs (e.g. annotation, variant calls) to reduce overall storage footprint. --keep_all_files Keeps all analysis files created. By default, intermediate files are removed. This will not affect the ability to resume Nextflow runs, and only occurs at the end of the process. --version Print workflow version information --help Show this message and exit --help_all Show a complete list of adjustable parameters","title":"Usage"},{"location":"usage-basic/#inputs","text":"Bactopia has multiple approaches to specify your input sequences. Bactopia can process Illumina FASTQs, assemblies, and long reads for hybrid assembly. Illumina FASTQs a can be your local FASTQs or a Experiment accession to download associated FASTQs from the European Nucleotide Archive (ENA) . Likewise assemblies can be local, or a GenBank/RefSeq accession to download from NCBI Assembly. Input assemblies will have Illumina reads simulated so that the complete Bactopia pipeline run. By default, the assembly will not be reassembled. Which approach really depends on what you need to achieve! The following sections describe methods to process single samples, multiple samples, downloading samples from the ENA.","title":"Inputs"},{"location":"usage-basic/#local","text":"","title":"Local"},{"location":"usage-basic/#single-sample","text":"When you only need to process a single sample at a time, Bactopia allows that! You only have to the sample name ( --sample ) and the whether the read set is paired-end ( --R1 and --R2 ), single-end ( --SE ), Illumina paired-end + long reads ( --hybrid ), or an assembly ( --assembly ). Use --R1, --R2 for Paired-End FASTQs bactopia --sample my-sample --R1 /path/to/my-sample_R1.fastq.gz --R2 /path/to/my-sample_R2.fastq.gz Use --SE for Single-End FASTQs bactopia --sample my-sample --SE /path/to/my-sample.fastq.gz Use --R1, --R2, --SE, and --hybrid for Paired-End FASTQs with Long Reads At the assembly step, Unicycler will be used to create a hybrid assembly using the paired-end reads and the long reads. bactopia --sample my-sample --R1 /path/to/my-sample_R1.fastq.gz \\ --R2 /path/to/my-sample_R2.fastq.gz \\ --SE /path/to/my-sample.fastq.gz \\ --hybrid Use --assembly for an assembled FASTA Assemblies will have 2x250bp Illumina reads simulated without insertions or deletions in the sequence and a minimum PHRED score of Q33. By default, the input assembly will be used for all downstream analyses (e.g. annotation) which use an assembly. If the --reassemble parameter is given, then the a assembly will be created from the simulated reads. bactopia --sample my-sample --assembly /path/to/my-sample.fna.gz","title":"Single Sample"},{"location":"usage-basic/#multiple-samples","text":"For multiple samples, you must create a file with information about the inputs, a file of filenames (FOFN). This file specifies sample names and location of FASTQs/FASTAs to be processed. Using this information, paired-end, single-end, hybrid or assembly information can be extracted as well as naming output files. While this is an additional step for you, the user, it helps to avoid potential pattern matching errors. Most importantly, by taking this approach, you can process hundreds of samples in a single command. There is also the added benefit of knowing which FASTQs were analysed and their location at a later time! Use --fastqs for Multiple Samples bactopia --fastqs my-samples.txt","title":"Multiple Samples"},{"location":"usage-basic/#the-fofn-format","text":"You can use the --example_fastqs to get an example of the expected structure for the input FASTQs FOFN. bactopia --example_fastqs N E X T F L O W ~ version 19.01.0 Launching `/home/rpetit/illumina-cleanup/bin/illumina-cleanup` [naughty_borg] - revision: 0416ba407c Printing example input for \"--fastqs\" sample runtype r1 r2 extra SA103113 assembly /example/SA103113.fna.gz SA110685 hybrid /example/SA110685_R1.fastq.gz /SA110685_R2.fastq.gz /example/SA110685.fastq.gz SA123186 paired-end /example/SA123186_R1.fastq.gz /example/SA123186_R2.fastq.gz SA123456 single-end /example/SA12345.fastq.gz The expected structure is a tab-delimited table with three columns: sample : A unique prefix, or unique name, to be used for naming output files runtype : Informs Bactopia what type of input the sample is r1 : If paired-end, the first pair of reads, else the single-end reads r2 : If paired-end, the second pair of reads extra : Either the assembly or long reads associated with a sample. These five columns are used as the header for the file. In other words, all input FOFNs require their first line to be: sample runtype r1 r2 extra All lines after the header line, contain unique sample names and location(s) to associated FASTQ file(s). Absolute paths should be used to prevent any file not found errors due to the relative path changing. In the example above, four samples would be processed by Bactopia. SA103113 would have simulated reads crreated from the assembly SA110685 would have a hybrid assembly created using the paired-end reads and long-reads SA123186 would be processed as paired-end reads SA123456 would be processed as single-end reads","title":"The FOFN Format"},{"location":"usage-basic/#generating-a-fofn","text":"bactopia prepare has been included to help aid (hopefully!) the process of creating a FOFN for your samples. This script will attempt to find FASTQ files in a given directory and output the expected FOFN format. It will also output any potential issues associated with the pattern matching. Verify accuracy of FOFN This is currently an experimental function. There are likely bugs to be ironed out. Please be sure to give the resulting FOFN a quick look over.","title":"Generating A FOFN"},{"location":"usage-basic/#usage_1","text":"usage: bactopia prepare [-h] [-f STR] [-a STR] [--fastq_seperator STR] [--fastq_pattern STR] [--assembly_pattern STR] [--long_reads] [--version] STR bactopia prepare - Read a directory and prepare a FOFN of FASTQs/FASTAs positional arguments: STR Directory where FASTQ files are stored optional arguments: -h, --help show this help message and exit -f STR, --fastq_ext STR Extension of the FASTQs. Default: .fastq.gz -a STR, --assembly_ext STR Extension of the FASTA assemblies. Default: .fna.gz --fastq_seperator STR Split FASTQ name on the last occurrence of the separator. Default: _ --fastq_pattern STR Glob pattern to match FASTQs. Default: *.fastq.gz --pe1_pattern STR Designates difference first set of paired-end reads. Default: ([Aa]|[Rr]1) (R1, r1, 1, A, a) --pe2_pattern STR Designates difference second set of paired-end reads. Default: ([Bb]|[Rr]2) (R2, r2, 2, AB b) --assembly_pattern STR Glob pattern to match assembly FASTAs. Default: *.fna.gz -r, --recursive Directories will be traversed recursively --long_reads Single-end reads should be treated as long reads --merge Flag samples with multiple read sets to be merged by Bactopia --version show program's version number and exit","title":"Usage"},{"location":"usage-basic/#validating-fofn","text":"When a FOFN is given, the first thing Bactopia does is verify all FASTQ files are found. If everything checks out, each sample will then be processed, otherwise a list of samples with errors will be output to STDERR. If you would like to only validate your FOFN (and not run the full pipeline), you can use the --check_fastqs parameter.","title":"Validating FOFN"},{"location":"usage-basic/#without-errors","text":"N E X T F L O W ~ version 20.01.0 Launching `/home/rpetit3/repos/bactopia/main.nf` [gigantic_meitner] - revision: 6a0fbfbd9c Printing what would have been processed. Each line consists of an array of five elements: [SAMPLE_NAME, RUNTYPE, IS_SINGLE_END, [FASTQ_1, FASTQ_2], EXTRA] Found: [SA103113, assembly, false, [null, null], /example/SA103113.fna.gz] [SA110685, hybrid, false, [/example/SA110685_R1.fastq.gz, /example/SA110685_R2.fastq.gz], /example/SA110685.fastq.gz] [SA123186, paired-end, false, [/example/SA123186_R1.fastq.gz, /example/SA123186_R2.fastq.gz], null] [SA12345, single-end, true, [/example/SA12345.fastq.gz], null] Each sample has passed validation and is put into a three element array: sample - the name for this sample is_single_end - the reads are single-end (true) or paired-end (false) fastq_array - the fastqs associated with the sample This array is then automatically queued up for proccessing by Nextflow.","title":"Without Errors"},{"location":"usage-basic/#with-errors","text":"N E X T F L O W ~ version 20.01.0 Launching `/home/rpetit3/repos/bactopia/main.nf` [special_ampere] - revision: 6a0fbfbd9c LINE 4:ERROR: Please verify /example-bad/SA123186_R1.fastq.gz exists, and try again LINE 4:ERROR: Please verify /example-bad/SA123186_R2.fastq.gz exists, and try again LINE 5:ERROR: Please verify /example-bad/SA12345.fastq.gz exists, and try again Sample name \"SA123186\" is not unique, please revise sample names Verify sample names are unique and/or FASTA/FASTQ paths are correct See \"--example_fastqs\" for an example Exiting In the above example, there are multiple errors. Lines 4 and 5 ( LINE 4:ERROR or LINE 5:ERROR ) suggest that based on the given paths the FASTQs do not exist. The sample name SA123186 has been used multiple times, and must be corrected.","title":"With errors"},{"location":"usage-basic/#ena-sra","text":"There are a lot of publicly avilable sequences available from the European Nucleotide Archive (ENA) and the Sequence Read Archive (SRA). There's a good chance you might want to include some of those sequences in your analysis! If that sounds like you, Bactopia has that built in for you! You can give a single Experiment accession ( --accession ) or a file where each line is a single Experiment accession ( --accessions ). Bactopia will then query ENA to determine Run accession(s) associated with the given Experiment accession and proceed download the corresponding FASTQ files from either the SRA (default) or ENA ( --use_ena ). After the download is completed, it will be processed through Bactopia. Use --accession for a Single Experiment Accession SRA: bactopia --accession SRX476958 ENA: bactopia --accession SRX476958 --use_ena Use --accessions for Multiple Experiment Accessions SRA: bactopia --accessions my-accessions.txt ENA: bactopia --accessions my-accessions.txt --use_ena What happens when an Experiment has multiple Runs? In cases where a single Experiment might have multiple Run accessions associated with it, the FASTQ files from each Run are merged into a single set of sequences.","title":"ENA &amp; SRA"},{"location":"usage-basic/#generating-accession-list","text":"bactopia search has been made to help assist in generating a list of Experiment accessions to be procesed by Bactopia (via --accessions ). Users can provide a Taxon ID (e.g. 1280), a binary name (e.g. Staphylococcus aureus), a Study accession (e.g. PRJNA480016), a BioSample accession (e.g. SAMN01737350), or a Run accession (e.g. SRR578340). This value is then queried against ENA's Data Warehouse API ), and a list of all Experiment accessions associated with the query is returned.","title":"Generating Accession List"},{"location":"usage-basic/#usage_2","text":"usage: bactopia search [-h] [--exact_taxon] [--outdir OUTPUT_DIRECTORY] [--prefix PREFIX] [--limit INT] [--version] STR bactopia search - Search ENA for associated WGS samples positional arguments: STR Taxon ID or Study, BioSample, or Run accession optional arguments: -h, --help show this help message and exit --exact_taxon Exclude Taxon ID descendents. --outdir OUTPUT_DIRECTORY Directory to write output. (Default: .) --prefix PREFIX Prefix to use for output file names. (Default: ena) --limit INT Maximum number of results to return. (Default: 1000000) --version show program's version number and exit example usage: bactopia search PRJNA480016 --limit 20 bactopia search 1280 --exact_taxon --limit 20' bactopia search \"staphylococcus aureus\" --limit 20 bactopia search SAMN01737350 bactopia search SRR578340","title":"Usage"},{"location":"usage-basic/#example","text":"bactopia search PRJNA480016 --limit 5 When completed three files are produced: ena-accessions.txt - Contains a list of Experiment accessions to be processed. SRX4563686 SRX4563689 SRX4563687 SRX4563690 SRX4563688 Input for Bactopia This file can be used in conjunction with the --accessions parameter for Bactopia processing. ena-results.txt - Contains the full results of the API query. This includes multiples fields (sample_accession, tax_id, sample_alias, center_name, etc...) ena-summary.txt - Contains a small summary of the completed request QUERY: (study_accession=PRJNA480016 OR secondary_study_accession=PRJNA480016) LIMIT: 5 RESULTS: 5 (./ena-results.txt) ILLUMINA ACCESSIONS: 5 (./ena-accessions.txt)","title":"Example"},{"location":"usage-basic/#-cleanup_workdir","text":"After you run Bactopia, you will notice a directory called work . This directory is where Nextflow runs all the processes and stores the intermediate files. After a process completes successfully, the appropriate results are pulled out and placed in the sample's result folder. The work directory can grow very large very quickly! Please keep this in mind when using Bactopia. To help prevent the build up of the work directory you can use --cleanup_workdir to delete intermediate files after a successful execution of Bactopia. Bactopia and Bactopia Tools use separate work directories Inside the work directory there will be separate subfolders that correspond to a Bactopia run or a specific Bactopia Tool run. This allows you to more easily identify which are ok to delete. The work directory is always ok to delete after a successful run.","title":"--cleanup_workdir"},{"location":"usage-basic/#-cpus","text":"At execution, Nextflow creates a queue and the number of slots in the queue is determined by the total number of cores on the system. So if you have a 24-core system, that means Nextflow will have a queue with 24-slots available. This feature kind of makes --cpus a little misleading. Typically when you give --cpus you are saying \"use this amount of cpus\" . But that is not the case for Nextflow and Bactopia. When you use --cpus what you are actually saying is \"for any particular task, use this amount of slots\" . Commands within a task processors will use the amount specified by --cpus . --cpus can have a significant effect on the efficiency of Bactopia So for example if you have a system with 24-cores. This command, bactopia ... --cpus 24 , says for any particular task, use 24 slots . Nextflow will give tasks in Bactopia 24 slots out of 24 available (24-core machine). In other words the queue can one have one task running at once because each task occupies 24 slots. On the other hand, bactopia ... --cpus 4 says for any particular task, use 4 slots . Now, for Nextflow will give each task 4 slots out of 24 slots. Which means 6 tasks can be running at once. This can lead to much better efficiency because less jobs are stuck waiting in line. There are some tasks in Bactopia that will only ever use a single slot because they are single-core tasks. But for example the annotation step will always use the number of slots specified by --cpus . If the --cpus is too high, the annotation will get bogged down, which causes tasks dependent on annotation to also get bogged down. When in doubt --cpus 4 is a safe value. This is also the default value for Bactopia.","title":"--cpus"},{"location":"usage-basic/#-qs","text":"The -qs parameter is short for queue size . As described above for --cpus , the default value for -qs is set to the total number of cores on the system. This parameter allows you to adjust the maximum number of cores Nextflow can use at any given moment. -qs allows you to play nicely on shared resources From the example above, if you have a system with 24-cores. The default queue size if 24 slots. bactopia ... --cpus 4 says for any particular task, use a maximum of 4 slots . Nextflow will give each task 4 slots out of 24 slots. But there might be other people also using the server. bactopia ... --cpus 4 -qs 12 says for any particular task, use a maximum of 4 slots, but don't use more than 12 slots . Nextflow will give each task 4 slots out of 12 slots. Now instead of using all the cores on the server, the maximum that can be used in 12. -qs might need adjusting for job schedulers. The default value for -qs is set to 100 when using a job scheduler (e.g. SLURM, AWS Batch). There may be times when you need adjust this to meet your needs. For example, if using AWS Batch you might want to increase the value to have more jobs processed at once (e.g. 100 vs 500).","title":"-qs"},{"location":"usage-basic/#-genome_size","text":"Throughout the Bactopia workflow a genome size is used for various tasks. By default, a genome size is estimated using Mash. However, users can provide their own value for genome size, use values based on Species Specific Datasets , or completely disable it. Value Result empty Mash is used to estimate the genome size integer Uses the genome size (e.g. --genome_size 2800000 ) provided by the user 0 Read error correct and read subsampling will be disabled. min Requires --species , the minimum completed genome size for a species is used median Requires --species , the median completed genome size for a species is used mean Requires --species , the mean completed genome size for a species is used max Requires --species , the maximum completed genome size for a species is used Mash may not be the most accurate estimate Mash is very convenient to quickly estimate a genome size, but it may not be the most accurate in all cases and will differ between samples. It is recommended that when possible a known genome size or one based off completed genomes should be used.","title":"--genome_size"},{"location":"usage-basic/#-nfconfig","text":"A key feature of Nextflow is you can provide your own config files. What this boils down to you can easily set Bactopia to run on your environment. With --nfconfig you can tell Bactopia to import your config file. --nfconfig has been set up so that it is the last config file to be loaded by Nextflow. This means that if your config file contains variables (e.g. params or profiles) already set they will be overwritten by your values. Nextflow goes into great details on how to create configuration files. Please check the following links for adjustsments you be interested in making. Scope Description env Set any environment variables that might be required params Change the default values of command line arguments process Adjust perprocess configurations such as containers, conda envs, or resource usage profile Create predefined profiles for your Executor There are many other scopes that you might be interested in checking out. You are most like going to want to create a custom profile. By doing so you can specify it at runtime ( -profile myProfile ) and Nextflow will be excuted based on that profile. Often times your custom profile will include information on the executor (queues, allocations, apths, etc...). If you need help please reach out ! If you're using the standard profile (did not specify -profile 'xyz') this might not be necessary.","title":"--nfconfig"},{"location":"usage-basic/#-resume","text":"Bactopia relies on Nextflow's Resume Feature to resume runs. You can tell Bactopia to resume by adding -resume to your command line. When -resume is used, Nextflow will review the cache and determine if the previous run is resumable. If the previous run is not resumable, execution will start at the beginning.","title":"-resume"},{"location":"usage-basic/#-keep_all_files","text":"In some processes, Bactopia will delete large intermediate files (e.g. multiple uncompressed FASTQs) only after a process successfully completes. Since this a per-process function, it does not affect Nextflow's ability to resume ( -resume )a workflow. You can deactivate this feature using --keep_all_files . Please, keep in mind the work directory is already large, this will make it 2-3 times larger.","title":"--keep_all_files"},{"location":"usage-complete/","text":"Runtime Parameters \u00b6 Bactopia includes numerous (100+) configurable parameters. Basically for each step of the pipeline, you can modify the default parameters of a specific tool. Required \u00b6 The required parameters depends on how many samples are to be proccessed. You can learn more about which approach to take at Specifying Input FASTQs . ### For Procesessing Multiple Samples --fastqs STR An input file containing the sample name and absolute paths to FASTQ/FASTAs to process ### For Processing A Single Sample --R1 STR First set of reads for paired end in compressed (gzip) FASTQ format --R2 STR Second set of reads for paired end in compressed (gzip) FASTQ format --SE STR Single end set of reads in compressed (gzip) FASTQ format --hybrid The SE should be treated as long reads for hybrid assembly. --sample STR The name of the input sequences ### For Downloading from SRA/ENA or NCBI Assembly **Note: Assemblies will have error free Illumina reads simulated for processing.** --accessions An input file containing ENA/SRA Experiment accessions or NCBI Assembly accessions to be processed --accession A single ENA/SRA Experiment accession or NCBI Assembly accession to be processed ### For Processing an Assembly **Note: The assembly will have error free Illumina reads simulated for processing.** --assembly STR A assembled genome in compressed FASTA format. --reassemble The simulated reads will be used to create a new assembly. Default: Use the original assembly, do not reassemble Dataset \u00b6 If you followed the steps in Build Datasets , you can use the following parameters to point Bactopia to you datasets. --datasets DIR The path to available datasets that have already been set up --species STR Determines which species-specific dataset to use for the input sequencing Optional \u00b6 These optional parameters, while not required, will be quite useful to tweak. --coverage INT Reduce samples to a given coverage Default: 100x --genome_size INT Expected genome size (bp) for all samples, a value of '0' will disable read error correction and read subsampling. Special values (requires --species): 'min': uses minimum completed genome size of species 'median': uses median completed genome size of species 'mean': uses mean completed genome size of species 'max': uses max completed genome size of species Default: Mash estimate --outdir DIR Directory to write results to Default: . --max_time INT The maximum number of minutes a task should run before being halted. Default: 120 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single task. Default: 32 Gb --cpus INT Number of processors made available to a single task. Default: 4 -qs Nextflow queue size. This parameter is very useful to limit the total number of processors used on desktops, laptops or shared resources. Default: Nextflow defaults to the total number of processors on your system. --cpus \u00b6 At execution, Nextflow creates a queue and the number of slots in the queue is determined by the total number of cores on the system. So if you have a 24-core system, that means Nextflow will have a queue with 24-slots available. This feature kind of makes --cpus a little misleading. Typically when you give --cpus you are saying \"use this amount of cpus\" . But that is not the case for Nextflow and Bactopia. When you use --cpus what you are actually saying is \"for any particular task, use this amount of slots\" . Commands within a task processors will use the amount specified by --cpus . --cpus can have a significant effect on the efficiency of Bactopia So for example if you have a system with 24-cores. This command, bactopia ... --cpus 24 , says for any particular task, use 24 slots . Nextflow will give tasks in Bactopia 24 slots out of 24 available (24-core machine). In other words the queue can one have one task running at once because each task occupies 24 slots. On the other hand, bactopia ... --cpus 4 says for any particular task, use 4 slots . Now, for Nextflow will give each task 4 slots out of 24 slots. Which means 6 tasks can be running at once. This can lead to much better efficiency because less jobs are stuck waiting in line. There are some tasks in Bactopia that will only ever use a single slot because they are single-core tasks. But for example the annotation step will always use the number of slots specified by --cpus . If the --cpus is too high, the annotation will get bogged down, which causes tasks dependent on annotation to also get bogged down. When in doubt --cpus 4 is a safe value. This is also the default value for Bactopia. -qs \u00b6 The -qs parameter is short for queue size . As described above for --cpus , the default value for -qs is set to the total number of cores on the system. This parameter allows you to adjust the maximum number of cores Nextflow can use at any given moment. -qs allows you to play nicely on shared resources From the example above, if you have a system with 24-cores. The default queue size if 24 slots. bactopia ... --cpus 4 says for any particular task, use a maximum of 4 slots . Nextflow will give each task 4 slots out of 24 slots. But there might be other people also using the server. bactopia ... --cpus 4 -qs 12 says for any particular task, use a maximum of 4 slots, but don't use more than 12 slots . Nextflow will give each task 4 slots out of 12 slots. Now instead of using all the cores on the server, the maximum that can be used in 12. -qs might need adjusting for job schedulers. The default value for -qs is set to 100 when using a job scheduler (e.g. SLURM, AWS Batch). There may be times when you need adjust this to meet your needs. For example, if using AWS Batch you might want to increase the value to have more jobs processed at once (e.g. 100 vs 500). --genome_size \u00b6 Throughout the Bactopia workflow a genome size is used for various tasks. By default, a genome size is estimated using Mash. However, users can provide their own value for genome size, use values based on Species Specific Datasets , or completely disable it. Value Result empty Mash is used to estimate the genome size integer Uses the genome size (e.g. --genome_size 2800000 ) provided by the user 0 Read error correct and read subsampling will be disabled. min Requires --species , the minimum completed genome size for a species is used median Requires --species , the median completed genome size for a species is used mean Requires --species , the mean completed genome size for a species is used max Requires --species , the maximum completed genome size for a species is used Mash may not be the most accurate estimate Mash is very convenient to quickly estimate a genome size, but it may not be the most accurate in all cases and will differ between samples. It is recommended that when possible a known genome size or one based off completed genomes should be used. Helpers \u00b6 The following parameters are useful to test input parameters. --infodir DIR Directory to write Nextflow summary files to Default: ./bactopia-info --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --nfconfig STR A Nextflow compatible config file for custom profiles. This allows you to create profiles specific to your environment (e.g. SGE, AWS, SLURM, etc...). This config file is loaded last and will overwrite existing variables if set. Default: Bactopia's default configs --nfdir Print directory Nextflow has pulled Bactopia to --overwrite Nextflow will overwrite existing output files. Default: false --conatainerPath Path to Singularity containers to be used by the 'slurm' profile. Default: /opt/bactopia/singularity --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: false -resume Nextflow will attempt to resume a previous run. Please notice it is only a single '-' --cleanup_workdir After Bactopia is successfully executed, the work firectory will be deleted. Warning: by doing this you lose the ability to resume workflows. --skip_logs Logs for each process per sample will not be kept. --available_datasets Print a list of available datasets found based on location given by \"--datasets\" --example_fastqs Print example of expected input for FASTQs file --check_fastqs Verify \"--fastqs\" produces the expected inputs --compress Compress (gzip) select outputs (e.g. annotation, variant calls) to reduce overall storage footprint. --keep_all_files Keeps all analysis files created. By default, intermediate files are removed. This will not affect the ability to resume Nextflow runs, and only occurs at the end of the process. --version Print workflow version information --help Show this message and exit --help_all Show a complete list of adjustable parameters --cleanup_workdir \u00b6 After you run Bactopia, you will notice a directory called work . This directory is where Nextflow runs all the processes and stores the intermediate files. After a process completes successfully, the appropriate results are pulled out and placed in the sample's result folder. The work directory can grow very large very quickly! Please keep this in mind when using Bactopia. To help prevent the build up of the work directory you can use --cleanup_workdir to delete intermediate files after a successful execution of Bactopia. Bactopia and Bactopia Tools use separate work directories Inside the work directory there will be separate subfolders that correspond to a Bactopia run or a specific Bactopia Tool run. This allows you to more easily identify which are ok to delete. The work directory is always ok to delete after a successful run. --nfconfig \u00b6 A key feature of Nextflow is you can provide your own config files. What this boils down to you can easily set Bactopia to run on your environment. With --nfconfig you can tell Bactopia to import your config file. --nfconfig has been set up so that it is the last config file to be loaded by Nextflow. This means that if your config file contains variables (e.g. params or profiles) already set they will be overwritten by your values. Nextflow goes into great details on how to create configuration files. Please check the following links for adjustsments you be interested in making. Scope Description env Set any environment variables that might be required params Change the default values of command line arguments process Adjust perprocess configurations such as containers, conda envs, or resource usage profile Create predefined profiles for your Executor There are many other scopes that you might be interested in checking out. You are most like going to want to create a custom profile. By doing so you can specify it at runtime ( -profile myProfile ) and Nextflow will be excuted based on that profile. Often times your custom profile will include information on the executor (queues, allocations, apths, etc...). If you need help please reach out ! If you're using the standard profile (did not specify -profile 'xyz') this might not be necessary. -resume \u00b6 Bactopia relies on Nextflow's Resume Feature to resume runs. You can tell Bactopia to resume by adding -resume to your command line. When -resume is used, Nextflow will review the cache and determine if the previous run is resumable. If the previous run is not resumable, execution will start at the beginning. --keep_all_files \u00b6 In some processes, Bactopia will delete large intermediate files (e.g. multiple uncompressed FASTQs) only after a process successfully completes. Since this a per-process function, it does not affect Nextflow's ability to resume ( -resume )a workflow. You can deactivate this feature using --keep_all_files . Please, keep in mind the work directory is already large, this will make it 2-3 times larger. Additional Parameters \u00b6 The remaining parameters are associated with specific programs. In the following sections, these parameters are grouped by which Nextflow process they are applicable to. The description and default values for these parameters were taken from the program to which they apply. It is important to note, not all of the available parameters for each and every program are available in Bactopia. If there is a parameter that was overlooked and should probably be included, please make a suggestion! ENA Download Parameters \u00b6 ENA Download Parameters: --max_retry INT Maximum times to retry downloads Default: 10 --use_ena Download FASTQs from ENA with Aspera Connect. Default: Download from SRA --ftp_only If \"--use_ena\" is enabled, FTP will be used to download FASTQs from ENA. --aspera_speed STR Speed at which Aspera Connect will download. Default: 100M --no_cache Don't cache the assembly summary file from ncbi-genome-download FASTQ Minimum Requirements Parameters \u00b6 FASTQ Minimum Requirements Parameters: --min_basepairs INT The minimum amount of input sequenced basepairs required to continue downstream analyses. Default: 2241820 --min_reads INT The minimum amount of input sequenced reads required to continue downstream analyses. Default: 7472 --min_proportion FLOAT The minimum proportion of basepairs for paired-end reads to continue downstream analyses. Example: If set to 0.75 the R1 and R2 must have > 75% proportion of reads (e.g. R1 100bp, R2 75bp, not R1 100bp, R2 50bp) Default: 0.5 --skip_fastq_check The input FASTQs will not be check to verify they meet the minimum requirements to be processed. This parameter is useful if you are confident your sequences will pass the minimum requirements. Estimate Genome Size Parameters \u00b6 Estimate Genome Size Parameters: Only applied if the genome size is estimated. --min_genome_size INT The minimum estimated genome size allowed for the input sequence to continue downstream analyses. Default: 100000 --max_genome_size INT The maximum estimated genome size allowed for the input sequence to continue downstream analyses. Default: 18040666 QC Reads Parameters \u00b6 QC Reads Parameters: --skip_qc The QC step qill be skipped and it will be assumed the inputs sequences have already been QCed. --skip_error_correction FLASH error correction of paired-end reads will be skipped. --qc_ram INT Try to keep RAM usage below this many GB Default: 3 GB --adapters FASTA Illumina adapters to remove Default: BBmap adapters --adapter_k INT Kmer length used for finding adapters. Adapters shorter than k will not be found Default: 23 --phix FASTA phiX174 reference genome to remove Default: NC_001422 --phix_k INT Kmer length used for finding phiX174. Contaminants shorter than k will not be found Default: 31 --ktrim STR Trim reads to remove bases matching reference kmers Values: f (do not trim) r (trim to the right, Default) l (trim to the left) --mink INT Look for shorter kmers at read tips down to this length, when k-trimming or masking. 0 means disabled. Enabling this will disable maskmiddle Default: 11 --hdist INT Maximum Hamming distance for ref kmers (subs only) Memory use is proportional to (3*K)^hdist Default: 1 --tpe BOOL When kmer right-trimming, trim both reads to the minimum length of either Values: f (do not equally trim) t (equally trim to the right, Default) --tbo BOOL Trim adapters based on where paired reads overlap Values: f (do not trim by overlap) t (trim by overlap, Default) --qtrim STR Trim read ends to remove bases with quality below trimq. Performed AFTER looking for kmers Values: rl (trim both ends, Default) f (neither end) r (right end only) l (left end only) w (sliding window) --trimq FLOAT Regions with average quality BELOW this will be trimmed if qtrim is set to something other than f Default: 6 --maq INT Reads with average quality (after trimming) below this will be discarded Default: 10 --minlength INT Reads shorter than this after trimming will be discarded. Pairs will be discarded if both are shorter Default: 35 --ftm INT If positive, right-trim length to be equal to zero, modulo this number Default: 5 --tossjunk Discard reads with invalid characters as bases Values: f (keep all reads) t (toss reads with ambiguous bases, Default) --qout STR Output quality offset Values: 33 (PHRED33 offset quality scores, Default) 64 (PHRED64 offset quality scores) auto (keeps the current input offset) --xmx STR This will be passed to Java to set memory usage Examples: '8g' will specify 8 gigs of RAM (Default) '20g' will specify 20 gigs of RAM '200m' will specify 200 megs of RAM --maxcor INT Max number of corrections within a 20bp window Default: 1 --sampleseed INT Set to a positive number to use as the rng seed for sampling Default: 42 Assembly Parameters \u00b6 Assembly Parameters: Standard Assembly: --shovill_ram INT Try to keep RAM usage below this many GB Default: 8 GB --assembler STR Assembler: megahit velvet skesa spades Default: skesa --min_contig_len INT Minimum contig length <0=AUTO> Default: 500 --min_contig_cov INT Minimum contig coverage <0=AUTO> Default: 2 --contig_namefmt STR Format of contig FASTA IDs in 'printf' style Default: contig%05d --shovill_opts STR Extra assembler options in quotes eg. spades: \"--untrusted-contigs locus.fna\" ... Default: '' --shovill_kmers STR K-mers to use <blank=AUTO> Default: '' --trim Enable adaptor trimming --nostitch Disable read stitching --nocorr Disable post-assembly correction Hybrid Assembly: --unicycler_ram INT Try to keep RAM usage below this many GB Default: 32 GB --unicycler_mode STR Bridging mode used by Unicycler, choices are: conservative = smaller contigs, lowest misassembly rate normal = moderate contig size and misassembly rate (Default) bold = longest contigs, higher misassembly rate --min_polish_size INT Contigs shorter than this value (bp) will not be polished using Pilon Default: 10000 --min_component_size INT Graph components smaller than this size (bp) will be removed from the final graph Default: null --min_dead_end_size INT Graph dead ends smaller than this size (bp) will be removed from the final graph Default: 1000 --no_miniasm Skip miniasm+Racon bridging Default: Produce long-read bridges --no_rotate Do not rotate completed replicons to start at a standard gene --no_pilon Do not use Pilon to polish the final assembly Assembly Quality Control Parameters \u00b6 Assembly Quality Control Parameters: --checkm_unique INT Minimum number of unique phylogenetic markers required to use lineage-specific marker set. Default: 10 --checkm_multi INT Maximum number of multi-copy phylogenetic markers before defaulting to domain-level marker set. Default: 10 --aai_strain FLOAT AAI threshold used to identify strain heterogeneity Default: 0.9 --checkm_length FLOAT Percent overlap between target and query Default: 0.7 --full_tree Use the full tree (requires ~40GB of memory) for determining lineage of each bin. Default: Use reduced tree (<16gb memory) --skip_pseudogene_correction Skip identification and filtering of pseudogene --ignore_thresholds Ignore model-specific score thresholds --checkm_ali Generate HMMER alignment file for each bin --checkm_nt Generate nucleotide gene sequences for each bin --force_domain Use domain-level sets for all bins --no_refinement Do not perform lineage-specific marker set refinement --individual_markers Treat marker as independent (i.e., ignore co-located set structure. --skip_adj_correction Do not exclude adjacent marker genes when estimating contamination --contig_thresholds STR Comma-separated list of contig length thresholds Default: 0,1000,10000,100000,250000,1000000 --plots_format STR Save plots in specified format. Supported formats: emf, eps, pdf, png, ps, raw, rgba, svg, svgz Default: pdf Count 31mers Parameters \u00b6 Count 31mers Parameters: --cortex_ram INT Try to keep RAM usage below this many GB Default: 8 GB --keep_singletons Keep all counted 31-mers Default: Filter out singletons Annotation Parameters \u00b6 Annotation Parameters: --compliant Force Genbank/ENA/DDJB compliance: --genes --mincontiglen 500 --centre 'Bactopia' Default: false --centre STR Sequencing centre ID Default: 'Bactopia' --addmrna Add 'mRNA' features for each 'CDS' feature --rawproduct Do not clean up /product annotation --cdsrnaolap Allow [tr]RNA to overlap CDS --prokka_evalue STR Similarity e-value cut-off Default: 1e-09 --prokka_coverage INT Minimum coverage on query protein Default: 80 --nogenes Do not add 'gene' features for each 'CDS' feature --norrna Don't run rRNA search --notrna Don't run tRNA search --rnammer Prefer RNAmmer over Barrnap for rRNA prediction --rfam Enable searching for ncRNAs with Infernal+Rfam --skip_prodigal_tf If a Prodigal training file was found, it will not be used Minmer Sketch Parameters \u00b6 Minmer Sketch Parameters: --mash_sketch INT Sketch size. Each sketch will have at most this many non-redundant min-hashes. Default: 10000 --sourmash_scale INT Choose number of hashes as 1 in FRACTION of input k-mers Default: 10000 Minmer Query Parameters \u00b6 Minmer Query Parameters: --minmer_ram INT Try to keep RAM usage below this many GB Default: 5 GB --screen_w Winner-takes-all strategy for identity estimates. After counting hashes for each query, hashes that appear in multiple queries will be removed from all except the one with the best identity (ties broken by larger query), and other identities will be reduced. This removes output redundancy, providing a rough compositional outline. Default: True --screen_i FLOAT Minimum identity to report. Inclusive unless set to zero, in which case only identities greater than zero (i.e. with at least one shared hash) will be reported. Set to -1 to output everything. Default: 0.8 Ariba Parameters \u00b6 Ariba Parameters: --nucmer_min_id INT Minimum alignment identity (delta-filter -i) Default: 90 --nucmer_min_len INT Minimum alignment length (delta-filter -i) Default: 20 --nucmer_breaklen INT Value to use for -breaklen when running nucmer Default: 200 --assembly_cov INT Target read coverage when sampling reads for assembly Default: 50 --min_scaff_depth INT Minimum number of read pairs needed as evidence for scaffold link between two contigs Default: 10 --spades_options STR Extra options to pass to Spades assembler Default: null --assembled_threshold FLOAT (between 0 and 1) If proportion of gene assembled (regardless of into how many contigs) is at least this value then the flag gene_assembled is set Default: 0.95 --gene_nt_extend INT Max number of nucleotides to extend ends of gene matches to look for start/stop codons Default: 30 --unique_threshold FLOAT (between 0 and 1) If proportion of bases in gene assembled more than once is <= this value, then the flag unique_contig is set Default: 0.03 --ariba_no_clean Do not clean up intermediate files created by Ariba. By default, the local assemblies are deleted. Call Variant Parameters \u00b6 Call Variant Parameters: --snippy_ram INT Try and keep RAM under this many GB Default: 4 GB --mapqual INT Minimum read mapping quality to consider Default: 60 --basequal INT Minimum base quality to consider Default: 13 --mincov INT Minimum site depth to for calling alleles Default: 10 --minfrac FLOAT Minimum proportion for variant evidence (0=AUTO) Default: 0 --minqual INT Minimum QUALITY in VCF column 6 Default: 100 --maxsoft INT Maximum soft clipping to allow Default: 10 --bwaopt STR Extra BWA MEM options, eg. -x pacbio Default: '' --fbopt STR Extra Freebayes options, eg. --theta 1E-6 --read-snp-limit 2 Default: '' Nearest Neighbor Reference Genomes \u00b6 Nearest Neighbor Reference Genomes: --max_references INT Maximum number of nearest neighbor reference genomes to download for variant calling. Default: 1 --random_tie_break On references with matching distances, randomly select one. Default: Pick earliest accession number --disable_auto_variants Disable automatic selection of reference genome based on Mash distances. BLAST Parameters \u00b6 BLAST Parameters: --perc_identity INT Percent identity Default: 50 --qcov_hsp_perc INT Percent query coverage per hsp Default: 50 --max_target_seqs INT Maximum number of aligned sequences to keep Default: 2000 Mapping Parameters \u00b6 Mapping Parameters: --keep_unmapped_reads Keep unmapped reads, this does not affect variant calling. --bwa_mem_opts STR Extra BWA MEM options Default: '' --bwa_aln_opts STR Extra BWA ALN options Default: '' --bwa_samse_opts STR Extra BWA SAMSE options Default: '' --bwa_sampe_opts STR Extra BWA SAMPE options Default: '' --bwa_n INT Maximum number of alignments to output in the XA tag for reads paired properly. If a read has more than INT hits, the XA tag will not be written. Default: 9999 Antimicrobial Resistance Parameters \u00b6 Antimicrobial Resistance Parameters: --update_amr Force amrfinder to update its database. --amr_ident_min Minimum identity for nucleotide hit (0..1). -1 means use a curated threshold if it exists and 0.9 otherwise Default: -1 --amr_coverage_min Minimum coverage of the reference protein (0..1) Default: 0.5 --amr_organism Taxonomy group: Campylobacter, Escherichia, Klebsiella Salmonella, Staphylococcus, Vibrio Default: '' --amr_translation_table NCBI genetic code for translated BLAST Default: 11 --amr_plus Add the plus genes to the report --amr_report_common Suppress proteins common to a taxonomy group","title":"Complete Usage"},{"location":"usage-complete/#runtime-parameters","text":"Bactopia includes numerous (100+) configurable parameters. Basically for each step of the pipeline, you can modify the default parameters of a specific tool.","title":"Runtime Parameters"},{"location":"usage-complete/#required","text":"The required parameters depends on how many samples are to be proccessed. You can learn more about which approach to take at Specifying Input FASTQs . ### For Procesessing Multiple Samples --fastqs STR An input file containing the sample name and absolute paths to FASTQ/FASTAs to process ### For Processing A Single Sample --R1 STR First set of reads for paired end in compressed (gzip) FASTQ format --R2 STR Second set of reads for paired end in compressed (gzip) FASTQ format --SE STR Single end set of reads in compressed (gzip) FASTQ format --hybrid The SE should be treated as long reads for hybrid assembly. --sample STR The name of the input sequences ### For Downloading from SRA/ENA or NCBI Assembly **Note: Assemblies will have error free Illumina reads simulated for processing.** --accessions An input file containing ENA/SRA Experiment accessions or NCBI Assembly accessions to be processed --accession A single ENA/SRA Experiment accession or NCBI Assembly accession to be processed ### For Processing an Assembly **Note: The assembly will have error free Illumina reads simulated for processing.** --assembly STR A assembled genome in compressed FASTA format. --reassemble The simulated reads will be used to create a new assembly. Default: Use the original assembly, do not reassemble","title":"Required"},{"location":"usage-complete/#dataset","text":"If you followed the steps in Build Datasets , you can use the following parameters to point Bactopia to you datasets. --datasets DIR The path to available datasets that have already been set up --species STR Determines which species-specific dataset to use for the input sequencing","title":"Dataset"},{"location":"usage-complete/#optional","text":"These optional parameters, while not required, will be quite useful to tweak. --coverage INT Reduce samples to a given coverage Default: 100x --genome_size INT Expected genome size (bp) for all samples, a value of '0' will disable read error correction and read subsampling. Special values (requires --species): 'min': uses minimum completed genome size of species 'median': uses median completed genome size of species 'mean': uses mean completed genome size of species 'max': uses max completed genome size of species Default: Mash estimate --outdir DIR Directory to write results to Default: . --max_time INT The maximum number of minutes a task should run before being halted. Default: 120 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single task. Default: 32 Gb --cpus INT Number of processors made available to a single task. Default: 4 -qs Nextflow queue size. This parameter is very useful to limit the total number of processors used on desktops, laptops or shared resources. Default: Nextflow defaults to the total number of processors on your system.","title":"Optional"},{"location":"usage-complete/#-cpus","text":"At execution, Nextflow creates a queue and the number of slots in the queue is determined by the total number of cores on the system. So if you have a 24-core system, that means Nextflow will have a queue with 24-slots available. This feature kind of makes --cpus a little misleading. Typically when you give --cpus you are saying \"use this amount of cpus\" . But that is not the case for Nextflow and Bactopia. When you use --cpus what you are actually saying is \"for any particular task, use this amount of slots\" . Commands within a task processors will use the amount specified by --cpus . --cpus can have a significant effect on the efficiency of Bactopia So for example if you have a system with 24-cores. This command, bactopia ... --cpus 24 , says for any particular task, use 24 slots . Nextflow will give tasks in Bactopia 24 slots out of 24 available (24-core machine). In other words the queue can one have one task running at once because each task occupies 24 slots. On the other hand, bactopia ... --cpus 4 says for any particular task, use 4 slots . Now, for Nextflow will give each task 4 slots out of 24 slots. Which means 6 tasks can be running at once. This can lead to much better efficiency because less jobs are stuck waiting in line. There are some tasks in Bactopia that will only ever use a single slot because they are single-core tasks. But for example the annotation step will always use the number of slots specified by --cpus . If the --cpus is too high, the annotation will get bogged down, which causes tasks dependent on annotation to also get bogged down. When in doubt --cpus 4 is a safe value. This is also the default value for Bactopia.","title":"--cpus"},{"location":"usage-complete/#-qs","text":"The -qs parameter is short for queue size . As described above for --cpus , the default value for -qs is set to the total number of cores on the system. This parameter allows you to adjust the maximum number of cores Nextflow can use at any given moment. -qs allows you to play nicely on shared resources From the example above, if you have a system with 24-cores. The default queue size if 24 slots. bactopia ... --cpus 4 says for any particular task, use a maximum of 4 slots . Nextflow will give each task 4 slots out of 24 slots. But there might be other people also using the server. bactopia ... --cpus 4 -qs 12 says for any particular task, use a maximum of 4 slots, but don't use more than 12 slots . Nextflow will give each task 4 slots out of 12 slots. Now instead of using all the cores on the server, the maximum that can be used in 12. -qs might need adjusting for job schedulers. The default value for -qs is set to 100 when using a job scheduler (e.g. SLURM, AWS Batch). There may be times when you need adjust this to meet your needs. For example, if using AWS Batch you might want to increase the value to have more jobs processed at once (e.g. 100 vs 500).","title":"-qs"},{"location":"usage-complete/#-genome_size","text":"Throughout the Bactopia workflow a genome size is used for various tasks. By default, a genome size is estimated using Mash. However, users can provide their own value for genome size, use values based on Species Specific Datasets , or completely disable it. Value Result empty Mash is used to estimate the genome size integer Uses the genome size (e.g. --genome_size 2800000 ) provided by the user 0 Read error correct and read subsampling will be disabled. min Requires --species , the minimum completed genome size for a species is used median Requires --species , the median completed genome size for a species is used mean Requires --species , the mean completed genome size for a species is used max Requires --species , the maximum completed genome size for a species is used Mash may not be the most accurate estimate Mash is very convenient to quickly estimate a genome size, but it may not be the most accurate in all cases and will differ between samples. It is recommended that when possible a known genome size or one based off completed genomes should be used.","title":"--genome_size"},{"location":"usage-complete/#helpers","text":"The following parameters are useful to test input parameters. --infodir DIR Directory to write Nextflow summary files to Default: ./bactopia-info --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --nfconfig STR A Nextflow compatible config file for custom profiles. This allows you to create profiles specific to your environment (e.g. SGE, AWS, SLURM, etc...). This config file is loaded last and will overwrite existing variables if set. Default: Bactopia's default configs --nfdir Print directory Nextflow has pulled Bactopia to --overwrite Nextflow will overwrite existing output files. Default: false --conatainerPath Path to Singularity containers to be used by the 'slurm' profile. Default: /opt/bactopia/singularity --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: false -resume Nextflow will attempt to resume a previous run. Please notice it is only a single '-' --cleanup_workdir After Bactopia is successfully executed, the work firectory will be deleted. Warning: by doing this you lose the ability to resume workflows. --skip_logs Logs for each process per sample will not be kept. --available_datasets Print a list of available datasets found based on location given by \"--datasets\" --example_fastqs Print example of expected input for FASTQs file --check_fastqs Verify \"--fastqs\" produces the expected inputs --compress Compress (gzip) select outputs (e.g. annotation, variant calls) to reduce overall storage footprint. --keep_all_files Keeps all analysis files created. By default, intermediate files are removed. This will not affect the ability to resume Nextflow runs, and only occurs at the end of the process. --version Print workflow version information --help Show this message and exit --help_all Show a complete list of adjustable parameters","title":"Helpers"},{"location":"usage-complete/#-cleanup_workdir","text":"After you run Bactopia, you will notice a directory called work . This directory is where Nextflow runs all the processes and stores the intermediate files. After a process completes successfully, the appropriate results are pulled out and placed in the sample's result folder. The work directory can grow very large very quickly! Please keep this in mind when using Bactopia. To help prevent the build up of the work directory you can use --cleanup_workdir to delete intermediate files after a successful execution of Bactopia. Bactopia and Bactopia Tools use separate work directories Inside the work directory there will be separate subfolders that correspond to a Bactopia run or a specific Bactopia Tool run. This allows you to more easily identify which are ok to delete. The work directory is always ok to delete after a successful run.","title":"--cleanup_workdir"},{"location":"usage-complete/#-nfconfig","text":"A key feature of Nextflow is you can provide your own config files. What this boils down to you can easily set Bactopia to run on your environment. With --nfconfig you can tell Bactopia to import your config file. --nfconfig has been set up so that it is the last config file to be loaded by Nextflow. This means that if your config file contains variables (e.g. params or profiles) already set they will be overwritten by your values. Nextflow goes into great details on how to create configuration files. Please check the following links for adjustsments you be interested in making. Scope Description env Set any environment variables that might be required params Change the default values of command line arguments process Adjust perprocess configurations such as containers, conda envs, or resource usage profile Create predefined profiles for your Executor There are many other scopes that you might be interested in checking out. You are most like going to want to create a custom profile. By doing so you can specify it at runtime ( -profile myProfile ) and Nextflow will be excuted based on that profile. Often times your custom profile will include information on the executor (queues, allocations, apths, etc...). If you need help please reach out ! If you're using the standard profile (did not specify -profile 'xyz') this might not be necessary.","title":"--nfconfig"},{"location":"usage-complete/#-resume","text":"Bactopia relies on Nextflow's Resume Feature to resume runs. You can tell Bactopia to resume by adding -resume to your command line. When -resume is used, Nextflow will review the cache and determine if the previous run is resumable. If the previous run is not resumable, execution will start at the beginning.","title":"-resume"},{"location":"usage-complete/#-keep_all_files","text":"In some processes, Bactopia will delete large intermediate files (e.g. multiple uncompressed FASTQs) only after a process successfully completes. Since this a per-process function, it does not affect Nextflow's ability to resume ( -resume )a workflow. You can deactivate this feature using --keep_all_files . Please, keep in mind the work directory is already large, this will make it 2-3 times larger.","title":"--keep_all_files"},{"location":"usage-complete/#additional-parameters","text":"The remaining parameters are associated with specific programs. In the following sections, these parameters are grouped by which Nextflow process they are applicable to. The description and default values for these parameters were taken from the program to which they apply. It is important to note, not all of the available parameters for each and every program are available in Bactopia. If there is a parameter that was overlooked and should probably be included, please make a suggestion!","title":"Additional Parameters"},{"location":"usage-complete/#ena-download-parameters","text":"ENA Download Parameters: --max_retry INT Maximum times to retry downloads Default: 10 --use_ena Download FASTQs from ENA with Aspera Connect. Default: Download from SRA --ftp_only If \"--use_ena\" is enabled, FTP will be used to download FASTQs from ENA. --aspera_speed STR Speed at which Aspera Connect will download. Default: 100M --no_cache Don't cache the assembly summary file from ncbi-genome-download","title":"ENA Download Parameters"},{"location":"usage-complete/#fastq-minimum-requirements-parameters","text":"FASTQ Minimum Requirements Parameters: --min_basepairs INT The minimum amount of input sequenced basepairs required to continue downstream analyses. Default: 2241820 --min_reads INT The minimum amount of input sequenced reads required to continue downstream analyses. Default: 7472 --min_proportion FLOAT The minimum proportion of basepairs for paired-end reads to continue downstream analyses. Example: If set to 0.75 the R1 and R2 must have > 75% proportion of reads (e.g. R1 100bp, R2 75bp, not R1 100bp, R2 50bp) Default: 0.5 --skip_fastq_check The input FASTQs will not be check to verify they meet the minimum requirements to be processed. This parameter is useful if you are confident your sequences will pass the minimum requirements.","title":"FASTQ Minimum Requirements Parameters"},{"location":"usage-complete/#estimate-genome-size-parameters","text":"Estimate Genome Size Parameters: Only applied if the genome size is estimated. --min_genome_size INT The minimum estimated genome size allowed for the input sequence to continue downstream analyses. Default: 100000 --max_genome_size INT The maximum estimated genome size allowed for the input sequence to continue downstream analyses. Default: 18040666","title":"Estimate Genome Size Parameters"},{"location":"usage-complete/#qc-reads-parameters","text":"QC Reads Parameters: --skip_qc The QC step qill be skipped and it will be assumed the inputs sequences have already been QCed. --skip_error_correction FLASH error correction of paired-end reads will be skipped. --qc_ram INT Try to keep RAM usage below this many GB Default: 3 GB --adapters FASTA Illumina adapters to remove Default: BBmap adapters --adapter_k INT Kmer length used for finding adapters. Adapters shorter than k will not be found Default: 23 --phix FASTA phiX174 reference genome to remove Default: NC_001422 --phix_k INT Kmer length used for finding phiX174. Contaminants shorter than k will not be found Default: 31 --ktrim STR Trim reads to remove bases matching reference kmers Values: f (do not trim) r (trim to the right, Default) l (trim to the left) --mink INT Look for shorter kmers at read tips down to this length, when k-trimming or masking. 0 means disabled. Enabling this will disable maskmiddle Default: 11 --hdist INT Maximum Hamming distance for ref kmers (subs only) Memory use is proportional to (3*K)^hdist Default: 1 --tpe BOOL When kmer right-trimming, trim both reads to the minimum length of either Values: f (do not equally trim) t (equally trim to the right, Default) --tbo BOOL Trim adapters based on where paired reads overlap Values: f (do not trim by overlap) t (trim by overlap, Default) --qtrim STR Trim read ends to remove bases with quality below trimq. Performed AFTER looking for kmers Values: rl (trim both ends, Default) f (neither end) r (right end only) l (left end only) w (sliding window) --trimq FLOAT Regions with average quality BELOW this will be trimmed if qtrim is set to something other than f Default: 6 --maq INT Reads with average quality (after trimming) below this will be discarded Default: 10 --minlength INT Reads shorter than this after trimming will be discarded. Pairs will be discarded if both are shorter Default: 35 --ftm INT If positive, right-trim length to be equal to zero, modulo this number Default: 5 --tossjunk Discard reads with invalid characters as bases Values: f (keep all reads) t (toss reads with ambiguous bases, Default) --qout STR Output quality offset Values: 33 (PHRED33 offset quality scores, Default) 64 (PHRED64 offset quality scores) auto (keeps the current input offset) --xmx STR This will be passed to Java to set memory usage Examples: '8g' will specify 8 gigs of RAM (Default) '20g' will specify 20 gigs of RAM '200m' will specify 200 megs of RAM --maxcor INT Max number of corrections within a 20bp window Default: 1 --sampleseed INT Set to a positive number to use as the rng seed for sampling Default: 42","title":"QC Reads Parameters"},{"location":"usage-complete/#assembly-parameters","text":"Assembly Parameters: Standard Assembly: --shovill_ram INT Try to keep RAM usage below this many GB Default: 8 GB --assembler STR Assembler: megahit velvet skesa spades Default: skesa --min_contig_len INT Minimum contig length <0=AUTO> Default: 500 --min_contig_cov INT Minimum contig coverage <0=AUTO> Default: 2 --contig_namefmt STR Format of contig FASTA IDs in 'printf' style Default: contig%05d --shovill_opts STR Extra assembler options in quotes eg. spades: \"--untrusted-contigs locus.fna\" ... Default: '' --shovill_kmers STR K-mers to use <blank=AUTO> Default: '' --trim Enable adaptor trimming --nostitch Disable read stitching --nocorr Disable post-assembly correction Hybrid Assembly: --unicycler_ram INT Try to keep RAM usage below this many GB Default: 32 GB --unicycler_mode STR Bridging mode used by Unicycler, choices are: conservative = smaller contigs, lowest misassembly rate normal = moderate contig size and misassembly rate (Default) bold = longest contigs, higher misassembly rate --min_polish_size INT Contigs shorter than this value (bp) will not be polished using Pilon Default: 10000 --min_component_size INT Graph components smaller than this size (bp) will be removed from the final graph Default: null --min_dead_end_size INT Graph dead ends smaller than this size (bp) will be removed from the final graph Default: 1000 --no_miniasm Skip miniasm+Racon bridging Default: Produce long-read bridges --no_rotate Do not rotate completed replicons to start at a standard gene --no_pilon Do not use Pilon to polish the final assembly","title":"Assembly Parameters"},{"location":"usage-complete/#assembly-quality-control-parameters","text":"Assembly Quality Control Parameters: --checkm_unique INT Minimum number of unique phylogenetic markers required to use lineage-specific marker set. Default: 10 --checkm_multi INT Maximum number of multi-copy phylogenetic markers before defaulting to domain-level marker set. Default: 10 --aai_strain FLOAT AAI threshold used to identify strain heterogeneity Default: 0.9 --checkm_length FLOAT Percent overlap between target and query Default: 0.7 --full_tree Use the full tree (requires ~40GB of memory) for determining lineage of each bin. Default: Use reduced tree (<16gb memory) --skip_pseudogene_correction Skip identification and filtering of pseudogene --ignore_thresholds Ignore model-specific score thresholds --checkm_ali Generate HMMER alignment file for each bin --checkm_nt Generate nucleotide gene sequences for each bin --force_domain Use domain-level sets for all bins --no_refinement Do not perform lineage-specific marker set refinement --individual_markers Treat marker as independent (i.e., ignore co-located set structure. --skip_adj_correction Do not exclude adjacent marker genes when estimating contamination --contig_thresholds STR Comma-separated list of contig length thresholds Default: 0,1000,10000,100000,250000,1000000 --plots_format STR Save plots in specified format. Supported formats: emf, eps, pdf, png, ps, raw, rgba, svg, svgz Default: pdf","title":"Assembly Quality Control Parameters"},{"location":"usage-complete/#count-31mers-parameters","text":"Count 31mers Parameters: --cortex_ram INT Try to keep RAM usage below this many GB Default: 8 GB --keep_singletons Keep all counted 31-mers Default: Filter out singletons","title":"Count 31mers Parameters"},{"location":"usage-complete/#annotation-parameters","text":"Annotation Parameters: --compliant Force Genbank/ENA/DDJB compliance: --genes --mincontiglen 500 --centre 'Bactopia' Default: false --centre STR Sequencing centre ID Default: 'Bactopia' --addmrna Add 'mRNA' features for each 'CDS' feature --rawproduct Do not clean up /product annotation --cdsrnaolap Allow [tr]RNA to overlap CDS --prokka_evalue STR Similarity e-value cut-off Default: 1e-09 --prokka_coverage INT Minimum coverage on query protein Default: 80 --nogenes Do not add 'gene' features for each 'CDS' feature --norrna Don't run rRNA search --notrna Don't run tRNA search --rnammer Prefer RNAmmer over Barrnap for rRNA prediction --rfam Enable searching for ncRNAs with Infernal+Rfam --skip_prodigal_tf If a Prodigal training file was found, it will not be used","title":"Annotation Parameters"},{"location":"usage-complete/#minmer-sketch-parameters","text":"Minmer Sketch Parameters: --mash_sketch INT Sketch size. Each sketch will have at most this many non-redundant min-hashes. Default: 10000 --sourmash_scale INT Choose number of hashes as 1 in FRACTION of input k-mers Default: 10000","title":"Minmer Sketch Parameters"},{"location":"usage-complete/#minmer-query-parameters","text":"Minmer Query Parameters: --minmer_ram INT Try to keep RAM usage below this many GB Default: 5 GB --screen_w Winner-takes-all strategy for identity estimates. After counting hashes for each query, hashes that appear in multiple queries will be removed from all except the one with the best identity (ties broken by larger query), and other identities will be reduced. This removes output redundancy, providing a rough compositional outline. Default: True --screen_i FLOAT Minimum identity to report. Inclusive unless set to zero, in which case only identities greater than zero (i.e. with at least one shared hash) will be reported. Set to -1 to output everything. Default: 0.8","title":"Minmer Query Parameters"},{"location":"usage-complete/#ariba-parameters","text":"Ariba Parameters: --nucmer_min_id INT Minimum alignment identity (delta-filter -i) Default: 90 --nucmer_min_len INT Minimum alignment length (delta-filter -i) Default: 20 --nucmer_breaklen INT Value to use for -breaklen when running nucmer Default: 200 --assembly_cov INT Target read coverage when sampling reads for assembly Default: 50 --min_scaff_depth INT Minimum number of read pairs needed as evidence for scaffold link between two contigs Default: 10 --spades_options STR Extra options to pass to Spades assembler Default: null --assembled_threshold FLOAT (between 0 and 1) If proportion of gene assembled (regardless of into how many contigs) is at least this value then the flag gene_assembled is set Default: 0.95 --gene_nt_extend INT Max number of nucleotides to extend ends of gene matches to look for start/stop codons Default: 30 --unique_threshold FLOAT (between 0 and 1) If proportion of bases in gene assembled more than once is <= this value, then the flag unique_contig is set Default: 0.03 --ariba_no_clean Do not clean up intermediate files created by Ariba. By default, the local assemblies are deleted.","title":"Ariba Parameters"},{"location":"usage-complete/#call-variant-parameters","text":"Call Variant Parameters: --snippy_ram INT Try and keep RAM under this many GB Default: 4 GB --mapqual INT Minimum read mapping quality to consider Default: 60 --basequal INT Minimum base quality to consider Default: 13 --mincov INT Minimum site depth to for calling alleles Default: 10 --minfrac FLOAT Minimum proportion for variant evidence (0=AUTO) Default: 0 --minqual INT Minimum QUALITY in VCF column 6 Default: 100 --maxsoft INT Maximum soft clipping to allow Default: 10 --bwaopt STR Extra BWA MEM options, eg. -x pacbio Default: '' --fbopt STR Extra Freebayes options, eg. --theta 1E-6 --read-snp-limit 2 Default: ''","title":"Call Variant Parameters"},{"location":"usage-complete/#nearest-neighbor-reference-genomes","text":"Nearest Neighbor Reference Genomes: --max_references INT Maximum number of nearest neighbor reference genomes to download for variant calling. Default: 1 --random_tie_break On references with matching distances, randomly select one. Default: Pick earliest accession number --disable_auto_variants Disable automatic selection of reference genome based on Mash distances.","title":"Nearest Neighbor Reference Genomes"},{"location":"usage-complete/#blast-parameters","text":"BLAST Parameters: --perc_identity INT Percent identity Default: 50 --qcov_hsp_perc INT Percent query coverage per hsp Default: 50 --max_target_seqs INT Maximum number of aligned sequences to keep Default: 2000","title":"BLAST Parameters"},{"location":"usage-complete/#mapping-parameters","text":"Mapping Parameters: --keep_unmapped_reads Keep unmapped reads, this does not affect variant calling. --bwa_mem_opts STR Extra BWA MEM options Default: '' --bwa_aln_opts STR Extra BWA ALN options Default: '' --bwa_samse_opts STR Extra BWA SAMSE options Default: '' --bwa_sampe_opts STR Extra BWA SAMPE options Default: '' --bwa_n INT Maximum number of alignments to output in the XA tag for reads paired properly. If a read has more than INT hits, the XA tag will not be written. Default: 9999","title":"Mapping Parameters"},{"location":"usage-complete/#antimicrobial-resistance-parameters","text":"Antimicrobial Resistance Parameters: --update_amr Force amrfinder to update its database. --amr_ident_min Minimum identity for nucleotide hit (0..1). -1 means use a curated threshold if it exists and 0.9 otherwise Default: -1 --amr_coverage_min Minimum coverage of the reference protein (0..1) Default: 0.5 --amr_organism Taxonomy group: Campylobacter, Escherichia, Klebsiella Salmonella, Staphylococcus, Vibrio Default: '' --amr_translation_table NCBI genetic code for translated BLAST Default: 11 --amr_plus Add the plus genes to the report --amr_report_common Suppress proteins common to a taxonomy group","title":"Antimicrobial Resistance Parameters"},{"location":"workflow-overview/","text":"Workflow Overview \u00b6 Bactopia is an extensive workflow integrating numerous steps in bacterial genome analysis. Through out the workflow there are steps that are always enabled and dataset enabled . Each of the steps depicted in the image below are described in this section. A list of software directly used in each step is also listed. Please check out the Acknowledgements section to get the full list of software as well how to download and cite said software. Always Enabled Steps \u00b6 The Always Enabled Steps are always executed by Bactopia. These steps do not depend of external datasets and thus are always enabled. Gather FASTQs \u00b6 Specifies exactly where the input FASTQ/FASTAs are coming from. If you are using local inputs (e.g. --R1/--R2 , --fastqs ) it will verify they can be accessed. If an accession(s) ( --accession or --accessions ) was given, the corresponding FASTQs (SRA/ENA) or assemblies (NCBI Assembly) are downloaded in this step. All assemblies will have 2x250bp Illumina reads simulated withour insertions or deletions and a minimum PHRED score of Q33. Software Usage ART Generate simulated Illumina reads from an assembly ena-dl Download FASTQ files from ENA ncbi-genome-download Download GenBank/RefSeq assemblies from NCBI Assembly database Validate FASTQs \u00b6 Determines if the FASTQ file contains enough sequencing to continue processing. The --min_reads and --min_basepairs parameters adjust the minimum amount of sequencing required to continue processing. This step does not directly test the validity of the FASTQ format (although, it would fail if the format is invalid!). Software Usage fastq-scan Determine total read and basepairs of FASTQ Original Summary \u00b6 Produces summary statistics (read lengths, quality scores, etc...) based on the original input FASTQs. Software Usage FastQC Generates a HTML report of original FASTQ summary statistics fastq-scan Generates original FASTQ summary statistics in JSON format Genome Size \u00b6 The genome size is by various programs in the Bactopia workflow. By default, if no genome size is given one is estimated using Mash. Otherwise, a specific genome size can be specified or completely disabled using the --genome_size parameter. See Genome Size Parameter to learn more about specifying the genome size. Software Usage Mash If not given, estimates genome size of sample Quality Control \u00b6 The input FASTQs go through a few clean up steps. First, Illumina related adapters and phiX contaminants are removed. Then reads that fail to pass length and/or quality requirements are filtered out. If the genome size is available, sequence error-corrections are made and the total sequencing is reduced to a specified coverage. After this step, all downstream analyses are based on the QC'd FASTQ and the original is no longer used. Software Description BBTools Removes Illumina adapters, phiX contaminants, filters reads based on length and quality score, and reduces inputs to a specified coverage. Lighter Corrects sequencing errors QC Summary \u00b6 Produces summary statistics (read lengths, quality scores, etc...) based on the final set of QC'd FASTQs. Software Usage FastQC Generates a HTML report of QC'd FASTQ summary statistics fastq-scan Generates QC'd FASTQ summary statistics in JSON format Count 31-mers \u00b6 All 31 basepair (31-mers) sequences are counted and the singletons (those 31-mers only counted once) are filtered out. Software Description McCortex Counts 31-mers in the input FASTQ Minmer Sketch \u00b6 A minmer sketch and signature is created based on the QC'd FASTQs for multiple values of k . If datasets are available, the sketches/signatures are used for further downstream analysis. Software Usage Mash Produces a sketch ( k =21,31) of tje QC'd FASTQ Sourmash Produces a signature ( k =21,31,51) of the QC'd FASTQ De novo Assembly \u00b6 The QC'd FASTQs are assembled using the Shovill pipeline. This allows for a seamless assembly process using MEGAHIT , SKESA , SPAdes or Velvet . Alternatively, if long reads are available to complement Illumina paired-end reads, hybrid assembly is available through Unicycler . Software Usage assembly-scan Generates summary statistics of the final assembly Shovill Manages multiple steps in the Illumina assembly process Unicycler Manages multiple steps in the hybrid assembly process Assembly Quality Assessment \u00b6 After assembly, the de novo assembly is assessed for its biological (e.g. containment & contamination) as well as its technical (e.g. misassemblies and errors) quality using CheckM and QUAST . Software Usage CheckM Assess the biological quality of a de novo assembly based on presence of marker genes QUAST Gives a summary on the technical (e.g. misassemblies etc) quality of a de novo assembly Genome Annotation \u00b6 Genes are predicted and annotated from the assembled genome using Prokka . If available, a clustered RefSeq protein set is used for the first pass of annotation. Software Usage Prokka Predicts and annotates assembled genomes Antimicrobial Resistance \u00b6 Searches for antimicrobial resistance genes and assosiated point mutations in the annotated gene and protein sequences. If datasets are available, local assemblies can also be used to predict antibiotic resistance. Software Usage AMRFinderPlus Predicts antimicrobial resistance based on genes and point mutations Dataset Enabled Steps \u00b6 The remaining Dataset Enabled Steps require supplemental datasets to be available to be executed. There are many datasets available that Bactopia can take advantage of. To learn more about setting up these datasets, check out Build Datasets . These datasets can be broken into two groups, Public Datasets and User Datasets . Public Datasets \u00b6 Publicly available datasets can be used for further analysis. Call Variants (Auto) \u00b6 Variants are predicted using Snippy . The QC'd FASTQs are aligned to the nearest (based on Mash distance) RefSeq completed genome. By default, only the nearest genome is selected, but multiple genomes can be selected ( --max_references ) or this feature can be completely disabled ( disable_auto_variants ). Software Usage Bedtools Generates the per-base coverage of the reference alignment NCBI Genome Download Downloads the RefSeq completed genome Snippy Manages multiple steps in the haploid variant calling process vcf-annotator Adds annotations from reference GenBank to the final VCF Local Assembly \u00b6 Using available Ariba reference datasets , determines which reference sequences were found with an additional detailed report summarizing the results. Software Usage Ariba Creates local assemblies of reference sequences Minmer Query \u00b6 Screens QC'd FASTQs and signatures against available Minmer Datasets . Software Usage Mash Screens against RefSeq and/or PLSDB sketches Sourmash Screens signature against GenBank Sequence Type \u00b6 Uses a PubMLST.org MLST schema to determine the sequence type of the sample. Software Usage Ariba Runs QC'd FASTQ against a MLST database BLAST Aligns MLST loci against the assembled genome User Datasets \u00b6 Another option is for users to provide their own data to include in the analysis. BLAST Alignment \u00b6 Each gene, protein, or primer sequence provided by the user is aligned against the assembled genome. Software Usage BLAST Aligns reference sequences against the assembled genome Call Variants (User) \u00b6 Uses the same procedure as Call Variants (Auto) , except variants are called against each reference provided by the user. Software Usage Bedtools Generates the per-base coverage of the reference alignment Snippy Manages multiple steps in the haploid variant calling process vcf-annotator Adds annotations from reference GenBank to the final VCF Reference Mapping \u00b6 Aligns the QC'd FASTQs to each sequence provided by the user. Software Usage Bedtools Generates the per-base coverage of the reference alignment BWA Aligns QC'd FASTQ to a reference sequence Samtools Converts alignment from SAM to BAM","title":"Workflow Overview"},{"location":"workflow-overview/#workflow-overview","text":"Bactopia is an extensive workflow integrating numerous steps in bacterial genome analysis. Through out the workflow there are steps that are always enabled and dataset enabled . Each of the steps depicted in the image below are described in this section. A list of software directly used in each step is also listed. Please check out the Acknowledgements section to get the full list of software as well how to download and cite said software.","title":"Workflow Overview"},{"location":"workflow-overview/#always-enabled-steps","text":"The Always Enabled Steps are always executed by Bactopia. These steps do not depend of external datasets and thus are always enabled.","title":"Always Enabled Steps"},{"location":"workflow-overview/#gather-fastqs","text":"Specifies exactly where the input FASTQ/FASTAs are coming from. If you are using local inputs (e.g. --R1/--R2 , --fastqs ) it will verify they can be accessed. If an accession(s) ( --accession or --accessions ) was given, the corresponding FASTQs (SRA/ENA) or assemblies (NCBI Assembly) are downloaded in this step. All assemblies will have 2x250bp Illumina reads simulated withour insertions or deletions and a minimum PHRED score of Q33. Software Usage ART Generate simulated Illumina reads from an assembly ena-dl Download FASTQ files from ENA ncbi-genome-download Download GenBank/RefSeq assemblies from NCBI Assembly database","title":"Gather FASTQs"},{"location":"workflow-overview/#validate-fastqs","text":"Determines if the FASTQ file contains enough sequencing to continue processing. The --min_reads and --min_basepairs parameters adjust the minimum amount of sequencing required to continue processing. This step does not directly test the validity of the FASTQ format (although, it would fail if the format is invalid!). Software Usage fastq-scan Determine total read and basepairs of FASTQ","title":"Validate FASTQs"},{"location":"workflow-overview/#original-summary","text":"Produces summary statistics (read lengths, quality scores, etc...) based on the original input FASTQs. Software Usage FastQC Generates a HTML report of original FASTQ summary statistics fastq-scan Generates original FASTQ summary statistics in JSON format","title":"Original Summary"},{"location":"workflow-overview/#genome-size","text":"The genome size is by various programs in the Bactopia workflow. By default, if no genome size is given one is estimated using Mash. Otherwise, a specific genome size can be specified or completely disabled using the --genome_size parameter. See Genome Size Parameter to learn more about specifying the genome size. Software Usage Mash If not given, estimates genome size of sample","title":"Genome Size"},{"location":"workflow-overview/#quality-control","text":"The input FASTQs go through a few clean up steps. First, Illumina related adapters and phiX contaminants are removed. Then reads that fail to pass length and/or quality requirements are filtered out. If the genome size is available, sequence error-corrections are made and the total sequencing is reduced to a specified coverage. After this step, all downstream analyses are based on the QC'd FASTQ and the original is no longer used. Software Description BBTools Removes Illumina adapters, phiX contaminants, filters reads based on length and quality score, and reduces inputs to a specified coverage. Lighter Corrects sequencing errors","title":"Quality Control"},{"location":"workflow-overview/#qc-summary","text":"Produces summary statistics (read lengths, quality scores, etc...) based on the final set of QC'd FASTQs. Software Usage FastQC Generates a HTML report of QC'd FASTQ summary statistics fastq-scan Generates QC'd FASTQ summary statistics in JSON format","title":"QC Summary"},{"location":"workflow-overview/#count-31-mers","text":"All 31 basepair (31-mers) sequences are counted and the singletons (those 31-mers only counted once) are filtered out. Software Description McCortex Counts 31-mers in the input FASTQ","title":"Count 31-mers"},{"location":"workflow-overview/#minmer-sketch","text":"A minmer sketch and signature is created based on the QC'd FASTQs for multiple values of k . If datasets are available, the sketches/signatures are used for further downstream analysis. Software Usage Mash Produces a sketch ( k =21,31) of tje QC'd FASTQ Sourmash Produces a signature ( k =21,31,51) of the QC'd FASTQ","title":"Minmer Sketch"},{"location":"workflow-overview/#de-novo-assembly","text":"The QC'd FASTQs are assembled using the Shovill pipeline. This allows for a seamless assembly process using MEGAHIT , SKESA , SPAdes or Velvet . Alternatively, if long reads are available to complement Illumina paired-end reads, hybrid assembly is available through Unicycler . Software Usage assembly-scan Generates summary statistics of the final assembly Shovill Manages multiple steps in the Illumina assembly process Unicycler Manages multiple steps in the hybrid assembly process","title":"De novo Assembly"},{"location":"workflow-overview/#assembly-quality-assessment","text":"After assembly, the de novo assembly is assessed for its biological (e.g. containment & contamination) as well as its technical (e.g. misassemblies and errors) quality using CheckM and QUAST . Software Usage CheckM Assess the biological quality of a de novo assembly based on presence of marker genes QUAST Gives a summary on the technical (e.g. misassemblies etc) quality of a de novo assembly","title":"Assembly Quality Assessment"},{"location":"workflow-overview/#genome-annotation","text":"Genes are predicted and annotated from the assembled genome using Prokka . If available, a clustered RefSeq protein set is used for the first pass of annotation. Software Usage Prokka Predicts and annotates assembled genomes","title":"Genome Annotation"},{"location":"workflow-overview/#antimicrobial-resistance","text":"Searches for antimicrobial resistance genes and assosiated point mutations in the annotated gene and protein sequences. If datasets are available, local assemblies can also be used to predict antibiotic resistance. Software Usage AMRFinderPlus Predicts antimicrobial resistance based on genes and point mutations","title":"Antimicrobial Resistance"},{"location":"workflow-overview/#dataset-enabled-steps","text":"The remaining Dataset Enabled Steps require supplemental datasets to be available to be executed. There are many datasets available that Bactopia can take advantage of. To learn more about setting up these datasets, check out Build Datasets . These datasets can be broken into two groups, Public Datasets and User Datasets .","title":"Dataset Enabled Steps"},{"location":"workflow-overview/#public-datasets","text":"Publicly available datasets can be used for further analysis.","title":"Public Datasets"},{"location":"workflow-overview/#call-variants-auto","text":"Variants are predicted using Snippy . The QC'd FASTQs are aligned to the nearest (based on Mash distance) RefSeq completed genome. By default, only the nearest genome is selected, but multiple genomes can be selected ( --max_references ) or this feature can be completely disabled ( disable_auto_variants ). Software Usage Bedtools Generates the per-base coverage of the reference alignment NCBI Genome Download Downloads the RefSeq completed genome Snippy Manages multiple steps in the haploid variant calling process vcf-annotator Adds annotations from reference GenBank to the final VCF","title":"Call Variants (Auto)"},{"location":"workflow-overview/#local-assembly","text":"Using available Ariba reference datasets , determines which reference sequences were found with an additional detailed report summarizing the results. Software Usage Ariba Creates local assemblies of reference sequences","title":"Local Assembly"},{"location":"workflow-overview/#minmer-query","text":"Screens QC'd FASTQs and signatures against available Minmer Datasets . Software Usage Mash Screens against RefSeq and/or PLSDB sketches Sourmash Screens signature against GenBank","title":"Minmer Query"},{"location":"workflow-overview/#sequence-type","text":"Uses a PubMLST.org MLST schema to determine the sequence type of the sample. Software Usage Ariba Runs QC'd FASTQ against a MLST database BLAST Aligns MLST loci against the assembled genome","title":"Sequence Type"},{"location":"workflow-overview/#user-datasets","text":"Another option is for users to provide their own data to include in the analysis.","title":"User Datasets"},{"location":"workflow-overview/#blast-alignment","text":"Each gene, protein, or primer sequence provided by the user is aligned against the assembled genome. Software Usage BLAST Aligns reference sequences against the assembled genome","title":"BLAST Alignment"},{"location":"workflow-overview/#call-variants-user","text":"Uses the same procedure as Call Variants (Auto) , except variants are called against each reference provided by the user. Software Usage Bedtools Generates the per-base coverage of the reference alignment Snippy Manages multiple steps in the haploid variant calling process vcf-annotator Adds annotations from reference GenBank to the final VCF","title":"Call Variants (User)"},{"location":"workflow-overview/#reference-mapping","text":"Aligns the QC'd FASTQs to each sequence provided by the user. Software Usage Bedtools Generates the per-base coverage of the reference alignment BWA Aligns QC'd FASTQ to a reference sequence Samtools Converts alignment from SAM to BAM","title":"Reference Mapping"},{"location":"bactopia-tools/","text":"Overview \u00b6 After Bactopia has completed, there will be a lot of output files for each individual sample. The next step is to take these results and compare samples between each other. To aid in these comparative analyses, a set of predefined workflows, called Bactopia Tools , have been created. These workflows use the predictable directory structure of Bactopia to automate analyses. Common Inputs \u00b6 With the exceptions of the summary tool, each Bactopia Tool will use the following input parameters: --bactopia STR Directory containing Bactopia analysis results for all samples. --exclude STR A text file containing sample names to exclude from the analysis. The expected format is a single sample per line. --include STR A text file containing sample names to include in the analysis. The expected format is a single sample per line. --bactiopia \u00b6 This parameter tells each tool where to find your Bactopia outputs from your project. Using this path, the tool will identify the required inputs and begin analysis. What this means is there is no need for you to wrangle up input files for compartive analyses. --exclude \u00b6 What --exclude allows is for you to give a text file with a list of samples that should probably be excluded from further analyses. While you can produce this list yourself, the summary tool will produce a list of samples that do not pass certain thresholds. These thresholds are based on read lengths, sequence quality, coverage and assembly quality. You can adjust these thresholds to meet your needs. --include \u00b6 Similarly, --include allows you to give a text file with a list of samples to be included in the analysis. This allows you to target your anlyses on a specific subset of samples. An example of this may be to use the fastani tool to determine samples with >95% ANI to a reference, then create a pan-genome with the roary tool using only the subset of samples. Available Tools \u00b6 Below is a list of Bactopia Tools currently available. To learn more about each, please follow the link. eggnog Functional annotation using orthologous groups fastani Pairwise average nucleotide identity gtdb Identify marker genes and assign taxonomic classifications hicap In silico typing of the H. influenzae cap locus ismapper Identify positions of insertion sites mashtree Tree based on Mash distances phyloflash 16s extraction, alignment, and tree pirate Pan-genome, core-genome alignment and tree roary Pan-genome, core-genome alignment and tree staph-typer A set of tools for typing Staphylococcus aureus summary A report summarizing Bactopia project Suggest A Tool \u00b6 Do you have an idea or suggestion for an analysis that should be added to the set of Bactopia Tools? If so, please feel free to submit it to Bactopia GitHub Issues !","title":"Introduction"},{"location":"bactopia-tools/#overview","text":"After Bactopia has completed, there will be a lot of output files for each individual sample. The next step is to take these results and compare samples between each other. To aid in these comparative analyses, a set of predefined workflows, called Bactopia Tools , have been created. These workflows use the predictable directory structure of Bactopia to automate analyses.","title":"Overview"},{"location":"bactopia-tools/#common-inputs","text":"With the exceptions of the summary tool, each Bactopia Tool will use the following input parameters: --bactopia STR Directory containing Bactopia analysis results for all samples. --exclude STR A text file containing sample names to exclude from the analysis. The expected format is a single sample per line. --include STR A text file containing sample names to include in the analysis. The expected format is a single sample per line.","title":"Common Inputs"},{"location":"bactopia-tools/#-bactiopia","text":"This parameter tells each tool where to find your Bactopia outputs from your project. Using this path, the tool will identify the required inputs and begin analysis. What this means is there is no need for you to wrangle up input files for compartive analyses.","title":"--bactiopia"},{"location":"bactopia-tools/#-exclude","text":"What --exclude allows is for you to give a text file with a list of samples that should probably be excluded from further analyses. While you can produce this list yourself, the summary tool will produce a list of samples that do not pass certain thresholds. These thresholds are based on read lengths, sequence quality, coverage and assembly quality. You can adjust these thresholds to meet your needs.","title":"--exclude"},{"location":"bactopia-tools/#-include","text":"Similarly, --include allows you to give a text file with a list of samples to be included in the analysis. This allows you to target your anlyses on a specific subset of samples. An example of this may be to use the fastani tool to determine samples with >95% ANI to a reference, then create a pan-genome with the roary tool using only the subset of samples.","title":"--include"},{"location":"bactopia-tools/#available-tools","text":"Below is a list of Bactopia Tools currently available. To learn more about each, please follow the link. eggnog Functional annotation using orthologous groups fastani Pairwise average nucleotide identity gtdb Identify marker genes and assign taxonomic classifications hicap In silico typing of the H. influenzae cap locus ismapper Identify positions of insertion sites mashtree Tree based on Mash distances phyloflash 16s extraction, alignment, and tree pirate Pan-genome, core-genome alignment and tree roary Pan-genome, core-genome alignment and tree staph-typer A set of tools for typing Staphylococcus aureus summary A report summarizing Bactopia project","title":"Available Tools"},{"location":"bactopia-tools/#suggest-a-tool","text":"Do you have an idea or suggestion for an analysis that should be added to the set of Bactopia Tools? If so, please feel free to submit it to Bactopia GitHub Issues !","title":"Suggest A Tool"},{"location":"bactopia-tools/eggnog/","text":"Bactopia Tools - eggnog \u00b6 The eggnog tool uses eggNOG-mapper to assign functional annotation to protein sequences. eggNOG-mapper uses orthologous groups and phylogenies from the eggNOG database to more precisely functionally annotate than traditional homology methods. Example \u00b6 The following command will run eggnog on each available sample. bactopia tools eggnog \\ --bactopia ~/bactopia-tutorial/bactopia \\ --eggnog ~/bactopia-tutorial/eggnogdb Output Overview \u00b6 Below is the default output structure for the eggnog tool. Where possible the file descriptions below were modified from a tools description. bactopia-tools/ \u2514\u2500\u2500 eggnog/ \u2514\u2500\u2500 ${PREFIX} \u2514\u2500\u2500 bactopia-info \u2502 \u251c\u2500\u2500 eggnog-report.html \u2502 \u251c\u2500\u2500 eggnog-timeline.html \u2502 \u2514\u2500\u2500 eggnog-trace.txt \u251c\u2500\u2500 ${SAMPLE_NAME}.emapper.annotations \u2514\u2500\u2500 ${SAMPLE_NAME}.emapper.seed_orthologs Filename Description ${SAMPLE_NAME}.emapper.annotations The final eggNOG functional annotations ${SAMPLE_NAME}.emapper.seed_orthologs A list of best match for each query against the whole eggNOG protein space Directory Description \u00b6 bactopia-info \u00b6 Filename Description eggnog-report.html The Nextflow Execution Report eggnog-timeline.html The Nextflow Timeline Report eggnog-trace.txt The Nextflow Trace report Usage \u00b6 Required Parameters: --bactopia STR Directory containing Bactopia analysis results for all samples. --eggnog STR Directory containing the the eggNOG database files: eggnog.db and eggnog_proteins.dmnd. If the database is not found, you must use '--download_eggnog'. WARNING: eggNOG databases stored on NFS will see a significant increase in runtimes. If possible, SSD or Ramdisk should be used. Optional Parameters: --include STR A text file containing sample names to include in the analysis. The expected format is a single sample per line. --exclude STR A text file containing sample names to exclude from the analysis. The expected format is a single sample per line. --prefix DIR Prefix to use for final output files Default: emapper --outdir DIR Directory to write results to Default: ./ --max_time INT The maximum number of minutes a job should run before being halted. Default: 120 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single process. Default: 32 Gb --cpus INT Number of processors made available to a single process. Default: 1 eggNOG-mapper Parameters: *Note: Unless specified the eggNOG-mapper defaults are used.* --download_eggnog Download the latest eggNOG database, even if it exists. eggNOG Annotation Parameters: --tax_scope STR Fix the taxonomic scope used for annotation, so only orthologs from a particular clade are used for functional transfer. --target_orthologs STR Defines what type of orthologs should be used for functional transfer. Choices are: one2one, many2one, one2many, many2many, all --go_evidence STR Defines what type of GO terms should be used for annotation. Choices are: 'experimental': Use only terms inferred from experimental evidence 'non-electronic': Use only non- electronically curated terms eggNOG HMM Search Parameters: --hmm_maxhits INT Max number of hits to report. --hmm_evalue FLOAT E-value threshold. --hmm_score INT Bit score threshold. --hmm_maxseqlen INT Ignore query sequences larger than `maxseqlen`. --hmm_qcov FLOAT Min query coverage (from 0 to 1). --Z INT Fixed database size used in phmmer/hmmscan (allows comparing e-values among databases). eggNOG DIAMOND Search Parameters: --use_diamond Use DIAMOND instead of HMMER. --matrix STR Scoring matrix. Choices are: BLOSUM62, BLOSUM90, BLOSUM80, BLOSUM50, BLOSUM45, PAM250, PAM70, PAM30 --gapopen INT Gap open penalty --gapextend INT Gap extend penalty --query_cover FLOAT Report only alignments above the given percentage of query cover. --subject_cover FLOAT Report only alignments above the given percentage of subject cover. eggNOG Seed Ortholog Search Parameters: --seed_ortholog_evalue FLOAT Min E-value expected when searching for seed eggNOG ortholog. Applies to phmmer/diamond searches. Queries not having a --significant seed orthologs will not be annotated. --seed_ortholog_score INT Min bit score expected when searching for seed eggNOG ortholog. Applies to phmmer/diamond searches. Queries not having a --significant seed orthologs will not be annotated. eggNOG Output Parameters: --keep_mapping_files Do not delete temporary mapping files used for annotation (i.e. HMMER and DIAMOND search outputs) --no_annot Skip functional annotation, reporting only hits --no_file_comments No header lines nor stats are included in the output files --no_refine Skip hit refinement, reporting only HMM hits. --no_search Skip HMM search mapping. Use existing hits file eggNOG Predict Orthologs Parameters: --target_taxa STR Taxa that will be searched for orthologs --predict_output_format STR Choose the output format among: per_query, per_species. Nextflow Related Parameters: --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: false --conatainerPath Path to Singularity containers to be used by the 'slurm' profile. Default: /opt/bactopia/singularity --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds --nfconfig STR A Nextflow compatible config file for custom profiles. This allows you to create profiles specific to your environment (e.g. SGE, AWS, SLURM, etc...). This config file is loaded last and will overwrite existing variables if set. Default: Bactopia's default configs -resume Nextflow will attempt to resume a previous run. Please notice it is only a single '-' Useful Parameters: --version Print workflow version information --help Show this message and exit Conda Environment \u00b6 Below is the command used to create the Conda environment. conda create -n bactopia-eggnog -c conda-forge -c bioconda \\ eggnog-mapper References \u00b6 DIAMOND B. Buchfink, C. Xie, D. H. Huson, Fast and sensitive protein alignment using DIAMOND. Nat. Methods. 12, 59\u201360 (2015). eggNOG-mapper J. Huerta-Cepas, K. Forslund, L. P. Coelho, D. Szklarczyk, L. J. Jensen, C. von Mering, P. Bork, Fast Genome-Wide Functional Annotation through Orthology Assignment by eggNOG-Mapper. Mol. Biol. Evol. 34, 2115\u20132122 (2017). eggNOG 5.0 Database J. Huerta-Cepas, D. Szklarczyk, D. Heller, A. Hern\u00e1ndez-Plaza, S. K. Forslund, H. Cook, D. R. Mende, I. Letunic, T. Rattei, L. J. Jensen, C. von Mering, P. Bork, eggNOG 5.0: a hierarchical, functionally and phylogenetically annotated orthology resource based on 5090 organisms and 2502 viruses. Nucleic Acids Res. 47, D309\u2013D314 (2019).","title":"eggnog"},{"location":"bactopia-tools/eggnog/#bactopia-tools-eggnog","text":"The eggnog tool uses eggNOG-mapper to assign functional annotation to protein sequences. eggNOG-mapper uses orthologous groups and phylogenies from the eggNOG database to more precisely functionally annotate than traditional homology methods.","title":"Bactopia Tools - eggnog"},{"location":"bactopia-tools/eggnog/#example","text":"The following command will run eggnog on each available sample. bactopia tools eggnog \\ --bactopia ~/bactopia-tutorial/bactopia \\ --eggnog ~/bactopia-tutorial/eggnogdb","title":"Example"},{"location":"bactopia-tools/eggnog/#output-overview","text":"Below is the default output structure for the eggnog tool. Where possible the file descriptions below were modified from a tools description. bactopia-tools/ \u2514\u2500\u2500 eggnog/ \u2514\u2500\u2500 ${PREFIX} \u2514\u2500\u2500 bactopia-info \u2502 \u251c\u2500\u2500 eggnog-report.html \u2502 \u251c\u2500\u2500 eggnog-timeline.html \u2502 \u2514\u2500\u2500 eggnog-trace.txt \u251c\u2500\u2500 ${SAMPLE_NAME}.emapper.annotations \u2514\u2500\u2500 ${SAMPLE_NAME}.emapper.seed_orthologs Filename Description ${SAMPLE_NAME}.emapper.annotations The final eggNOG functional annotations ${SAMPLE_NAME}.emapper.seed_orthologs A list of best match for each query against the whole eggNOG protein space","title":"Output Overview"},{"location":"bactopia-tools/eggnog/#directory-description","text":"","title":"Directory Description"},{"location":"bactopia-tools/eggnog/#bactopia-info","text":"Filename Description eggnog-report.html The Nextflow Execution Report eggnog-timeline.html The Nextflow Timeline Report eggnog-trace.txt The Nextflow Trace report","title":"bactopia-info"},{"location":"bactopia-tools/eggnog/#usage","text":"Required Parameters: --bactopia STR Directory containing Bactopia analysis results for all samples. --eggnog STR Directory containing the the eggNOG database files: eggnog.db and eggnog_proteins.dmnd. If the database is not found, you must use '--download_eggnog'. WARNING: eggNOG databases stored on NFS will see a significant increase in runtimes. If possible, SSD or Ramdisk should be used. Optional Parameters: --include STR A text file containing sample names to include in the analysis. The expected format is a single sample per line. --exclude STR A text file containing sample names to exclude from the analysis. The expected format is a single sample per line. --prefix DIR Prefix to use for final output files Default: emapper --outdir DIR Directory to write results to Default: ./ --max_time INT The maximum number of minutes a job should run before being halted. Default: 120 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single process. Default: 32 Gb --cpus INT Number of processors made available to a single process. Default: 1 eggNOG-mapper Parameters: *Note: Unless specified the eggNOG-mapper defaults are used.* --download_eggnog Download the latest eggNOG database, even if it exists. eggNOG Annotation Parameters: --tax_scope STR Fix the taxonomic scope used for annotation, so only orthologs from a particular clade are used for functional transfer. --target_orthologs STR Defines what type of orthologs should be used for functional transfer. Choices are: one2one, many2one, one2many, many2many, all --go_evidence STR Defines what type of GO terms should be used for annotation. Choices are: 'experimental': Use only terms inferred from experimental evidence 'non-electronic': Use only non- electronically curated terms eggNOG HMM Search Parameters: --hmm_maxhits INT Max number of hits to report. --hmm_evalue FLOAT E-value threshold. --hmm_score INT Bit score threshold. --hmm_maxseqlen INT Ignore query sequences larger than `maxseqlen`. --hmm_qcov FLOAT Min query coverage (from 0 to 1). --Z INT Fixed database size used in phmmer/hmmscan (allows comparing e-values among databases). eggNOG DIAMOND Search Parameters: --use_diamond Use DIAMOND instead of HMMER. --matrix STR Scoring matrix. Choices are: BLOSUM62, BLOSUM90, BLOSUM80, BLOSUM50, BLOSUM45, PAM250, PAM70, PAM30 --gapopen INT Gap open penalty --gapextend INT Gap extend penalty --query_cover FLOAT Report only alignments above the given percentage of query cover. --subject_cover FLOAT Report only alignments above the given percentage of subject cover. eggNOG Seed Ortholog Search Parameters: --seed_ortholog_evalue FLOAT Min E-value expected when searching for seed eggNOG ortholog. Applies to phmmer/diamond searches. Queries not having a --significant seed orthologs will not be annotated. --seed_ortholog_score INT Min bit score expected when searching for seed eggNOG ortholog. Applies to phmmer/diamond searches. Queries not having a --significant seed orthologs will not be annotated. eggNOG Output Parameters: --keep_mapping_files Do not delete temporary mapping files used for annotation (i.e. HMMER and DIAMOND search outputs) --no_annot Skip functional annotation, reporting only hits --no_file_comments No header lines nor stats are included in the output files --no_refine Skip hit refinement, reporting only HMM hits. --no_search Skip HMM search mapping. Use existing hits file eggNOG Predict Orthologs Parameters: --target_taxa STR Taxa that will be searched for orthologs --predict_output_format STR Choose the output format among: per_query, per_species. Nextflow Related Parameters: --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: false --conatainerPath Path to Singularity containers to be used by the 'slurm' profile. Default: /opt/bactopia/singularity --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds --nfconfig STR A Nextflow compatible config file for custom profiles. This allows you to create profiles specific to your environment (e.g. SGE, AWS, SLURM, etc...). This config file is loaded last and will overwrite existing variables if set. Default: Bactopia's default configs -resume Nextflow will attempt to resume a previous run. Please notice it is only a single '-' Useful Parameters: --version Print workflow version information --help Show this message and exit","title":"Usage"},{"location":"bactopia-tools/eggnog/#conda-environment","text":"Below is the command used to create the Conda environment. conda create -n bactopia-eggnog -c conda-forge -c bioconda \\ eggnog-mapper","title":"Conda Environment"},{"location":"bactopia-tools/eggnog/#references","text":"DIAMOND B. Buchfink, C. Xie, D. H. Huson, Fast and sensitive protein alignment using DIAMOND. Nat. Methods. 12, 59\u201360 (2015). eggNOG-mapper J. Huerta-Cepas, K. Forslund, L. P. Coelho, D. Szklarczyk, L. J. Jensen, C. von Mering, P. Bork, Fast Genome-Wide Functional Annotation through Orthology Assignment by eggNOG-Mapper. Mol. Biol. Evol. 34, 2115\u20132122 (2017). eggNOG 5.0 Database J. Huerta-Cepas, D. Szklarczyk, D. Heller, A. Hern\u00e1ndez-Plaza, S. K. Forslund, H. Cook, D. R. Mende, I. Letunic, T. Rattei, L. J. Jensen, C. von Mering, P. Bork, eggNOG 5.0: a hierarchical, functionally and phylogenetically annotated orthology resource based on 5090 organisms and 2502 viruses. Nucleic Acids Res. 47, D309\u2013D314 (2019).","title":"References"},{"location":"bactopia-tools/fastani/","text":"Bactopia Tools - fastani \u00b6 The fastani tool uses FastANI to calcualte the average nucleotide identity (ANI) between your samples. Although, sometimes you might be more interested in calculating the ANI of your samples against a reference genome. Fortunately, using ncbi-genome-download , the fastani tool allows you specify either a specific NCBI Assembly RefSeq accession ( --accession ) or a species name ( --species ) for which to download all RefSeq genomes for. Example \u00b6 bactopia tools fastani \\ --bactopia ~/bactopia-tutorial/bactopia \\ --exclude ~/bactopia-tutorial/bactopia-tools/summary/bactopia-exclude.txt \\ --accession \"GCF_900475245.1\" \\ awk '{if ($3 > 95){print $0}}' ~/bactopia-tutorial/bactopia-tools/fastani/fastani.tsv | \\ grep -v \"GCF_900475245\" > ~/bactopia-tutorial/GCF_900475245-include.txt Above is a good example of subsetting your samples. In the example, all samples would have had their ANI to GCF_900475245 calculated. Then with awk, all samples that had greater than 95% ANI to GCF_900475245 were output to a text file. This text file could then be used with the --include parameter for other Bactopia Tools. Output Overview \u00b6 Below is the default output structure for the fastani tool. Where possible the file descriptions below were modified from a tools description. bactopia-tools/ \u2514\u2500\u2500 fastani/ \u2514\u2500\u2500 ${PREFIX} \u251c\u2500\u2500 bactopia-info \u2502 \u251c\u2500\u2500 fastani-report.html \u2502 \u251c\u2500\u2500 fastani-timeline.html \u2502 \u2514\u2500\u2500 fastani-trace.txt \u251c\u2500\u2500 fastani.tsv \u251c\u2500\u2500 references \u2502 \u2514\u2500\u2500 ${REFERENCE}.tsv \u2514\u2500\u2500 refseq \u2514\u2500\u2500 fasta \u2514\u2500\u2500 ${REFERENCE}.fna Filename Description fastani.tsv All the FastANI results ( references/*.tsv ) merged into a single file. Directory Description \u00b6 bactopia-info \u00b6 Filename Description fastani-report.html The Nextflow Execution Report fastani-timeline.html The Nextflow Timeline Report fastani-trace.txt The Nextflow Trace report references \u00b6 Filename Description ${REFERENCE}.tsv FastANI results of all samples against a reference genome refseq/fasta \u00b6 Filename Description ${REFERENCE}.fna FASTA formated genome downloaded from NCBI Assembly database. Usage \u00b6 Required Parameters: --bactopia STR Directory containing Bactopia analysis results for all samples. Optional Parameters: --include STR A text file containing sample names to include in the analysis. The expected format is a single sample per line. --exclude STR A text file containing sample names to exclude from the analysis. The expected format is a single sample per line. --prefix DIR Prefix to use for final output files Default: fastani --outdir DIR Directory to write results to Default: ./ --max_time INT The maximum number of minutes a job should run before being halted. Default: 120 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single process. Default: 32 Gb --cpus INT Number of processors made available to a single process. Default: 1 RefSeq Assemblies Related Parameters: This is a completely optional step and is meant to supplement your dataset with high-quality completed genomes. --species STR The name of the species to download RefSeq assemblies for. This is a completely optional step and is meant to supplement your dataset with high-quality completed genomes. --accession STR A NCBI Assembly database RefSeq accession to be downloaded and included in the pan-genome analysis. --limit INT Limit the number of RefSeq assemblies to download. If the the number of available genomes exceeds the given limit, a random subset will be selected. Default: Download all available genomes --refseq_only Pairwise ANI's will only be calulated against download RefSeq genomes. FastANI Related Parameters: --kmer INT kmer size <= 16 Default: null --fragLen INT fragment length Default: 3000 --minFraction FLOAT Minimum fraction of genome that must be shared for trusting ANI. If reference and query genome size differ, smaller one among the two is considered. Default: 0.2 Nextflow Related Parameters: --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: false --conatainerPath Path to Singularity containers to be used by the 'slurm' profile. Default: /opt/bactopia/singularity --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds Useful Parameters: --version Print workflow version information --help Show this message and exit Conda Environment \u00b6 Below is the command used to create the Conda environment. conda create -y -n bactopia-fastani -c conda-forge -c bioconda \\ fastani \\ ncbi-genome-download \\ rename References \u00b6 FastANI Jain, C., Rodriguez-R, L. M., Phillippy, A. M., Konstantinidis, K. T. & Aluru, S. High throughput ANI analysis of 90K prokaryotic genomes reveals clear species boundaries. Nat. Commun. 9, 5114 (2018) ncbi-genome-download Blin, K. ncbi-genome-download: Scripts to download genomes from the NCBI FTP servers","title":"fastani"},{"location":"bactopia-tools/fastani/#bactopia-tools-fastani","text":"The fastani tool uses FastANI to calcualte the average nucleotide identity (ANI) between your samples. Although, sometimes you might be more interested in calculating the ANI of your samples against a reference genome. Fortunately, using ncbi-genome-download , the fastani tool allows you specify either a specific NCBI Assembly RefSeq accession ( --accession ) or a species name ( --species ) for which to download all RefSeq genomes for.","title":"Bactopia Tools - fastani"},{"location":"bactopia-tools/fastani/#example","text":"bactopia tools fastani \\ --bactopia ~/bactopia-tutorial/bactopia \\ --exclude ~/bactopia-tutorial/bactopia-tools/summary/bactopia-exclude.txt \\ --accession \"GCF_900475245.1\" \\ awk '{if ($3 > 95){print $0}}' ~/bactopia-tutorial/bactopia-tools/fastani/fastani.tsv | \\ grep -v \"GCF_900475245\" > ~/bactopia-tutorial/GCF_900475245-include.txt Above is a good example of subsetting your samples. In the example, all samples would have had their ANI to GCF_900475245 calculated. Then with awk, all samples that had greater than 95% ANI to GCF_900475245 were output to a text file. This text file could then be used with the --include parameter for other Bactopia Tools.","title":"Example"},{"location":"bactopia-tools/fastani/#output-overview","text":"Below is the default output structure for the fastani tool. Where possible the file descriptions below were modified from a tools description. bactopia-tools/ \u2514\u2500\u2500 fastani/ \u2514\u2500\u2500 ${PREFIX} \u251c\u2500\u2500 bactopia-info \u2502 \u251c\u2500\u2500 fastani-report.html \u2502 \u251c\u2500\u2500 fastani-timeline.html \u2502 \u2514\u2500\u2500 fastani-trace.txt \u251c\u2500\u2500 fastani.tsv \u251c\u2500\u2500 references \u2502 \u2514\u2500\u2500 ${REFERENCE}.tsv \u2514\u2500\u2500 refseq \u2514\u2500\u2500 fasta \u2514\u2500\u2500 ${REFERENCE}.fna Filename Description fastani.tsv All the FastANI results ( references/*.tsv ) merged into a single file.","title":"Output Overview"},{"location":"bactopia-tools/fastani/#directory-description","text":"","title":"Directory Description"},{"location":"bactopia-tools/fastani/#bactopia-info","text":"Filename Description fastani-report.html The Nextflow Execution Report fastani-timeline.html The Nextflow Timeline Report fastani-trace.txt The Nextflow Trace report","title":"bactopia-info"},{"location":"bactopia-tools/fastani/#references","text":"Filename Description ${REFERENCE}.tsv FastANI results of all samples against a reference genome","title":"references"},{"location":"bactopia-tools/fastani/#refseqfasta","text":"Filename Description ${REFERENCE}.fna FASTA formated genome downloaded from NCBI Assembly database.","title":"refseq/fasta"},{"location":"bactopia-tools/fastani/#usage","text":"Required Parameters: --bactopia STR Directory containing Bactopia analysis results for all samples. Optional Parameters: --include STR A text file containing sample names to include in the analysis. The expected format is a single sample per line. --exclude STR A text file containing sample names to exclude from the analysis. The expected format is a single sample per line. --prefix DIR Prefix to use for final output files Default: fastani --outdir DIR Directory to write results to Default: ./ --max_time INT The maximum number of minutes a job should run before being halted. Default: 120 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single process. Default: 32 Gb --cpus INT Number of processors made available to a single process. Default: 1 RefSeq Assemblies Related Parameters: This is a completely optional step and is meant to supplement your dataset with high-quality completed genomes. --species STR The name of the species to download RefSeq assemblies for. This is a completely optional step and is meant to supplement your dataset with high-quality completed genomes. --accession STR A NCBI Assembly database RefSeq accession to be downloaded and included in the pan-genome analysis. --limit INT Limit the number of RefSeq assemblies to download. If the the number of available genomes exceeds the given limit, a random subset will be selected. Default: Download all available genomes --refseq_only Pairwise ANI's will only be calulated against download RefSeq genomes. FastANI Related Parameters: --kmer INT kmer size <= 16 Default: null --fragLen INT fragment length Default: 3000 --minFraction FLOAT Minimum fraction of genome that must be shared for trusting ANI. If reference and query genome size differ, smaller one among the two is considered. Default: 0.2 Nextflow Related Parameters: --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: false --conatainerPath Path to Singularity containers to be used by the 'slurm' profile. Default: /opt/bactopia/singularity --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds Useful Parameters: --version Print workflow version information --help Show this message and exit","title":"Usage"},{"location":"bactopia-tools/fastani/#conda-environment","text":"Below is the command used to create the Conda environment. conda create -y -n bactopia-fastani -c conda-forge -c bioconda \\ fastani \\ ncbi-genome-download \\ rename","title":"Conda Environment"},{"location":"bactopia-tools/fastani/#references_1","text":"FastANI Jain, C., Rodriguez-R, L. M., Phillippy, A. M., Konstantinidis, K. T. & Aluru, S. High throughput ANI analysis of 90K prokaryotic genomes reveals clear species boundaries. Nat. Commun. 9, 5114 (2018) ncbi-genome-download Blin, K. ncbi-genome-download: Scripts to download genomes from the NCBI FTP servers","title":"References"},{"location":"bactopia-tools/gtdb/","text":"Bactopia Tools - gtdb \u00b6 The gtdb tool uses GTDB-Tk's classify workflow to assign taxonomic classifications to your set of samples. This is done through the use of the Genome Taxonomy Database . If you are unsure of your sequences, gtdb is useful tool to help determine the taxonomy of your samples. Example \u00b6 The following command will use gtdb to assign a taxonomic classification on all samples except those listed in the exclude file. bactopia tools gtdb \\ --bactopia ~/bactopia-tutorial/bactopia \\ --gtdb ~/bactopia-tutorial/bactopia-datasets/gtdb/db \\ --exclude ~/bactopia-tutorial/bactopia-tools/summary/bactopia-exclude.txt \\ --cpus 4 Output Overview \u00b6 Below is the default output structure for the gtdb tool. Where possible the file descriptions below were modified from descriptions at the GTDB-Tk Classify Workflow page. bactopia-tools/ \u2514\u2500\u2500 gtdb \u2514\u2500\u2500 ${PREFIX} \u251c\u2500\u2500 bactopia-info \u2502 \u251c\u2500\u2500 gtdb-report.html \u2502 \u251c\u2500\u2500 gtdb-timeline.html \u2502 \u2514\u2500\u2500 gtdb-trace.txt \u2514\u2500\u2500 classify \u251c\u2500\u2500 align \u2502 \u251c\u2500\u2500 gtdb.(ar122|bac120).filtered.tsv \u2502 \u251c\u2500\u2500 gtdb.(ar122|bac120).msa.fasta \u2502 \u251c\u2500\u2500 gtdb.(ar122|bac120).user_msa.fasta \u2502 \u2514\u2500\u2500 intermediate_results \u2502 \u2514\u2500\u2500 gtdb.(ar122|bac120).marker_info.tsv \u251c\u2500\u2500 classify \u2502 \u251c\u2500\u2500 gtdb.(ar122|bac120).classify.tree \u2502 \u251c\u2500\u2500 gtdb.(ar122|bac120).summary.tsv \u2502 \u2514\u2500\u2500 intermediate_results \u2502 \u251c\u2500\u2500 gtdb.(ar122|bac120).classification_pplacer.tsv \u2502 \u251c\u2500\u2500 gtdb.(ar122|bac120).red_dictionary.tsv \u2502 \u2514\u2500\u2500 pplacer \u2502 \u251c\u2500\u2500 pplacer.(ar122|bac120).json \u2502 \u2514\u2500\u2500 pplacer.(ar122|bac120).out \u251c\u2500\u2500 gtdb.(ar122|bac120).classify.tree \u251c\u2500\u2500 gtdb.(ar122|bac120).filtered.tsv \u251c\u2500\u2500 gtdb.(ar122|bac120).markers_summary.tsv \u251c\u2500\u2500 gtdb.(ar122|bac120).msa.fasta \u251c\u2500\u2500 gtdb.(ar122|bac120).summary.tsv \u251c\u2500\u2500 gtdb.(ar122|bac120).user_msa.fasta \u251c\u2500\u2500 gtdbtk.log \u251c\u2500\u2500 gtdbtk.warnings.log \u251c\u2500\u2500 gtdb.translation_table_summary.tsv \u2514\u2500\u2500 identify \u251c\u2500\u2500 gtdb.ar122.markers_summary.tsv \u251c\u2500\u2500 gtdb.bac120.markers_summary.tsv \u251c\u2500\u2500 gtdb.translation_table_summary.tsv \u2514\u2500\u2500 intermediate_results \u2514\u2500\u2500 marker_genes \u2514\u2500\u2500 ${SAMPLE_NAME} \u251c\u2500\u2500 prodigal_translation_table.tsv \u251c\u2500\u2500 prodigal_translation_table.tsv.sha256 \u251c\u2500\u2500 ${SAMPLE_NAME}_pfam_tophit.tsv \u251c\u2500\u2500 ${SAMPLE_NAME}_pfam_tophit.tsv.sha256 \u251c\u2500\u2500 ${SAMPLE_NAME}_pfam.tsv \u251c\u2500\u2500 ${SAMPLE_NAME}_pfam.tsv.sha256 \u251c\u2500\u2500 ${SAMPLE_NAME}_protein.faa \u251c\u2500\u2500 ${SAMPLE_NAME}_protein.faa.sha256 \u251c\u2500\u2500 ${SAMPLE_NAME}_protein.fna \u251c\u2500\u2500 ${SAMPLE_NAME}_protein.fna.sha256 \u251c\u2500\u2500 ${SAMPLE_NAME}_protein.gff \u251c\u2500\u2500 ${SAMPLE_NAME}_protein.gff.sha256 \u251c\u2500\u2500 ${SAMPLE_NAME}_tigrfam.out \u251c\u2500\u2500 ${SAMPLE_NAME}_tigrfam.out.sha256 \u251c\u2500\u2500 ${SAMPLE_NAME}_tigrfam_tophit.tsv \u251c\u2500\u2500 ${SAMPLE_NAME}_tigrfam_tophit.tsv.sha256 \u251c\u2500\u2500 ${SAMPLE_NAME}_tigrfam.tsv \u2514\u2500\u2500 ${SAMPLE_NAME}_tigrfam.tsv.sha256 Filename Description gtdb.(ar122|bac120).classify.tree Reference tree in Newick format containing query genomes placed with pplacer gtdb.(ar122|bac120).filtered.tsv List of genomes with an insufficient number of amino acids in MSA gtdb.(ar122|bac120).markers_summary.tsv Markers used in generation of the concatenated MSA and the order in which they were applied gtdb.(ar122|bac120).msa.fasta FASTA file containing MSA of submitted and reference genomes gtdb.(ar122|bac120).summary.tsv A summary of classifications provided by GTDB-Tk, see classification summary for more details gtdb.(ar122|bac120).user_msa.fasta FASTA file containing MSA of the submitted genomes gtdbtk.log A log of the run gtdbtk.warnings.log A log of any warnings produced by the run gtdb.translation_table_summary.tsv Summary of the tranlastlation table used for each genome Directory Description \u00b6 align \u00b6 Filename Description gtdb.(ar122|bac120).filtered.tsv List of genomes with an insufficient number of amino acids in MSA gtdb.(ar122|bac120).msa.fasta FASTA file containing MSA of submitted and reference genomes gtdb.(ar122|bac120).user_msa.fasta FASTA file containing MSA of the submitted genomes gtdb.(ar122|bac120).marker_info.tsv Markers used in generation of the concatenated MSA and the order in which they were applied bactopia-info \u00b6 Filename Description gtdb-report.html The Nextflow Execution Report gtdb-timeline.html The Nextflow Timeline Report gtdb-trace.txt The Nextflow Trace report classify \u00b6 Filename Description gtdb.(ar122|bac120).classify.tree Reference tree in Newick format containing query genomes placed with pplacer gtdb.(ar122|bac120).summary.tsv Classification of query genomes based on their placement in the reference tree, relative evolutionary divergence, and ANI to reference genomes gtdb.(ar122|bac120).classification_pplacer.tsv Classification of query genomes based only on their placement in the reference tree gtdb.(ar122|bac120).red_dictionary.tsv Median RED values for taxonomic ranks pplacer.(ar122|bac120).json Output information generated by pplacer in JSON format pplacer.(ar122|bac120).out Output information generated by pplacer identify \u00b6 Filename Description gtdb.ar122.markers_summary.tsv Summary of unique, duplicated, and missing markers within the 122 archaeal marker set for each submitted genome gtdb.bac120.markers_summary.tsv Summary of unique, duplicated, and missing markers within the 120 bacterial marker set for each submitted genome gtdb.translation_table_summary.tsv The predicted translation table used for gene calling for each genome identify/intermediate_results/marker_genes/ Contains individual genome results for gene calling using Prodigal and gene identification based on TIGRFAM and Pfam HMMs Usage \u00b6 Required Parameters: --bactopia STR Directory containing Bactopia analysis results for all samples. --gtdb STR Location of a GTDB database. If a database is not found, you must use '--download_gtdb'. Optional Parameters: --include STR A text file containing sample names to include in the analysis. The expected format is a single sample per line. --exclude STR A text file containing sample names to exclude from the analysis. The expected format is a single sample per line. --prefix DIR Prefix to use for final output files Default: gtdb --outdir DIR Directory to write results to Default: ./ --max_time INT The maximum number of minutes a job should run before being halted. Default: 120 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single process. Default: 32 Gb --cpus INT Number of processors made available to a single process. Default: 1 GTDB-Tk Related Parameters: --download_gtdb Download the latest GTDB database, even it exists. --min_perc_aa INT Filter genomes with an insufficient percentage of AA in the MSA Default: 10 --recalculate_red Recalculate RED values based on the reference tree and all added user genomes --force_gtdb Force GTDB to continue processing if an error occurrs on a single genome --debug Create intermediate files for debugging purposes Nextflow Related Parameters: --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: false --conatainerPath Path to Singularity containers to be used by the 'slurm' profile. Default: /opt/bactopia/singularity --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds Useful Parameters: --version Print workflow version information --help Show this message and exit Conda Environment \u00b6 Below is the command used to create the Conda environment. conda create -y -n bactopia-gtdb -c conda-forge -c bioconda gtdbtk References \u00b6 FastANI Jain, C., Rodriguez-R, L. M., Phillippy, A. M., Konstantinidis, K. T. & Aluru, S. High throughput ANI analysis of 90K prokaryotic genomes reveals clear species boundaries. Nat. Commun. 9, 5114 (2018) FastTree 2 Price, M. N., Dehal, P. S. & Arkin, A. P. FastTree 2 \u2013 Approximately Maximum-Likelihood Trees for Large Alignments. PLoS One 5, e9490 (2010) Genome Taxonomy Database Parks, D. H. et al. A standardized bacterial taxonomy based on genome phylogeny substantially revises the tree of life. Nat. Biotechnol. 36, 996\u20131004 (2018) _ _Parks, D. H. et al. Selection of representative genomes for 24,706 bacterial and archaeal species clusters provide a complete genome-based taxonomy. bioRxiv 771964 (2019) GTDB-Tk Chaumeil, P.-A., Mussig, A. J., Hugenholtz, P. & Parks, D. H. GTDB-Tk: a toolkit to classify genomes with the Genome Taxonomy Database. Bioinformatics (2019) HMMER3 Eddy, S. R. Accelerated Profile HMM Searches. PLoS Comput. Biol. 7, e1002195 (2011) pplacer Matsen, F. A., Kodner, R. B. & Armbrust, E. V. pplacer: linear time maximum-likelihood and Bayesian phylogenetic placement of sequences onto a fixed reference tree. BMC Bioinformatics 11, 538 (2010) Prodigal Hyatt, D. et al. Prodigal: prokaryotic gene recognition and translation initiation site identification. BMC Bioinformatics 11, 119 (2010)","title":"gtdb"},{"location":"bactopia-tools/gtdb/#bactopia-tools-gtdb","text":"The gtdb tool uses GTDB-Tk's classify workflow to assign taxonomic classifications to your set of samples. This is done through the use of the Genome Taxonomy Database . If you are unsure of your sequences, gtdb is useful tool to help determine the taxonomy of your samples.","title":"Bactopia Tools - gtdb"},{"location":"bactopia-tools/gtdb/#example","text":"The following command will use gtdb to assign a taxonomic classification on all samples except those listed in the exclude file. bactopia tools gtdb \\ --bactopia ~/bactopia-tutorial/bactopia \\ --gtdb ~/bactopia-tutorial/bactopia-datasets/gtdb/db \\ --exclude ~/bactopia-tutorial/bactopia-tools/summary/bactopia-exclude.txt \\ --cpus 4","title":"Example"},{"location":"bactopia-tools/gtdb/#output-overview","text":"Below is the default output structure for the gtdb tool. Where possible the file descriptions below were modified from descriptions at the GTDB-Tk Classify Workflow page. bactopia-tools/ \u2514\u2500\u2500 gtdb \u2514\u2500\u2500 ${PREFIX} \u251c\u2500\u2500 bactopia-info \u2502 \u251c\u2500\u2500 gtdb-report.html \u2502 \u251c\u2500\u2500 gtdb-timeline.html \u2502 \u2514\u2500\u2500 gtdb-trace.txt \u2514\u2500\u2500 classify \u251c\u2500\u2500 align \u2502 \u251c\u2500\u2500 gtdb.(ar122|bac120).filtered.tsv \u2502 \u251c\u2500\u2500 gtdb.(ar122|bac120).msa.fasta \u2502 \u251c\u2500\u2500 gtdb.(ar122|bac120).user_msa.fasta \u2502 \u2514\u2500\u2500 intermediate_results \u2502 \u2514\u2500\u2500 gtdb.(ar122|bac120).marker_info.tsv \u251c\u2500\u2500 classify \u2502 \u251c\u2500\u2500 gtdb.(ar122|bac120).classify.tree \u2502 \u251c\u2500\u2500 gtdb.(ar122|bac120).summary.tsv \u2502 \u2514\u2500\u2500 intermediate_results \u2502 \u251c\u2500\u2500 gtdb.(ar122|bac120).classification_pplacer.tsv \u2502 \u251c\u2500\u2500 gtdb.(ar122|bac120).red_dictionary.tsv \u2502 \u2514\u2500\u2500 pplacer \u2502 \u251c\u2500\u2500 pplacer.(ar122|bac120).json \u2502 \u2514\u2500\u2500 pplacer.(ar122|bac120).out \u251c\u2500\u2500 gtdb.(ar122|bac120).classify.tree \u251c\u2500\u2500 gtdb.(ar122|bac120).filtered.tsv \u251c\u2500\u2500 gtdb.(ar122|bac120).markers_summary.tsv \u251c\u2500\u2500 gtdb.(ar122|bac120).msa.fasta \u251c\u2500\u2500 gtdb.(ar122|bac120).summary.tsv \u251c\u2500\u2500 gtdb.(ar122|bac120).user_msa.fasta \u251c\u2500\u2500 gtdbtk.log \u251c\u2500\u2500 gtdbtk.warnings.log \u251c\u2500\u2500 gtdb.translation_table_summary.tsv \u2514\u2500\u2500 identify \u251c\u2500\u2500 gtdb.ar122.markers_summary.tsv \u251c\u2500\u2500 gtdb.bac120.markers_summary.tsv \u251c\u2500\u2500 gtdb.translation_table_summary.tsv \u2514\u2500\u2500 intermediate_results \u2514\u2500\u2500 marker_genes \u2514\u2500\u2500 ${SAMPLE_NAME} \u251c\u2500\u2500 prodigal_translation_table.tsv \u251c\u2500\u2500 prodigal_translation_table.tsv.sha256 \u251c\u2500\u2500 ${SAMPLE_NAME}_pfam_tophit.tsv \u251c\u2500\u2500 ${SAMPLE_NAME}_pfam_tophit.tsv.sha256 \u251c\u2500\u2500 ${SAMPLE_NAME}_pfam.tsv \u251c\u2500\u2500 ${SAMPLE_NAME}_pfam.tsv.sha256 \u251c\u2500\u2500 ${SAMPLE_NAME}_protein.faa \u251c\u2500\u2500 ${SAMPLE_NAME}_protein.faa.sha256 \u251c\u2500\u2500 ${SAMPLE_NAME}_protein.fna \u251c\u2500\u2500 ${SAMPLE_NAME}_protein.fna.sha256 \u251c\u2500\u2500 ${SAMPLE_NAME}_protein.gff \u251c\u2500\u2500 ${SAMPLE_NAME}_protein.gff.sha256 \u251c\u2500\u2500 ${SAMPLE_NAME}_tigrfam.out \u251c\u2500\u2500 ${SAMPLE_NAME}_tigrfam.out.sha256 \u251c\u2500\u2500 ${SAMPLE_NAME}_tigrfam_tophit.tsv \u251c\u2500\u2500 ${SAMPLE_NAME}_tigrfam_tophit.tsv.sha256 \u251c\u2500\u2500 ${SAMPLE_NAME}_tigrfam.tsv \u2514\u2500\u2500 ${SAMPLE_NAME}_tigrfam.tsv.sha256 Filename Description gtdb.(ar122|bac120).classify.tree Reference tree in Newick format containing query genomes placed with pplacer gtdb.(ar122|bac120).filtered.tsv List of genomes with an insufficient number of amino acids in MSA gtdb.(ar122|bac120).markers_summary.tsv Markers used in generation of the concatenated MSA and the order in which they were applied gtdb.(ar122|bac120).msa.fasta FASTA file containing MSA of submitted and reference genomes gtdb.(ar122|bac120).summary.tsv A summary of classifications provided by GTDB-Tk, see classification summary for more details gtdb.(ar122|bac120).user_msa.fasta FASTA file containing MSA of the submitted genomes gtdbtk.log A log of the run gtdbtk.warnings.log A log of any warnings produced by the run gtdb.translation_table_summary.tsv Summary of the tranlastlation table used for each genome","title":"Output Overview"},{"location":"bactopia-tools/gtdb/#directory-description","text":"","title":"Directory Description"},{"location":"bactopia-tools/gtdb/#align","text":"Filename Description gtdb.(ar122|bac120).filtered.tsv List of genomes with an insufficient number of amino acids in MSA gtdb.(ar122|bac120).msa.fasta FASTA file containing MSA of submitted and reference genomes gtdb.(ar122|bac120).user_msa.fasta FASTA file containing MSA of the submitted genomes gtdb.(ar122|bac120).marker_info.tsv Markers used in generation of the concatenated MSA and the order in which they were applied","title":"align"},{"location":"bactopia-tools/gtdb/#bactopia-info","text":"Filename Description gtdb-report.html The Nextflow Execution Report gtdb-timeline.html The Nextflow Timeline Report gtdb-trace.txt The Nextflow Trace report","title":"bactopia-info"},{"location":"bactopia-tools/gtdb/#classify","text":"Filename Description gtdb.(ar122|bac120).classify.tree Reference tree in Newick format containing query genomes placed with pplacer gtdb.(ar122|bac120).summary.tsv Classification of query genomes based on their placement in the reference tree, relative evolutionary divergence, and ANI to reference genomes gtdb.(ar122|bac120).classification_pplacer.tsv Classification of query genomes based only on their placement in the reference tree gtdb.(ar122|bac120).red_dictionary.tsv Median RED values for taxonomic ranks pplacer.(ar122|bac120).json Output information generated by pplacer in JSON format pplacer.(ar122|bac120).out Output information generated by pplacer","title":"classify"},{"location":"bactopia-tools/gtdb/#identify","text":"Filename Description gtdb.ar122.markers_summary.tsv Summary of unique, duplicated, and missing markers within the 122 archaeal marker set for each submitted genome gtdb.bac120.markers_summary.tsv Summary of unique, duplicated, and missing markers within the 120 bacterial marker set for each submitted genome gtdb.translation_table_summary.tsv The predicted translation table used for gene calling for each genome identify/intermediate_results/marker_genes/ Contains individual genome results for gene calling using Prodigal and gene identification based on TIGRFAM and Pfam HMMs","title":"identify"},{"location":"bactopia-tools/gtdb/#usage","text":"Required Parameters: --bactopia STR Directory containing Bactopia analysis results for all samples. --gtdb STR Location of a GTDB database. If a database is not found, you must use '--download_gtdb'. Optional Parameters: --include STR A text file containing sample names to include in the analysis. The expected format is a single sample per line. --exclude STR A text file containing sample names to exclude from the analysis. The expected format is a single sample per line. --prefix DIR Prefix to use for final output files Default: gtdb --outdir DIR Directory to write results to Default: ./ --max_time INT The maximum number of minutes a job should run before being halted. Default: 120 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single process. Default: 32 Gb --cpus INT Number of processors made available to a single process. Default: 1 GTDB-Tk Related Parameters: --download_gtdb Download the latest GTDB database, even it exists. --min_perc_aa INT Filter genomes with an insufficient percentage of AA in the MSA Default: 10 --recalculate_red Recalculate RED values based on the reference tree and all added user genomes --force_gtdb Force GTDB to continue processing if an error occurrs on a single genome --debug Create intermediate files for debugging purposes Nextflow Related Parameters: --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: false --conatainerPath Path to Singularity containers to be used by the 'slurm' profile. Default: /opt/bactopia/singularity --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds Useful Parameters: --version Print workflow version information --help Show this message and exit","title":"Usage"},{"location":"bactopia-tools/gtdb/#conda-environment","text":"Below is the command used to create the Conda environment. conda create -y -n bactopia-gtdb -c conda-forge -c bioconda gtdbtk","title":"Conda Environment"},{"location":"bactopia-tools/gtdb/#references","text":"FastANI Jain, C., Rodriguez-R, L. M., Phillippy, A. M., Konstantinidis, K. T. & Aluru, S. High throughput ANI analysis of 90K prokaryotic genomes reveals clear species boundaries. Nat. Commun. 9, 5114 (2018) FastTree 2 Price, M. N., Dehal, P. S. & Arkin, A. P. FastTree 2 \u2013 Approximately Maximum-Likelihood Trees for Large Alignments. PLoS One 5, e9490 (2010) Genome Taxonomy Database Parks, D. H. et al. A standardized bacterial taxonomy based on genome phylogeny substantially revises the tree of life. Nat. Biotechnol. 36, 996\u20131004 (2018) _ _Parks, D. H. et al. Selection of representative genomes for 24,706 bacterial and archaeal species clusters provide a complete genome-based taxonomy. bioRxiv 771964 (2019) GTDB-Tk Chaumeil, P.-A., Mussig, A. J., Hugenholtz, P. & Parks, D. H. GTDB-Tk: a toolkit to classify genomes with the Genome Taxonomy Database. Bioinformatics (2019) HMMER3 Eddy, S. R. Accelerated Profile HMM Searches. PLoS Comput. Biol. 7, e1002195 (2011) pplacer Matsen, F. A., Kodner, R. B. & Armbrust, E. V. pplacer: linear time maximum-likelihood and Bayesian phylogenetic placement of sequences onto a fixed reference tree. BMC Bioinformatics 11, 538 (2010) Prodigal Hyatt, D. et al. Prodigal: prokaryotic gene recognition and translation initiation site identification. BMC Bioinformatics 11, 119 (2010)","title":"References"},{"location":"bactopia-tools/hicap/","text":"Bactopia Tools - hicap \u00b6 The hicap tool uses hicap for the in-silico typing of the H. influenzae cap locus. Example \u00b6 The following command will run hicap on each available sample. bactopia tools hicap --bactopia ~/bactopia-tutorial/bactopia Output Overview \u00b6 Below is the default output structure for the hicap tool. Where possible the file descriptions below were modified from a tools description . bactopia-tools/ \u2514\u2500\u2500 hicap/ \u2514\u2500\u2500 ${PREFIX}/ \u251c\u2500\u2500 bactopia-info \u2502 \u251c\u2500\u2500 hicap-report.html \u2502 \u251c\u2500\u2500 hicap-timeline.html \u2502 \u2514\u2500\u2500 hicap-trace.txt \u2514\u2500\u2500 ${SAMPLE_NAME} \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}.gbk \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}.svg \u2502 \u2514\u2500\u2500 ${SAMPLE_NAME}.tsv \u2514\u2500\u2500 hicap-results.txt Below is a description of hicap outputs. Filename Description hicap-results.txt Merged set of outputs from hicap Directory Description \u00b6 bactopia-info \u00b6 Filename Description hicap-report.html The Nextflow Execution Report hicap-timeline.html The Nextflow Timeline Report hicap-trace.txt The Nextflow Trace report Per Sample \u00b6 Extension Description .gbk GenBank file with sequence marked up with cap locus annotations .svg visual representation of the annotated cap locus .tsv detailed summary information Usage \u00b6 Required Parameters: --bactopia STR Directory containing Bactopia analysis results for all samples. hicap Related Parameters --database_dir STR Directory containing locus database. Default: Use hicap's default --model_fp STR Path to prodigal model. Default: Use hicap's default --full_sequence BOOL Write the full input sequence out to the genbank file rather than just the region surrounding and including the locus --gene_coverage FLOAT Minimum percentage coverage to consider a single gene complete. Default: 0.8 --gene_identity FLOAT Minimum percentage identity to consider a single gene complete. Default: 0.7 --broken_gene_length INT Minimum length to consider a broken gene. Default: 60 --broken_gene_identity FLOAT Minimum percentage identity to consider a broken gene Default: 0.8 --log_fp Record logging messages to file --debug Print debug messages Optional Parameters: --include STR A text file containing sample names to include in the analysis. The expected format is a single sample per line. --exclude STR A text file containing sample names to exclude from the analysis. The expected format is a single sample per line. --prefix DIR Prefix to use for final output files Default: hicap --outdir DIR Directory to write results to Default: ./ --min_time INT The minimum number of minutes a job should run before being halted. Default: 60 minutes --max_time INT The maximum number of minutes a job should run before being halted. Default: 120 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single process. Default: 32 Gb --cpus INT Number of processors made available to a single process. Default: 1 Nextflow Related Parameters: --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --registry STR Docker registry to pull containers from. Available options: dockerhub, quay, or github Default: dockerhub --singularity_cache STR Directory where remote Singularity images are stored. If using a cluster, it must be accessible from all compute nodes. Default: NXF_SINGULARITY_CACHEDIR evironment variable, otherwise /local/home/rpetit/.bactopia/singularity --queue STR The name of the queue(s) to be used by a job scheduler (e.g. AWS Batch or SLURM). If using multiple queues, please seperate queues by a comma without spaces. Default: general --disable_scratch All intermediate files created on worker nodes of will be transferred to the head node. Default: Only result files are transferred back --cleanup_workdir After Bactopia is successfully executed, the work directory will be deleted. Warning: by doing this you lose the ability to resume workflows. --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: true --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds --nfconfig STR A Nextflow compatible config file for custom profiles. This allows you to create profiles specific to your environment (e.g. SGE, AWS, SLURM, etc...). This config file is loaded last and will overwrite existing variables if set. Default: Bactopia's default configs -resume Nextflow will attempt to resume a previous run. Please notice it is only a single '-' AWS Batch Related Parameters: --aws_region STR AWS Region to be used by Nextflow Default: us-east-1 --aws_volumes STR Volumes to be mounted from the EC2 instance to the Docker container Default: /opt/conda:/mnt/conda --aws_cli_path STR Path to the AWS CLI for Nextflow to use. Default: /home/ec2-user/conda/bin/aws --aws_upload_storage_class STR The S3 storage slass to use for storing files on S3 Default: STANDARD --aws_max_parallel_transfers INT The number of parallele transfers between EC2 and S3 Default: 8 --aws_delay_between_attempts INT The duration of sleep (in seconds) between each transfer between EC2 and S3 Default: 15 --aws_max_transfer_attempts INT The maximum number of times to retry transferring a file between EC2 and S3 Default: 3 --aws_max_retry INT The maximum number of times to retry a process on AWS Batch Default: 4 --aws_ecr_registry STR The ECR registry containing Bactopia related containers. Default: Use the registry given by --registry Useful Parameters: --version Print workflow version information --help Show this message and exit Conda Environment \u00b6 Below is the command used to create the Conda environment. conda create -n hicap -c conda-forge -c bioconda hicap References \u00b6 hicap in silico typing of the H. influenzae cap locus Watts S. C. and Holt K. E. hicap: in silico serotyping of the Haemophilus influenzae capsule locus. Journal of Clinical Microbiology, JCM.00190-19 (2019).","title":"hicap"},{"location":"bactopia-tools/hicap/#bactopia-tools-hicap","text":"The hicap tool uses hicap for the in-silico typing of the H. influenzae cap locus.","title":"Bactopia Tools - hicap"},{"location":"bactopia-tools/hicap/#example","text":"The following command will run hicap on each available sample. bactopia tools hicap --bactopia ~/bactopia-tutorial/bactopia","title":"Example"},{"location":"bactopia-tools/hicap/#output-overview","text":"Below is the default output structure for the hicap tool. Where possible the file descriptions below were modified from a tools description . bactopia-tools/ \u2514\u2500\u2500 hicap/ \u2514\u2500\u2500 ${PREFIX}/ \u251c\u2500\u2500 bactopia-info \u2502 \u251c\u2500\u2500 hicap-report.html \u2502 \u251c\u2500\u2500 hicap-timeline.html \u2502 \u2514\u2500\u2500 hicap-trace.txt \u2514\u2500\u2500 ${SAMPLE_NAME} \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}.gbk \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}.svg \u2502 \u2514\u2500\u2500 ${SAMPLE_NAME}.tsv \u2514\u2500\u2500 hicap-results.txt Below is a description of hicap outputs. Filename Description hicap-results.txt Merged set of outputs from hicap","title":"Output Overview"},{"location":"bactopia-tools/hicap/#directory-description","text":"","title":"Directory Description"},{"location":"bactopia-tools/hicap/#bactopia-info","text":"Filename Description hicap-report.html The Nextflow Execution Report hicap-timeline.html The Nextflow Timeline Report hicap-trace.txt The Nextflow Trace report","title":"bactopia-info"},{"location":"bactopia-tools/hicap/#per-sample","text":"Extension Description .gbk GenBank file with sequence marked up with cap locus annotations .svg visual representation of the annotated cap locus .tsv detailed summary information","title":"Per Sample"},{"location":"bactopia-tools/hicap/#usage","text":"Required Parameters: --bactopia STR Directory containing Bactopia analysis results for all samples. hicap Related Parameters --database_dir STR Directory containing locus database. Default: Use hicap's default --model_fp STR Path to prodigal model. Default: Use hicap's default --full_sequence BOOL Write the full input sequence out to the genbank file rather than just the region surrounding and including the locus --gene_coverage FLOAT Minimum percentage coverage to consider a single gene complete. Default: 0.8 --gene_identity FLOAT Minimum percentage identity to consider a single gene complete. Default: 0.7 --broken_gene_length INT Minimum length to consider a broken gene. Default: 60 --broken_gene_identity FLOAT Minimum percentage identity to consider a broken gene Default: 0.8 --log_fp Record logging messages to file --debug Print debug messages Optional Parameters: --include STR A text file containing sample names to include in the analysis. The expected format is a single sample per line. --exclude STR A text file containing sample names to exclude from the analysis. The expected format is a single sample per line. --prefix DIR Prefix to use for final output files Default: hicap --outdir DIR Directory to write results to Default: ./ --min_time INT The minimum number of minutes a job should run before being halted. Default: 60 minutes --max_time INT The maximum number of minutes a job should run before being halted. Default: 120 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single process. Default: 32 Gb --cpus INT Number of processors made available to a single process. Default: 1 Nextflow Related Parameters: --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --registry STR Docker registry to pull containers from. Available options: dockerhub, quay, or github Default: dockerhub --singularity_cache STR Directory where remote Singularity images are stored. If using a cluster, it must be accessible from all compute nodes. Default: NXF_SINGULARITY_CACHEDIR evironment variable, otherwise /local/home/rpetit/.bactopia/singularity --queue STR The name of the queue(s) to be used by a job scheduler (e.g. AWS Batch or SLURM). If using multiple queues, please seperate queues by a comma without spaces. Default: general --disable_scratch All intermediate files created on worker nodes of will be transferred to the head node. Default: Only result files are transferred back --cleanup_workdir After Bactopia is successfully executed, the work directory will be deleted. Warning: by doing this you lose the ability to resume workflows. --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: true --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds --nfconfig STR A Nextflow compatible config file for custom profiles. This allows you to create profiles specific to your environment (e.g. SGE, AWS, SLURM, etc...). This config file is loaded last and will overwrite existing variables if set. Default: Bactopia's default configs -resume Nextflow will attempt to resume a previous run. Please notice it is only a single '-' AWS Batch Related Parameters: --aws_region STR AWS Region to be used by Nextflow Default: us-east-1 --aws_volumes STR Volumes to be mounted from the EC2 instance to the Docker container Default: /opt/conda:/mnt/conda --aws_cli_path STR Path to the AWS CLI for Nextflow to use. Default: /home/ec2-user/conda/bin/aws --aws_upload_storage_class STR The S3 storage slass to use for storing files on S3 Default: STANDARD --aws_max_parallel_transfers INT The number of parallele transfers between EC2 and S3 Default: 8 --aws_delay_between_attempts INT The duration of sleep (in seconds) between each transfer between EC2 and S3 Default: 15 --aws_max_transfer_attempts INT The maximum number of times to retry transferring a file between EC2 and S3 Default: 3 --aws_max_retry INT The maximum number of times to retry a process on AWS Batch Default: 4 --aws_ecr_registry STR The ECR registry containing Bactopia related containers. Default: Use the registry given by --registry Useful Parameters: --version Print workflow version information --help Show this message and exit","title":"Usage"},{"location":"bactopia-tools/hicap/#conda-environment","text":"Below is the command used to create the Conda environment. conda create -n hicap -c conda-forge -c bioconda hicap","title":"Conda Environment"},{"location":"bactopia-tools/hicap/#references","text":"hicap in silico typing of the H. influenzae cap locus Watts S. C. and Holt K. E. hicap: in silico serotyping of the Haemophilus influenzae capsule locus. Journal of Clinical Microbiology, JCM.00190-19 (2019).","title":"References"},{"location":"bactopia-tools/ismapper/","text":"Bactopia Tools - ismapper \u00b6 The ismapper tool uses ISMapper to search for insertion sites in your samples. Example \u00b6 The following command will run ismapper on each available sample. bactopia tools ismapper --bactopia ~/bactopia-tutorial/bactopia \\ --reference ~/bactopia-tutorial/bactopia-datasets/ismapper/reference.gbk \\ --insertions ~/bactopia-tutorial/bactopia-datasets/ismapper/insertions.fasta \\ --cpus 4 Output Overview \u00b6 Below is the default output structure for the ismapper tool. Where possible the file descriptions below were modified from a tools description. bactopia-tools/ \u2514\u2500\u2500 ismapper/ \u2514\u2500\u2500 ${PREFIX}/ \u251c\u2500\u2500 bactopia-info \u2502 \u251c\u2500\u2500 ismapper-report.html \u2502 \u251c\u2500\u2500 ismapper-timeline.html \u2502 \u2514\u2500\u2500 ismapper-trace.txt \u2514\u2500\u2500 ${SAMPLE_NAME} \u2502 \u251c\u2500\u2500 ${INSERTION_NAME} \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}_${INSERTION_NAME}_(left|right)_final.fastq \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}_(left|right)_${SAMPLE_NAME}_${CONTIG_NUMBER}_finalcov.bed \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}_(left|right)_${SAMPLE_NAME}_${CONTIG_NUMBER}_merged.sorted.bed \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}_(left|right)_${SAMPLE_NAME}_${CONTIG_NUMBER}.sorted.bam \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}_(left|right)_${SAMPLE_NAME}_${CONTIG_NUMBER}.sorted.bam.bai \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}_(left|right)_${SAMPLE_NAME}_${CONTIG_NUMBER}_unpaired.bed \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}__${SAMPLE_NAME}_${CONTIG_NUMBER}_closest.bed \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}__${SAMPLE_NAME}_${CONTIG_NUMBER}_intersect.bed \u2502 \u2502 \u2514\u2500\u2500 ${SAMPLE_NAME}__${SAMPLE_NAME}_${CONTIG_NUMBER}_table.txt \u2502 \u2514\u2500\u2500 ${SAMPLE_NAME}-${INSERTION_NAME}.log \u2514\u2500\u2500 genbank \u2514\u2500\u2500 ${REFERENCE_NAME}.gbk Below is a description of ISMapper outputs. Extension Description _final.fastq Sequences (FASTQ format) that mapped to the flanking regions of the IS query _finalcov.bed Contains information about the coverage of the IS query _merged.sorted.bed Merged overlapping regions that passed coverage cutoffs .sorted.bam Reads mapped to the IS query. .sorted.bam.bai An index of the sorted BAM file. _unpaired.bed All unpaired mappings to the IS query _closest.bed Merged regions that are close but do not overlap _intersect.bed An intersection of merged regions from the left and right flanks. _table.txt A detailed description of the IS query results. .log Information logged during the execution of ISMapper Directory Description \u00b6 bactopia-info \u00b6 Filename Description TOOL_NAME-report.html The Nextflow Execution Report TOOL_NAME-timeline.html The Nextflow Timeline Report TOOL_NAME-trace.txt The Nextflow Trace report genbank \u00b6 Dxtension Description .gbk The reference used for analysis Usage \u00b6 Required Parameters: --bactopia STR Directory containing Bactopia analysis results for all samples. --insertions STR Multifasta file with insertion sequence(s) to be mapped to. *Note: --reference or --accession is required.* --reference STR Reference genome for typing against in GenBank format. --accession STR The Assembly accession (e.g. GC(A|F)*.*) of the reference to download from RefSeq. Optional Parameters: --include STR A text file containing sample names to include in the analysis. The expected format is a single sample per line. --exclude STR A text file containing sample names to exclude from the analysis. The expected format is a single sample per line. --prefix DIR Prefix to use for final output files Default: TOOL_NAME --outdir DIR Directory to write results to Default: ./ --max_time INT The maximum number of minutes a job should run before being halted. Default: 120 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single process. Default: 32 Gb --cpus INT Number of processors made available to a single process. Default: 1 ISMapper Parameters: --min_clip INT Minimum size for softclipped region to be extracted from initial mapping Default: 10 --max_clip INT Maximum size for softclipped regions to be included Default: 30 --cutoff INT Minimum depth for mapped region to be kept in bed file Default: 6 --novel_gap_size INT Distance in base pairs between left and right flanks to be called a novel hit Default: 15 --min_range FLOAT Minimum percent size of the gap to be called a known hit Default: 0.9 --max_range FLOAT Maximum percent size of the gap to be called a known hit Default: 1.1 --merging INT Value for merging left and right hits in bed files together to simply calculation of closest and intersecting regions Default: 100 --ismap_all Switch on all alignment reporting for bwa --ismap_minqual INT Mapping quality score for bwa Default: 30 Nextflow Related Parameters: --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: false --conatainerPath Path to Singularity containers to be used by the 'slurm' profile. Default: /opt/bactopia/singularity --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds --nfconfig STR A Nextflow compatible config file for custom profiles. This allows you to create profiles specific to your environment (e.g. SGE, AWS, SLURM, etc...). This config file is loaded last and will overwrite existing variables if set. Default: Bactopia's default configs -resume Nextflow will attempt to resume a previous run. Please notice it is only a single '-' Useful Parameters: --version Print workflow version information --help Show this message and exit Conda Environment \u00b6 Below is the command used to create the Conda environment. conda create -n ismapper -c conda-forge -c bioconda ismapper References \u00b6 Bedtools A powerful toolset for genome arithmetic. Quinlan, A. R. & Hall, I. M. BEDTools: a flexible suite of utilities for comparing genomic features . Bioinformatics 26, 841\u2013842 (2010). BLAST Basic Local Alignment Search Tool Camacho, C. et al. BLAST+: architecture and applications . BMC Bioinformatics 10, 421 (2009). BWA Burrow-Wheeler Aligner for short-read alignment Li, H. Aligning sequence reads, clone sequences and assembly contigs with BWA-MEM . arXiv [q-bio.GN] (2013). ISMapper IS mapping software Hawkey, J. et al. ISMapper: identifying transposase insertion sites in bacterial genomes from short read sequence data . BMC Genomics 16, 667 (2015). Samtools Tools for manipulating next-generation sequencing data Li, H. et al. The Sequence Alignment/Map format and SAMtools . Bioinformatics 25, 2078\u20132079 (2009).","title":"ismapper"},{"location":"bactopia-tools/ismapper/#bactopia-tools-ismapper","text":"The ismapper tool uses ISMapper to search for insertion sites in your samples.","title":"Bactopia Tools - ismapper"},{"location":"bactopia-tools/ismapper/#example","text":"The following command will run ismapper on each available sample. bactopia tools ismapper --bactopia ~/bactopia-tutorial/bactopia \\ --reference ~/bactopia-tutorial/bactopia-datasets/ismapper/reference.gbk \\ --insertions ~/bactopia-tutorial/bactopia-datasets/ismapper/insertions.fasta \\ --cpus 4","title":"Example"},{"location":"bactopia-tools/ismapper/#output-overview","text":"Below is the default output structure for the ismapper tool. Where possible the file descriptions below were modified from a tools description. bactopia-tools/ \u2514\u2500\u2500 ismapper/ \u2514\u2500\u2500 ${PREFIX}/ \u251c\u2500\u2500 bactopia-info \u2502 \u251c\u2500\u2500 ismapper-report.html \u2502 \u251c\u2500\u2500 ismapper-timeline.html \u2502 \u2514\u2500\u2500 ismapper-trace.txt \u2514\u2500\u2500 ${SAMPLE_NAME} \u2502 \u251c\u2500\u2500 ${INSERTION_NAME} \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}_${INSERTION_NAME}_(left|right)_final.fastq \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}_(left|right)_${SAMPLE_NAME}_${CONTIG_NUMBER}_finalcov.bed \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}_(left|right)_${SAMPLE_NAME}_${CONTIG_NUMBER}_merged.sorted.bed \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}_(left|right)_${SAMPLE_NAME}_${CONTIG_NUMBER}.sorted.bam \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}_(left|right)_${SAMPLE_NAME}_${CONTIG_NUMBER}.sorted.bam.bai \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}_(left|right)_${SAMPLE_NAME}_${CONTIG_NUMBER}_unpaired.bed \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}__${SAMPLE_NAME}_${CONTIG_NUMBER}_closest.bed \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}__${SAMPLE_NAME}_${CONTIG_NUMBER}_intersect.bed \u2502 \u2502 \u2514\u2500\u2500 ${SAMPLE_NAME}__${SAMPLE_NAME}_${CONTIG_NUMBER}_table.txt \u2502 \u2514\u2500\u2500 ${SAMPLE_NAME}-${INSERTION_NAME}.log \u2514\u2500\u2500 genbank \u2514\u2500\u2500 ${REFERENCE_NAME}.gbk Below is a description of ISMapper outputs. Extension Description _final.fastq Sequences (FASTQ format) that mapped to the flanking regions of the IS query _finalcov.bed Contains information about the coverage of the IS query _merged.sorted.bed Merged overlapping regions that passed coverage cutoffs .sorted.bam Reads mapped to the IS query. .sorted.bam.bai An index of the sorted BAM file. _unpaired.bed All unpaired mappings to the IS query _closest.bed Merged regions that are close but do not overlap _intersect.bed An intersection of merged regions from the left and right flanks. _table.txt A detailed description of the IS query results. .log Information logged during the execution of ISMapper","title":"Output Overview"},{"location":"bactopia-tools/ismapper/#directory-description","text":"","title":"Directory Description"},{"location":"bactopia-tools/ismapper/#bactopia-info","text":"Filename Description TOOL_NAME-report.html The Nextflow Execution Report TOOL_NAME-timeline.html The Nextflow Timeline Report TOOL_NAME-trace.txt The Nextflow Trace report","title":"bactopia-info"},{"location":"bactopia-tools/ismapper/#genbank","text":"Dxtension Description .gbk The reference used for analysis","title":"genbank"},{"location":"bactopia-tools/ismapper/#usage","text":"Required Parameters: --bactopia STR Directory containing Bactopia analysis results for all samples. --insertions STR Multifasta file with insertion sequence(s) to be mapped to. *Note: --reference or --accession is required.* --reference STR Reference genome for typing against in GenBank format. --accession STR The Assembly accession (e.g. GC(A|F)*.*) of the reference to download from RefSeq. Optional Parameters: --include STR A text file containing sample names to include in the analysis. The expected format is a single sample per line. --exclude STR A text file containing sample names to exclude from the analysis. The expected format is a single sample per line. --prefix DIR Prefix to use for final output files Default: TOOL_NAME --outdir DIR Directory to write results to Default: ./ --max_time INT The maximum number of minutes a job should run before being halted. Default: 120 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single process. Default: 32 Gb --cpus INT Number of processors made available to a single process. Default: 1 ISMapper Parameters: --min_clip INT Minimum size for softclipped region to be extracted from initial mapping Default: 10 --max_clip INT Maximum size for softclipped regions to be included Default: 30 --cutoff INT Minimum depth for mapped region to be kept in bed file Default: 6 --novel_gap_size INT Distance in base pairs between left and right flanks to be called a novel hit Default: 15 --min_range FLOAT Minimum percent size of the gap to be called a known hit Default: 0.9 --max_range FLOAT Maximum percent size of the gap to be called a known hit Default: 1.1 --merging INT Value for merging left and right hits in bed files together to simply calculation of closest and intersecting regions Default: 100 --ismap_all Switch on all alignment reporting for bwa --ismap_minqual INT Mapping quality score for bwa Default: 30 Nextflow Related Parameters: --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: false --conatainerPath Path to Singularity containers to be used by the 'slurm' profile. Default: /opt/bactopia/singularity --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds --nfconfig STR A Nextflow compatible config file for custom profiles. This allows you to create profiles specific to your environment (e.g. SGE, AWS, SLURM, etc...). This config file is loaded last and will overwrite existing variables if set. Default: Bactopia's default configs -resume Nextflow will attempt to resume a previous run. Please notice it is only a single '-' Useful Parameters: --version Print workflow version information --help Show this message and exit","title":"Usage"},{"location":"bactopia-tools/ismapper/#conda-environment","text":"Below is the command used to create the Conda environment. conda create -n ismapper -c conda-forge -c bioconda ismapper","title":"Conda Environment"},{"location":"bactopia-tools/ismapper/#references","text":"Bedtools A powerful toolset for genome arithmetic. Quinlan, A. R. & Hall, I. M. BEDTools: a flexible suite of utilities for comparing genomic features . Bioinformatics 26, 841\u2013842 (2010). BLAST Basic Local Alignment Search Tool Camacho, C. et al. BLAST+: architecture and applications . BMC Bioinformatics 10, 421 (2009). BWA Burrow-Wheeler Aligner for short-read alignment Li, H. Aligning sequence reads, clone sequences and assembly contigs with BWA-MEM . arXiv [q-bio.GN] (2013). ISMapper IS mapping software Hawkey, J. et al. ISMapper: identifying transposase insertion sites in bacterial genomes from short read sequence data . BMC Genomics 16, 667 (2015). Samtools Tools for manipulating next-generation sequencing data Li, H. et al. The Sequence Alignment/Map format and SAMtools . Bioinformatics 25, 2078\u20132079 (2009).","title":"References"},{"location":"bactopia-tools/mashtree/","text":"Bactopia Tools - mashtree \u00b6 The mashtree tool allows you to create a tree of your samples using Mashtree . Often times, you may also want to see how your samples compare to completed genomes. This is possible with the mashtree tool. If you use the --species parameter, all completed genomes available from RefSeq will be downloaded with ncbi-genome-download and included in your tree. Example \u00b6 The following command will run Mashtree on a set of Bactopia samples, as well as all completed Bacillus cereus genomes from RefSeq. bactopia tools mashree \\ --bactopia ~/bactopia-tutorial/bactopia \\ --species \"Bacillus cereus\" \\ --cpus 4 Output Overview \u00b6 Below is the default output structure for the mashtree tool. Where possible the file descriptions below were modified from a tools description. bactopia-tools/ \u2514\u2500\u2500 mashtree \u2514\u2500\u2500 ${PREFIX} \u251c\u2500\u2500 bactopia-info \u2502 \u251c\u2500\u2500 mashtree-report.html \u2502 \u251c\u2500\u2500 mashtree-timeline.html \u2502 \u2514\u2500\u2500 mashtree-trace.txt \u251c\u2500\u2500 refseq \u2502 \u2514\u2500\u2500 fasta \u2502 \u2514\u2500\u2500 ${SAMPLE_NAME}.fna \u251c\u2500\u2500 ${PREFIX}-mashtree.dnd \u2514\u2500\u2500 ${PREFIX}-matrix.txt Filename Description ${PREFIX}-mashtree.dnd A newick formatted tree based on Mash distances ${PREFIX}-matrix.txt Pair-wise Mash distance for each sample Directory Description \u00b6 bactopia-info \u00b6 Filename Description mashtree-report.html The Nextflow Execution Report mashtree-timeline.html The Nextflow Timeline Report mashtree-trace.txt The Nextflow Trace report refseq \u00b6 Extension Description .fna FASTA formated genome downloaded from NCBI Assembly database. Usage \u00b6 Required Parameters: --bactopia STR Directory containing Bactopia analysis results for all samples. Optional Parameters: --include STR A text file containing sample names to include in the analysis. The expected format is a single sample per line. --exclude STR A text file containing sample names to exclude from the analysis. The expected format is a single sample per line. --prefix DIR Prefix to use for final output files Default: mashtree --outdir DIR Directory to write results to Default: ./ --max_time INT The maximum number of minutes a job should run before being halted. Default: 120 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single process. Default: 32 Gb --cpus INT Number of processors made available to a single process. Default: 1 RefSeq Assemblies Related Parameters: This is a completely optional step and is meant to supplement your dataset with high-quality completed genomes. --species STR The name of the species to download RefSeq assemblies for. --accession STR The Assembly accession (e.g. GCF*.*) download from RefSeq. --limit INT Limit the number of RefSeq assemblies to download. If the the number of available genomes exceeds the given limit, a random subset will be selected. Default: Download all available genomes User Procided Reference: --reference STR A reference genome to calculate Mashtree Related Parameters --trunclength INT How many characters to keep in a filename Default: 250 --sortorder STR For neighbor-joining, the sort order can make a difference. Options include: ABC (alphabetical), random, input-order Default: ABC --genomesize INT Genome size of the input samples. Default: 5000000 --mindepth INT If mindepth is zero, then it will be chosen in a smart but slower method, to discard lower-abundance kmers. Default: 5 --kmerlength INT Hashes will be based on strings of this many nucleotides. Default: 21 --sketchsize INT Each sketch will have at most this many non-redundant min-hashes. Default: 10000 Nextflow Related Parameters: --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: false --conatainerPath Path to Singularity containers to be used by the 'slurm' profile. Default: /opt/bactopia/singularity --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds --nfconfig STR A Nextflow compatible config file for custom profiles. This allows you to create profiles specific to your environment (e.g. SGE, AWS, SLURM, etc...). This config file is loaded last and will overwrite existing variables if set. Default: Bactopia's default configs -resume Nextflow will attempt to resume a previous run. Please notice it is only a single '-' Useful Parameters: --version Print workflow version information --help Show this message and exit Conda Environment \u00b6 Below is the command that was used to create the Conda environment. conda create -n bactopia-mashtree -c conda-forge -c bioconda \\ mashtree \\ ncbi-genome-download \\ rename References \u00b6 Mash Ondov, B. D. et al. Mash: fast genome and metagenome distance estimation using MinHash . Genome Biol. 17, 132 (2016). Mashtree Katz, L. S., Griswold, T., Morrison, S., Caravas, J., Zhang, S., den Bakker, H.C., Deng, X., and Carleton, H. A. Mashtree: a rapid comparison of whole genome sequence files. Journal of Open Source Software, 4(44), 1762, (2019) ncbi-genome-download Blin, K. ncbi-genome-download: Scripts to download genomes from the NCBI FTP servers","title":"mashtree"},{"location":"bactopia-tools/mashtree/#bactopia-tools-mashtree","text":"The mashtree tool allows you to create a tree of your samples using Mashtree . Often times, you may also want to see how your samples compare to completed genomes. This is possible with the mashtree tool. If you use the --species parameter, all completed genomes available from RefSeq will be downloaded with ncbi-genome-download and included in your tree.","title":"Bactopia Tools - mashtree"},{"location":"bactopia-tools/mashtree/#example","text":"The following command will run Mashtree on a set of Bactopia samples, as well as all completed Bacillus cereus genomes from RefSeq. bactopia tools mashree \\ --bactopia ~/bactopia-tutorial/bactopia \\ --species \"Bacillus cereus\" \\ --cpus 4","title":"Example"},{"location":"bactopia-tools/mashtree/#output-overview","text":"Below is the default output structure for the mashtree tool. Where possible the file descriptions below were modified from a tools description. bactopia-tools/ \u2514\u2500\u2500 mashtree \u2514\u2500\u2500 ${PREFIX} \u251c\u2500\u2500 bactopia-info \u2502 \u251c\u2500\u2500 mashtree-report.html \u2502 \u251c\u2500\u2500 mashtree-timeline.html \u2502 \u2514\u2500\u2500 mashtree-trace.txt \u251c\u2500\u2500 refseq \u2502 \u2514\u2500\u2500 fasta \u2502 \u2514\u2500\u2500 ${SAMPLE_NAME}.fna \u251c\u2500\u2500 ${PREFIX}-mashtree.dnd \u2514\u2500\u2500 ${PREFIX}-matrix.txt Filename Description ${PREFIX}-mashtree.dnd A newick formatted tree based on Mash distances ${PREFIX}-matrix.txt Pair-wise Mash distance for each sample","title":"Output Overview"},{"location":"bactopia-tools/mashtree/#directory-description","text":"","title":"Directory Description"},{"location":"bactopia-tools/mashtree/#bactopia-info","text":"Filename Description mashtree-report.html The Nextflow Execution Report mashtree-timeline.html The Nextflow Timeline Report mashtree-trace.txt The Nextflow Trace report","title":"bactopia-info"},{"location":"bactopia-tools/mashtree/#refseq","text":"Extension Description .fna FASTA formated genome downloaded from NCBI Assembly database.","title":"refseq"},{"location":"bactopia-tools/mashtree/#usage","text":"Required Parameters: --bactopia STR Directory containing Bactopia analysis results for all samples. Optional Parameters: --include STR A text file containing sample names to include in the analysis. The expected format is a single sample per line. --exclude STR A text file containing sample names to exclude from the analysis. The expected format is a single sample per line. --prefix DIR Prefix to use for final output files Default: mashtree --outdir DIR Directory to write results to Default: ./ --max_time INT The maximum number of minutes a job should run before being halted. Default: 120 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single process. Default: 32 Gb --cpus INT Number of processors made available to a single process. Default: 1 RefSeq Assemblies Related Parameters: This is a completely optional step and is meant to supplement your dataset with high-quality completed genomes. --species STR The name of the species to download RefSeq assemblies for. --accession STR The Assembly accession (e.g. GCF*.*) download from RefSeq. --limit INT Limit the number of RefSeq assemblies to download. If the the number of available genomes exceeds the given limit, a random subset will be selected. Default: Download all available genomes User Procided Reference: --reference STR A reference genome to calculate Mashtree Related Parameters --trunclength INT How many characters to keep in a filename Default: 250 --sortorder STR For neighbor-joining, the sort order can make a difference. Options include: ABC (alphabetical), random, input-order Default: ABC --genomesize INT Genome size of the input samples. Default: 5000000 --mindepth INT If mindepth is zero, then it will be chosen in a smart but slower method, to discard lower-abundance kmers. Default: 5 --kmerlength INT Hashes will be based on strings of this many nucleotides. Default: 21 --sketchsize INT Each sketch will have at most this many non-redundant min-hashes. Default: 10000 Nextflow Related Parameters: --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: false --conatainerPath Path to Singularity containers to be used by the 'slurm' profile. Default: /opt/bactopia/singularity --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds --nfconfig STR A Nextflow compatible config file for custom profiles. This allows you to create profiles specific to your environment (e.g. SGE, AWS, SLURM, etc...). This config file is loaded last and will overwrite existing variables if set. Default: Bactopia's default configs -resume Nextflow will attempt to resume a previous run. Please notice it is only a single '-' Useful Parameters: --version Print workflow version information --help Show this message and exit","title":"Usage"},{"location":"bactopia-tools/mashtree/#conda-environment","text":"Below is the command that was used to create the Conda environment. conda create -n bactopia-mashtree -c conda-forge -c bioconda \\ mashtree \\ ncbi-genome-download \\ rename","title":"Conda Environment"},{"location":"bactopia-tools/mashtree/#references","text":"Mash Ondov, B. D. et al. Mash: fast genome and metagenome distance estimation using MinHash . Genome Biol. 17, 132 (2016). Mashtree Katz, L. S., Griswold, T., Morrison, S., Caravas, J., Zhang, S., den Bakker, H.C., Deng, X., and Carleton, H. A. Mashtree: a rapid comparison of whole genome sequence files. Journal of Open Source Software, 4(44), 1762, (2019) ncbi-genome-download Blin, K. ncbi-genome-download: Scripts to download genomes from the NCBI FTP servers","title":"References"},{"location":"bactopia-tools/phyloflash/","text":"Bactopia Tools - phyloflash \u00b6 The phyloflash tool uses phyloFlash to resconstruct 16S rRNA genes from your input samples. Optionally these reconstructed genes can then be aligned to one another with MAFFT and a phylogenetic representation created using IQ-TREE Example \u00b6 The following command will reconstruct the 16S rRNA gene for each sample except those listed in the exclude file. bactopia tools phyloflash \\ --bactopia ~/bactopia-tutorial/bactopia \\ --phyloflash ~/bactopia-tutorial/bactopia-datasets/16s/138 \\ --exclude ~/bactopia-tutorial/bactopia-tools/summary/bactopia-exclude.txt Output Overview \u00b6 Below is the default output structure for the phyloflash tool. Where possible the file descriptions below were modified from a tools description. bactopia-tools/ \u2514\u2500\u2500 phyloflash/ \u2514\u2500\u2500 ${PREFIX} \u251c\u2500\u2500 alignment \u2502 \u251c\u2500\u2500 phyloflash-alignment.fasta \u2502 \u2514\u2500\u2500 phyloflash-matches.txt \u251c\u2500\u2500 bactopia-info \u2502 \u251c\u2500\u2500 phyloflash-report.html \u2502 \u251c\u2500\u2500 phyloflash-timeline.html \u2502 \u2514\u2500\u2500 phyloflash-trace.txt \u251c\u2500\u2500 iqtree \u2502 \u251c\u2500\u2500 16s.alninfo \u2502 \u251c\u2500\u2500 16s.bionj \u2502 \u251c\u2500\u2500 16s.ckp.gz \u2502 \u251c\u2500\u2500 16s.iqtree \u2502 \u251c\u2500\u2500 16s.log \u2502 \u251c\u2500\u2500 16s.mldist \u2502 \u251c\u2500\u2500 16s.model.gz \u2502 \u251c\u2500\u2500 16s.treefile \u2502 \u2514\u2500\u2500 16s.uniqueseq.phy \u251c\u2500\u2500 phyloflash.iqtree \u251c\u2500\u2500 phyloflash-summary.txt \u2514\u2500\u2500 samples \u2514\u2500\u2500 ${SAMPLE_NAME} \u251c\u2500\u2500 ${SAMPLE_NAME}.all.dbhits.NR97.fa \u251c\u2500\u2500 ${SAMPLE_NAME}.all.final.fasta \u251c\u2500\u2500 ${SAMPLE_NAME}.all.final.phyloFlash.dbhits.fa \u251c\u2500\u2500 ${SAMPLE_NAME}.all.final.phyloFlash.notmatched.fa \u251c\u2500\u2500 ${SAMPLE_NAME}.all.vsearch.csv \u251c\u2500\u2500 ${SAMPLE_NAME}.assemratio.csv \u251c\u2500\u2500 ${SAMPLE_NAME}.assemratio.csv.svg \u251c\u2500\u2500 ${SAMPLE_NAME}.bbmap.out \u251c\u2500\u2500 ${SAMPLE_NAME}.bbmap.sam \u251c\u2500\u2500 ${SAMPLE_NAME}.hitstats \u251c\u2500\u2500 ${SAMPLE_NAME}.idhistogram \u251c\u2500\u2500 ${SAMPLE_NAME}.idhistogram.svg \u251c\u2500\u2500 ${SAMPLE_NAME}.inserthistogram \u251c\u2500\u2500 ${SAMPLE_NAME}.inserthistogram.svg \u251c\u2500\u2500 ${SAMPLE_NAME}.mapratio.csv \u251c\u2500\u2500 ${SAMPLE_NAME}.mapratio.csv.svg \u251c\u2500\u2500 ${SAMPLE_NAME}.phyloFlash \u251c\u2500\u2500 ${SAMPLE_NAME}.phyloFlash.extractedSSUclassifications.csv \u251c\u2500\u2500 ${SAMPLE_NAME}.phyloFlash.html \u251c\u2500\u2500 ${SAMPLE_NAME}.phyloFlash.json \u251c\u2500\u2500 ${SAMPLE_NAME}.phyloFlash.NTUabundance.csv \u251c\u2500\u2500 ${SAMPLE_NAME}.phyloFlash.NTUabundance.csv.svg \u251c\u2500\u2500 ${SAMPLE_NAME}.phyloFlash.NTUfull_abundance.csv \u251c\u2500\u2500 ${SAMPLE_NAME}.phyloFlash.report.csv \u251c\u2500\u2500 ${SAMPLE_NAME}.phyloFlash.unassembled.NTUabundance.csv \u251c\u2500\u2500 ${SAMPLE_NAME}.remap_spades.bbmap.out \u251c\u2500\u2500 ${SAMPLE_NAME}.spades.out \u251c\u2500\u2500 ${SAMPLE_NAME}.spades_rRNAs.final.fasta \u251c\u2500\u2500 ${SAMPLE_NAME}.${SAMPLE_NAME}_R1.fastq.gz.SSU.1.fq \u251c\u2500\u2500 ${SAMPLE_NAME}.${SAMPLE_NAME}_R1.fastq.gz.SSU.2.fq \u251c\u2500\u2500 ${SAMPLE_NAME}.${SAMPLE_NAME}_R1.fastq.gz.SSU.sam \u251c\u2500\u2500 ${SAMPLE_NAME}.${SAMPLE_NAME}_R1.fastq.gz.SSU_spades.sam \u251c\u2500\u2500 ${SAMPLE_NAME}.SSU.collection.alignment.fasta \u251c\u2500\u2500 ${SAMPLE_NAME}.SSU.collection.fasta \u251c\u2500\u2500 ${SAMPLE_NAME}.SSU.collection.fasta.tree \u251c\u2500\u2500 ${SAMPLE_NAME}.SSU.collection.fasta.tree.svg \u251c\u2500\u2500 ${SAMPLE_NAME}.toalign.fasta \u2514\u2500\u2500 ${SAMPLE_NAME}-unprocessed.txt Filename Description phyloflash.iqtree Full result of the run, this is the main report file (a copy of iqtree/16s.iqtree ) phyloflash-summary.txt The aggregated phyloFlash results of all samples Directory Description \u00b6 alignment \u00b6 Filename Description phyloflash-alignment.fasta The multiple sequence alignment produced by MAFFT. phyloflash-matches.txt A list of reconstructed 16S genes and their match bactopia-info \u00b6 Filename Description phyloflash-report.html The Nextflow Execution Report phyloflash-timeline.html The Nextflow Timeline Report phyloflash-trace.txt The Nextflow Trace report iqtree \u00b6 Where possible descriptions were taken from IQ-TREE's Command Reference page, Web Server Tutorial page, and the Tutorial page. Filename Description 16s.alninfo Alignment site statistics 16s.bionj A neighbor joining tree produced by BIONJ 16s.ckp.gz IQ-TREE writes a checkpoint file 16s.contree Consensus tree with assigned branch supports where branch lengths are optimized on the original alignment; printed if Ultrafast Bootstrap is selected 16s.iqtree Full result of the run, this is the main report file 16s.log Run log 16s.mldist Contains the likelihood distances 16s.model.gz Information about all models tested 16s.splits.nex Support values in percentage for all splits (bipartitions), computed as the occurence frequencies in the bootstrap trees 16s.treefile Maximum likelihood tree in NEWICK format, can be visualized with treeviewer programs 16s.ufboot Trees created during the bootstrap steps 16s.uniqueseq.phy Unique sequences indentified by IQ-TREE samples \u00b6 Where possible descriptions were taken from phyloFlash's Output Summary and the phyloFlash source PhyloFlash.pm Filename Description ${SAMPLE_NAME}.all.dbhits.NR97.fa Reference sequences from database with hits from the supplied reads, clustered at 97% identity ${SAMPLE_NAME}.all.final.fasta All assembled and reconstructed sequences from SPAdes in a single file ${SAMPLE_NAME}.all.final.phyloFlash.dbhits.fa FASTA file of all sequences in database with hits to reconstructed sequences ${SAMPLE_NAME}.all.final.phyloFlash.notmatched.fa FASTA file of full-length sequences without any database hits ${SAMPLE_NAME}.all.vsearch.csv CSV file of Vsearch output ${SAMPLE_NAME}.assemratio.csv CSV file of ratio assembled to unassembled ${SAMPLE_NAME}.assemratio.csv.svg A SVG image of the above ratios ${SAMPLE_NAME}.bbmap.out The bbmap log ${SAMPLE_NAME}.bbmap.sam The alignment of reads against 16S genes ${SAMPLE_NAME}.hitstats A SVG image of the above ratios ${SAMPLE_NAME}.idhistogram Histogram of the % identity of reads vs. reference database sequences, in tab-separated format ${SAMPLE_NAME}.idhistogram.svg A SVG image of the histogram above ${SAMPLE_NAME}.inserthistogram Histogram of detected insert sizes in tab-separated format, if paired-end reads were input ${SAMPLE_NAME}.inserthistogram.svg A SVG image of the above histogram ${SAMPLE_NAME}.mapratio.csv Ratios of mapped vs unmapped to report ${SAMPLE_NAME}.mapratio.csv.svg A SVG image of the above ratio ${SAMPLE_NAME}.phyloFlash Plain text file version of the HTML report ${SAMPLE_NAME}.phyloFlash.extractedSSUclassifications.csv Taxonomic classification of full-length sequences, in CSV format ${SAMPLE_NAME}.phyloFlash.html phyloFlash report file in HTML format, with a report on the taxonomic composition of SSU rRNA reads, quality metrics for the library, and affiliation of the reconstructed/assembled full-length sequences ${SAMPLE_NAME}.phyloFlash.json JSON version of ${SAMPLE_NAME}.phyloFlash ${SAMPLE_NAME}.phyloFlash.NTUabundance.csv The list of uniqe higher level taxa (e.g. orders for bacteria) in the order of their appearance ${SAMPLE_NAME}.phyloFlash.NTUabundance.csv.svg A SVG image depicting the NTU abundances ${SAMPLE_NAME}.phyloFlash.NTUfull_abundance.csv NTU abundances (untruncated) from initial mapping, in CSV format ${SAMPLE_NAME}.phyloFlash.report.csv phyloFlash report in CSV format ${SAMPLE_NAME}.phyloFlash.unassembled.NTUabundance.csv Taxonomic composition of unassembled SSU reads in CSV format ${SAMPLE_NAME}.remap_spades.bbmap.out SAM file of re-mapping extracted reads to SPAdes full-length sequences ${SAMPLE_NAME}.spades.out The SPAdes log ${SAMPLE_NAME}.spades_rRNAs.final.fasta Assembled OTUs from SPAdes with phyloFlash simplified headers \\({SAMPLE_NAME}.\\) _R1.fastq.gz.SSU.1.fq The filtered SSU reads and their paired read, forward read file \\({SAMPLE_NAME}.\\) _R1.fastq.gz.SSU.2.fq The filtered SSU reads and their paired read, reverse read file \\({SAMPLE_NAME}.\\) _R1.fastq.gz.SSU.sam SAM file of initial read mapping to SSU rRNA database \\({SAMPLE_NAME}.\\) _R1.fastq.gz.SSU_spades.sam SAM file of re-mapping extracted reads to SPAdes full-length sequences ${SAMPLE_NAME}.SSU.collection.alignment.fasta An aligned multifasta of all the predicted OTUs and the references ${SAMPLE_NAME}.SSU.collection.fasta A multifasta of all the predicted OTUs and the references ${SAMPLE_NAME}.SSU.collection.fasta.tree An NJ tree of the MAFFT alignment of all the predicted OTUs and the references ${SAMPLE_NAME}.SSU.collection.fasta.tree.svg An SVG image of the tree above ${SAMPLE_NAME}.toalign.fasta Sequences from the sample that were used in the MAFFT alignment ${SAMPLE_NAME}-unprocessed.txt Text file with reason for not processing sample Usage \u00b6 Required Parameters: --bactopia STR Directory containing Bactopia analysis results for all samples. --phyloflash STR Directory containing a pre-built phyloFlash database. Optional Parameters: --include STR A text file containing sample names to include in the analysis. The expected format is a single sample per line. --exclude STR A text file containing sample names to exclude from the analysis. The expected format is a single sample per line. --prefix DIR Prefix to use for final output files Default: phyloflash --outdir DIR Directory to write results to Default: ./ --max_time INT The maximum number of minutes a job should run before being halted. Default: 1440 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single process. Default: 32 Gb --cpus INT Number of processors made available to a single process. Default: 4 phyloFlash Related Parameters: --download_phyloflash Download the latest phyloFlash database, even it exists. --yes You acknowledge SILVAs license. --taxlevel INT Level in the taxonomy string to summarize read counts per taxon. Numeric and 1-based (i.e. \"1\" corresponds to \"Domain\"). Default: 6 --phyloflash_opts STR Extra phyloFlash options in quotes. Default: '' --allow_multiple_16s Include samples with multiple reconstructed 16S genes. Due to high sequence similarity in true multi-copy 16S genes, it is unlikely each copy will be reconstructed, instead only one. In order to get more than one reconstructed 16S gene there must be a significant difference in the sequence identity. As a consequence, any samples that have multiple 16S genes reconstructed contain multiple different species within their sequencing. Default: Exclude samples with multiple 16S genes MAFFT Related Parameters: --align_all Include reconstructed 16S genes as well as the corresponding reference 16S genes in the alignment. --mafft_opts STR MAFFT options to include (in quotes). Default: '' IQ-TREE Related Parameters: --skip_phylogeny Skip the creation a core-genome based phylogeny --m STR Substitution model name Default: MFP --bb INT Ultrafast bootstrap replicates Default: 1000 --alrt INT SH-like approximate likelihood ratio test replicates Default: 1000 --asr Ancestral state reconstruction by empirical Bayes Default: false --iqtree_opts STR Extra IQ-TREE options in quotes. Default: '' Nextflow Related Parameters: --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: false --conatainerPath Path to Singularity containers to be used by the 'slurm' profile. Default: /opt/bactopia/singularity --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds Useful Parameters: --version Print workflow version information --help Show this message and exit Conda Environment \u00b6 Below is the command that was used to create the Conda environment. conda create -y -n bactopia-phyloflash -c conda-forge -c bioconda \\ phyloflash \\ mafft \\ iqtree \\ pigz References \u00b6 Barrnap Seemann, T. Barrnap: Bacterial ribosomal RNA predictor . BBTools Bushnell, B. BBMap short read aligner, and other bioinformatic tools. Bedtools Quinlan, A. R. & Hall, I. M. BEDTools: a flexible suite of utilities for comparing genomic features . Bioinformatics 26, 841\u2013842 (2010). IQ-TREE L.-T. Nguyen, H.A. Schmidt, A. von Haeseler, B.Q. Minh (2015) IQ-TREE: A fast and effective stochastic algorithm for estimating maximum likelihood phylogenies. Mol. Biol. Evol., 32:268-274. S. Kalyaanamoorthy, B.Q. Minh, T.K.F. Wong, A. von Haeseler, L.S. Jermiin (2017) ModelFinder: Fast model selection for accurate phylogenetic estimates. Nat. Methods, 14:587-589. D.T. Hoang, O. Chernomor, A. von Haeseler, B.Q. Minh, L.S. Vinh (2018) UFBoot2: Improving the ultrafast bootstrap approximation. Mol. Biol. Evol., 35:518\u2013522. MAFFT Katoh, K. & Standley, D. M. MAFFT multiple sequence alignment software version 7: improvements in performance and usability. Mol. Biol. Evol. 30, 772\u2013780 (2013) nhmmer Wheeler, T. J. & Eddy, S. R. nhmmer: DNA homology search with profile HMMs. Bioinformatics 29, 2487\u20132489 (2013) phyloFlash H. R. Gruber-Vodicka, B.KB. Seah, E. Pruesse. phyloFlash \u2014 Rapid SSU rRNA profiling and targeted assembly from metagenomes. bioRxiv 521922 SILVA rRNA Database Quast, C. et al. The SILVA ribosomal RNA gene database project: improved data processing and web-based tools. Nucleic Acids Res. 41, D590\u20136 (2013) SPAdes Bankevich, A., et al. SPAdes: a new genome assembly algorithm and its applications to single-cell sequencing. Journal of computational biology 19.5 (2012): 455-477. VSEARCH Rognes, T., Flouri, T., Nichols, B., Quince, C. & Mah\u00e9, F. VSEARCH: a versatile open source tool for metagenomics. PeerJ 4, e2584 (2016)","title":"phyloflash"},{"location":"bactopia-tools/phyloflash/#bactopia-tools-phyloflash","text":"The phyloflash tool uses phyloFlash to resconstruct 16S rRNA genes from your input samples. Optionally these reconstructed genes can then be aligned to one another with MAFFT and a phylogenetic representation created using IQ-TREE","title":"Bactopia Tools - phyloflash"},{"location":"bactopia-tools/phyloflash/#example","text":"The following command will reconstruct the 16S rRNA gene for each sample except those listed in the exclude file. bactopia tools phyloflash \\ --bactopia ~/bactopia-tutorial/bactopia \\ --phyloflash ~/bactopia-tutorial/bactopia-datasets/16s/138 \\ --exclude ~/bactopia-tutorial/bactopia-tools/summary/bactopia-exclude.txt","title":"Example"},{"location":"bactopia-tools/phyloflash/#output-overview","text":"Below is the default output structure for the phyloflash tool. Where possible the file descriptions below were modified from a tools description. bactopia-tools/ \u2514\u2500\u2500 phyloflash/ \u2514\u2500\u2500 ${PREFIX} \u251c\u2500\u2500 alignment \u2502 \u251c\u2500\u2500 phyloflash-alignment.fasta \u2502 \u2514\u2500\u2500 phyloflash-matches.txt \u251c\u2500\u2500 bactopia-info \u2502 \u251c\u2500\u2500 phyloflash-report.html \u2502 \u251c\u2500\u2500 phyloflash-timeline.html \u2502 \u2514\u2500\u2500 phyloflash-trace.txt \u251c\u2500\u2500 iqtree \u2502 \u251c\u2500\u2500 16s.alninfo \u2502 \u251c\u2500\u2500 16s.bionj \u2502 \u251c\u2500\u2500 16s.ckp.gz \u2502 \u251c\u2500\u2500 16s.iqtree \u2502 \u251c\u2500\u2500 16s.log \u2502 \u251c\u2500\u2500 16s.mldist \u2502 \u251c\u2500\u2500 16s.model.gz \u2502 \u251c\u2500\u2500 16s.treefile \u2502 \u2514\u2500\u2500 16s.uniqueseq.phy \u251c\u2500\u2500 phyloflash.iqtree \u251c\u2500\u2500 phyloflash-summary.txt \u2514\u2500\u2500 samples \u2514\u2500\u2500 ${SAMPLE_NAME} \u251c\u2500\u2500 ${SAMPLE_NAME}.all.dbhits.NR97.fa \u251c\u2500\u2500 ${SAMPLE_NAME}.all.final.fasta \u251c\u2500\u2500 ${SAMPLE_NAME}.all.final.phyloFlash.dbhits.fa \u251c\u2500\u2500 ${SAMPLE_NAME}.all.final.phyloFlash.notmatched.fa \u251c\u2500\u2500 ${SAMPLE_NAME}.all.vsearch.csv \u251c\u2500\u2500 ${SAMPLE_NAME}.assemratio.csv \u251c\u2500\u2500 ${SAMPLE_NAME}.assemratio.csv.svg \u251c\u2500\u2500 ${SAMPLE_NAME}.bbmap.out \u251c\u2500\u2500 ${SAMPLE_NAME}.bbmap.sam \u251c\u2500\u2500 ${SAMPLE_NAME}.hitstats \u251c\u2500\u2500 ${SAMPLE_NAME}.idhistogram \u251c\u2500\u2500 ${SAMPLE_NAME}.idhistogram.svg \u251c\u2500\u2500 ${SAMPLE_NAME}.inserthistogram \u251c\u2500\u2500 ${SAMPLE_NAME}.inserthistogram.svg \u251c\u2500\u2500 ${SAMPLE_NAME}.mapratio.csv \u251c\u2500\u2500 ${SAMPLE_NAME}.mapratio.csv.svg \u251c\u2500\u2500 ${SAMPLE_NAME}.phyloFlash \u251c\u2500\u2500 ${SAMPLE_NAME}.phyloFlash.extractedSSUclassifications.csv \u251c\u2500\u2500 ${SAMPLE_NAME}.phyloFlash.html \u251c\u2500\u2500 ${SAMPLE_NAME}.phyloFlash.json \u251c\u2500\u2500 ${SAMPLE_NAME}.phyloFlash.NTUabundance.csv \u251c\u2500\u2500 ${SAMPLE_NAME}.phyloFlash.NTUabundance.csv.svg \u251c\u2500\u2500 ${SAMPLE_NAME}.phyloFlash.NTUfull_abundance.csv \u251c\u2500\u2500 ${SAMPLE_NAME}.phyloFlash.report.csv \u251c\u2500\u2500 ${SAMPLE_NAME}.phyloFlash.unassembled.NTUabundance.csv \u251c\u2500\u2500 ${SAMPLE_NAME}.remap_spades.bbmap.out \u251c\u2500\u2500 ${SAMPLE_NAME}.spades.out \u251c\u2500\u2500 ${SAMPLE_NAME}.spades_rRNAs.final.fasta \u251c\u2500\u2500 ${SAMPLE_NAME}.${SAMPLE_NAME}_R1.fastq.gz.SSU.1.fq \u251c\u2500\u2500 ${SAMPLE_NAME}.${SAMPLE_NAME}_R1.fastq.gz.SSU.2.fq \u251c\u2500\u2500 ${SAMPLE_NAME}.${SAMPLE_NAME}_R1.fastq.gz.SSU.sam \u251c\u2500\u2500 ${SAMPLE_NAME}.${SAMPLE_NAME}_R1.fastq.gz.SSU_spades.sam \u251c\u2500\u2500 ${SAMPLE_NAME}.SSU.collection.alignment.fasta \u251c\u2500\u2500 ${SAMPLE_NAME}.SSU.collection.fasta \u251c\u2500\u2500 ${SAMPLE_NAME}.SSU.collection.fasta.tree \u251c\u2500\u2500 ${SAMPLE_NAME}.SSU.collection.fasta.tree.svg \u251c\u2500\u2500 ${SAMPLE_NAME}.toalign.fasta \u2514\u2500\u2500 ${SAMPLE_NAME}-unprocessed.txt Filename Description phyloflash.iqtree Full result of the run, this is the main report file (a copy of iqtree/16s.iqtree ) phyloflash-summary.txt The aggregated phyloFlash results of all samples","title":"Output Overview"},{"location":"bactopia-tools/phyloflash/#directory-description","text":"","title":"Directory Description"},{"location":"bactopia-tools/phyloflash/#alignment","text":"Filename Description phyloflash-alignment.fasta The multiple sequence alignment produced by MAFFT. phyloflash-matches.txt A list of reconstructed 16S genes and their match","title":"alignment"},{"location":"bactopia-tools/phyloflash/#bactopia-info","text":"Filename Description phyloflash-report.html The Nextflow Execution Report phyloflash-timeline.html The Nextflow Timeline Report phyloflash-trace.txt The Nextflow Trace report","title":"bactopia-info"},{"location":"bactopia-tools/phyloflash/#iqtree","text":"Where possible descriptions were taken from IQ-TREE's Command Reference page, Web Server Tutorial page, and the Tutorial page. Filename Description 16s.alninfo Alignment site statistics 16s.bionj A neighbor joining tree produced by BIONJ 16s.ckp.gz IQ-TREE writes a checkpoint file 16s.contree Consensus tree with assigned branch supports where branch lengths are optimized on the original alignment; printed if Ultrafast Bootstrap is selected 16s.iqtree Full result of the run, this is the main report file 16s.log Run log 16s.mldist Contains the likelihood distances 16s.model.gz Information about all models tested 16s.splits.nex Support values in percentage for all splits (bipartitions), computed as the occurence frequencies in the bootstrap trees 16s.treefile Maximum likelihood tree in NEWICK format, can be visualized with treeviewer programs 16s.ufboot Trees created during the bootstrap steps 16s.uniqueseq.phy Unique sequences indentified by IQ-TREE","title":"iqtree"},{"location":"bactopia-tools/phyloflash/#samples","text":"Where possible descriptions were taken from phyloFlash's Output Summary and the phyloFlash source PhyloFlash.pm Filename Description ${SAMPLE_NAME}.all.dbhits.NR97.fa Reference sequences from database with hits from the supplied reads, clustered at 97% identity ${SAMPLE_NAME}.all.final.fasta All assembled and reconstructed sequences from SPAdes in a single file ${SAMPLE_NAME}.all.final.phyloFlash.dbhits.fa FASTA file of all sequences in database with hits to reconstructed sequences ${SAMPLE_NAME}.all.final.phyloFlash.notmatched.fa FASTA file of full-length sequences without any database hits ${SAMPLE_NAME}.all.vsearch.csv CSV file of Vsearch output ${SAMPLE_NAME}.assemratio.csv CSV file of ratio assembled to unassembled ${SAMPLE_NAME}.assemratio.csv.svg A SVG image of the above ratios ${SAMPLE_NAME}.bbmap.out The bbmap log ${SAMPLE_NAME}.bbmap.sam The alignment of reads against 16S genes ${SAMPLE_NAME}.hitstats A SVG image of the above ratios ${SAMPLE_NAME}.idhistogram Histogram of the % identity of reads vs. reference database sequences, in tab-separated format ${SAMPLE_NAME}.idhistogram.svg A SVG image of the histogram above ${SAMPLE_NAME}.inserthistogram Histogram of detected insert sizes in tab-separated format, if paired-end reads were input ${SAMPLE_NAME}.inserthistogram.svg A SVG image of the above histogram ${SAMPLE_NAME}.mapratio.csv Ratios of mapped vs unmapped to report ${SAMPLE_NAME}.mapratio.csv.svg A SVG image of the above ratio ${SAMPLE_NAME}.phyloFlash Plain text file version of the HTML report ${SAMPLE_NAME}.phyloFlash.extractedSSUclassifications.csv Taxonomic classification of full-length sequences, in CSV format ${SAMPLE_NAME}.phyloFlash.html phyloFlash report file in HTML format, with a report on the taxonomic composition of SSU rRNA reads, quality metrics for the library, and affiliation of the reconstructed/assembled full-length sequences ${SAMPLE_NAME}.phyloFlash.json JSON version of ${SAMPLE_NAME}.phyloFlash ${SAMPLE_NAME}.phyloFlash.NTUabundance.csv The list of uniqe higher level taxa (e.g. orders for bacteria) in the order of their appearance ${SAMPLE_NAME}.phyloFlash.NTUabundance.csv.svg A SVG image depicting the NTU abundances ${SAMPLE_NAME}.phyloFlash.NTUfull_abundance.csv NTU abundances (untruncated) from initial mapping, in CSV format ${SAMPLE_NAME}.phyloFlash.report.csv phyloFlash report in CSV format ${SAMPLE_NAME}.phyloFlash.unassembled.NTUabundance.csv Taxonomic composition of unassembled SSU reads in CSV format ${SAMPLE_NAME}.remap_spades.bbmap.out SAM file of re-mapping extracted reads to SPAdes full-length sequences ${SAMPLE_NAME}.spades.out The SPAdes log ${SAMPLE_NAME}.spades_rRNAs.final.fasta Assembled OTUs from SPAdes with phyloFlash simplified headers \\({SAMPLE_NAME}.\\) _R1.fastq.gz.SSU.1.fq The filtered SSU reads and their paired read, forward read file \\({SAMPLE_NAME}.\\) _R1.fastq.gz.SSU.2.fq The filtered SSU reads and their paired read, reverse read file \\({SAMPLE_NAME}.\\) _R1.fastq.gz.SSU.sam SAM file of initial read mapping to SSU rRNA database \\({SAMPLE_NAME}.\\) _R1.fastq.gz.SSU_spades.sam SAM file of re-mapping extracted reads to SPAdes full-length sequences ${SAMPLE_NAME}.SSU.collection.alignment.fasta An aligned multifasta of all the predicted OTUs and the references ${SAMPLE_NAME}.SSU.collection.fasta A multifasta of all the predicted OTUs and the references ${SAMPLE_NAME}.SSU.collection.fasta.tree An NJ tree of the MAFFT alignment of all the predicted OTUs and the references ${SAMPLE_NAME}.SSU.collection.fasta.tree.svg An SVG image of the tree above ${SAMPLE_NAME}.toalign.fasta Sequences from the sample that were used in the MAFFT alignment ${SAMPLE_NAME}-unprocessed.txt Text file with reason for not processing sample","title":"samples"},{"location":"bactopia-tools/phyloflash/#usage","text":"Required Parameters: --bactopia STR Directory containing Bactopia analysis results for all samples. --phyloflash STR Directory containing a pre-built phyloFlash database. Optional Parameters: --include STR A text file containing sample names to include in the analysis. The expected format is a single sample per line. --exclude STR A text file containing sample names to exclude from the analysis. The expected format is a single sample per line. --prefix DIR Prefix to use for final output files Default: phyloflash --outdir DIR Directory to write results to Default: ./ --max_time INT The maximum number of minutes a job should run before being halted. Default: 1440 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single process. Default: 32 Gb --cpus INT Number of processors made available to a single process. Default: 4 phyloFlash Related Parameters: --download_phyloflash Download the latest phyloFlash database, even it exists. --yes You acknowledge SILVAs license. --taxlevel INT Level in the taxonomy string to summarize read counts per taxon. Numeric and 1-based (i.e. \"1\" corresponds to \"Domain\"). Default: 6 --phyloflash_opts STR Extra phyloFlash options in quotes. Default: '' --allow_multiple_16s Include samples with multiple reconstructed 16S genes. Due to high sequence similarity in true multi-copy 16S genes, it is unlikely each copy will be reconstructed, instead only one. In order to get more than one reconstructed 16S gene there must be a significant difference in the sequence identity. As a consequence, any samples that have multiple 16S genes reconstructed contain multiple different species within their sequencing. Default: Exclude samples with multiple 16S genes MAFFT Related Parameters: --align_all Include reconstructed 16S genes as well as the corresponding reference 16S genes in the alignment. --mafft_opts STR MAFFT options to include (in quotes). Default: '' IQ-TREE Related Parameters: --skip_phylogeny Skip the creation a core-genome based phylogeny --m STR Substitution model name Default: MFP --bb INT Ultrafast bootstrap replicates Default: 1000 --alrt INT SH-like approximate likelihood ratio test replicates Default: 1000 --asr Ancestral state reconstruction by empirical Bayes Default: false --iqtree_opts STR Extra IQ-TREE options in quotes. Default: '' Nextflow Related Parameters: --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: false --conatainerPath Path to Singularity containers to be used by the 'slurm' profile. Default: /opt/bactopia/singularity --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds Useful Parameters: --version Print workflow version information --help Show this message and exit","title":"Usage"},{"location":"bactopia-tools/phyloflash/#conda-environment","text":"Below is the command that was used to create the Conda environment. conda create -y -n bactopia-phyloflash -c conda-forge -c bioconda \\ phyloflash \\ mafft \\ iqtree \\ pigz","title":"Conda Environment"},{"location":"bactopia-tools/phyloflash/#references","text":"Barrnap Seemann, T. Barrnap: Bacterial ribosomal RNA predictor . BBTools Bushnell, B. BBMap short read aligner, and other bioinformatic tools. Bedtools Quinlan, A. R. & Hall, I. M. BEDTools: a flexible suite of utilities for comparing genomic features . Bioinformatics 26, 841\u2013842 (2010). IQ-TREE L.-T. Nguyen, H.A. Schmidt, A. von Haeseler, B.Q. Minh (2015) IQ-TREE: A fast and effective stochastic algorithm for estimating maximum likelihood phylogenies. Mol. Biol. Evol., 32:268-274. S. Kalyaanamoorthy, B.Q. Minh, T.K.F. Wong, A. von Haeseler, L.S. Jermiin (2017) ModelFinder: Fast model selection for accurate phylogenetic estimates. Nat. Methods, 14:587-589. D.T. Hoang, O. Chernomor, A. von Haeseler, B.Q. Minh, L.S. Vinh (2018) UFBoot2: Improving the ultrafast bootstrap approximation. Mol. Biol. Evol., 35:518\u2013522. MAFFT Katoh, K. & Standley, D. M. MAFFT multiple sequence alignment software version 7: improvements in performance and usability. Mol. Biol. Evol. 30, 772\u2013780 (2013) nhmmer Wheeler, T. J. & Eddy, S. R. nhmmer: DNA homology search with profile HMMs. Bioinformatics 29, 2487\u20132489 (2013) phyloFlash H. R. Gruber-Vodicka, B.KB. Seah, E. Pruesse. phyloFlash \u2014 Rapid SSU rRNA profiling and targeted assembly from metagenomes. bioRxiv 521922 SILVA rRNA Database Quast, C. et al. The SILVA ribosomal RNA gene database project: improved data processing and web-based tools. Nucleic Acids Res. 41, D590\u20136 (2013) SPAdes Bankevich, A., et al. SPAdes: a new genome assembly algorithm and its applications to single-cell sequencing. Journal of computational biology 19.5 (2012): 455-477. VSEARCH Rognes, T., Flouri, T., Nichols, B., Quince, C. & Mah\u00e9, F. VSEARCH: a versatile open source tool for metagenomics. PeerJ 4, e2584 (2016)","title":"References"},{"location":"bactopia-tools/pirate/","text":"Bactopia Tools - pirate \u00b6 The pirate tool allows you to create a pan-genome of your samples using PIRATE . Often times, you may also want to include completed genomes in your pan-genome analysis. This is possible with the pirate tool. If you use the --species parameter, all completed genomes available from RefSeq will be downloaded with ncbi-genome-download and reannotated with Prokka (to make compatible gffs). You can also use the core genome alignment, produced by PIRATE, to create a core genome phylogeny using ClonalFrameMl , maskrc-svg , and IQ-TREE . The core genome pair-wise SNP distance for each sample is also calculated with snp-dists . Example \u00b6 The following command will run PIRATE, on a set of samples in the include file. Then it will create a phylogenetic tree based on the core-genome alignment. bactopia tools pirate \\ --bactopia ~/bactopia-tutorial/bactopia \\ --include ~/bactopia-tutorial/GCF_900475245-include.txt \\ --cpus 4 Output Overview \u00b6 Below is the default output structure for the pirate tool. Where possible the file descriptions below were modified from a tools description. bactopia-tools/ \u2514\u2500\u2500 pirate/ \u2514\u2500\u2500 ${PREFIX} \u251c\u2500\u2500 bactopia-info \u2502 \u251c\u2500\u2500 pirate-report.html \u2502 \u251c\u2500\u2500 pirate-timeline.html \u2502 \u2514\u2500\u2500 pirate-trace.txt \u251c\u2500\u2500 clonalframe \u2502 \u251c\u2500\u2500 clonalframe.emsim.txt \u2502 \u251c\u2500\u2500 clonalframe.em.txt \u2502 \u251c\u2500\u2500 clonalframe.importation_status.txt \u2502 \u251c\u2500\u2500 clonalframe.labelled_tree.newick \u2502 \u251c\u2500\u2500 clonalframe.ML_sequence.fasta \u2502 \u251c\u2500\u2500 clonalframe.position_cross_reference.txt \u2502 \u251c\u2500\u2500 core_gene_alignment-masked.aln.gz \u2502 \u251c\u2500\u2500 start-tree.bionj \u2502 \u251c\u2500\u2500 start-tree.ckp.gz \u2502 \u251c\u2500\u2500 start-tree.iqtree \u2502 \u251c\u2500\u2500 start-tree.log \u2502 \u251c\u2500\u2500 start-tree.mldist \u2502 \u251c\u2500\u2500 start-tree.model.gz \u2502 \u2514\u2500\u2500 start-tree.treefile \u251c\u2500\u2500 iqtree \u2502 \u251c\u2500\u2500 core-genome.alninfo \u2502 \u251c\u2500\u2500 core-genome.bionj \u2502 \u251c\u2500\u2500 core-genome.ckp.gz \u2502 \u251c\u2500\u2500 core-genome.contree \u2502 \u251c\u2500\u2500 core-genome.iqtree \u2502 \u251c\u2500\u2500 core-genome.log \u2502 \u251c\u2500\u2500 core-genome.mldist \u2502 \u251c\u2500\u2500 core-genome.model.gz \u2502 \u251c\u2500\u2500 core-genome.splits.nex \u2502 \u251c\u2500\u2500 core-genome.treefile \u2502 \u2514\u2500\u2500 core-genome.ufboot \u251c\u2500\u2500 pirate \u2502 \u251c\u2500\u2500 binary_presence_absence.{fasta|nwk} \u2502 \u251c\u2500\u2500 cluster_alleles.tab \u2502 \u251c\u2500\u2500 co-ords \u2502 \u2502 \u2514\u2500\u2500 ${SAMPLE_NAME}.co-ords.tab \u2502 \u251c\u2500\u2500 core_alignment.fasta \u2502 \u251c\u2500\u2500 core_alignment.gff \u2502 \u251c\u2500\u2500 feature_sequences \u2502 \u2502 \u2514\u2500\u2500 ${GENE_FAMILY}.{aa|nucleotide|.fasta \u2502 \u251c\u2500\u2500 genome2loci.tab \u2502 \u251c\u2500\u2500 genome_list.txt \u2502 \u251c\u2500\u2500 loci_list.tab \u2502 \u251c\u2500\u2500 loci_paralog_categories.tab \u2502 \u251c\u2500\u2500 loci_paralog_categories.tab.idx \u2502 \u251c\u2500\u2500 modified_gffs \u2502 \u2502 \u2514\u2500\u2500 ${SAMPLE_NAME}.gff \u2502 \u251c\u2500\u2500 pangenome_alignment.fasta.gz \u2502 \u251c\u2500\u2500 pangenome_alignment.gff \u2502 \u251c\u2500\u2500 pangenome.connected_blocks.tsv \u2502 \u251c\u2500\u2500 pangenome.edges \u2502 \u251c\u2500\u2500 pangenome.gfa \u2502 \u251c\u2500\u2500 pangenome_iterations \u2502 \u2502 \u251c\u2500\u2500 pan_sequences.{50|60|70|80|90|95|98}.reclustered.reinflated \u2502 \u2502 \u251c\u2500\u2500 pan_sequences.blast.output \u2502 \u2502 \u251c\u2500\u2500 pan_sequences.cdhit_clusters \u2502 \u2502 \u251c\u2500\u2500 pan_sequences.core_clusters.tab \u2502 \u2502 \u251c\u2500\u2500 pan_sequences.mcl_log.txt \u2502 \u2502 \u2514\u2500\u2500 pan_sequences.representative.fasta \u2502 \u251c\u2500\u2500 pangenome.order.tsv \u2502 \u251c\u2500\u2500 pangenome.reversed.tsv \u2502 \u251c\u2500\u2500 pangenome.syntenic_blocks.tsv \u2502 \u251c\u2500\u2500 pan_sequences.fasta \u2502 \u251c\u2500\u2500 paralog_clusters.tab \u2502 \u251c\u2500\u2500 PIRATE.gene_families.ordered.tsv \u2502 \u251c\u2500\u2500 PIRATE.gene_families.tsv \u2502 \u251c\u2500\u2500 PIRATE.genomes_per_allele.tsv \u2502 \u251c\u2500\u2500 PIRATE.log \u2502 \u251c\u2500\u2500 PIRATE.pangenome_summary.txt \u2502 \u251c\u2500\u2500 PIRATE_plots.pdf \u2502 \u251c\u2500\u2500 PIRATE.unique_alleles.tsv \u2502 \u2514\u2500\u2500 split_groups.log \u251c\u2500\u2500 refseq \u2502 \u251c\u2500\u2500 fasta \u2502 \u2502 \u2514\u2500\u2500 *.fna \u2502 \u2514\u2500\u2500 gff \u2502 \u2514\u2500\u2500 *.gff \u251c\u2500\u2500 ${PREFIX}.aligned.fa.gz \u251c\u2500\u2500 ${PREFIX}.distance.txt \u2514\u2500\u2500 ${PREFIX}.iqtree Filename Description ${PREFIX}.aligned.fa.gz A multiple sequence alignment FASTA of the core genome ${PREFIX}.distance.txt Core genome Pair-wise SNP distance for each sample ${PREFIX}.iqtree Full result of the IQ-TREE core genome phylogeny Directory Description \u00b6 bactopia-info \u00b6 Filename Description pirate-report.html The Nextflow Execution Report pirate-timeline.html The Nextflow Timeline Report pirate-trace.txt The Nextflow Trace report clonalframe \u00b6 Where possible descriptions were taken from the ClonalFrameML Wiki , IQ-TREE's Command Reference page, Web Server Tutorial page, and the Tutorial page. Filename Description clonalframe.emsim.txt The bootstrapped values for the three parameters R/theta, nu and delta clonalframe.em.txt The point estimates for R/theta, nu, delta and the branch lengths clonalframe.importation_status.txt The list of reconstructed recombination events clonalframe.labelled_tree.newick The output tree with all nodes labelled so that they can be referred to in other files clonalframe.ML_sequence.fasta The sequence reconstructed by maximum likelihood for all internal nodes of the phylogeny, as well as for all missing data in the input sequences clonalframe.position_cross_reference.txt A vector of comma-separated values indicating for each location in the input sequence file the corresponding position in the sequences in the output ML_sequence.fasta file core_gene_alignment-masked.aln.gz A core-genome alignment with the recomination masked start-tree.bionj A neighbor joining tree produced by BIONJ start-tree.ckp.gz IQ-TREE writes a checkpoint file start-tree.iqtree Full result of the run, this is the main report file start-tree.log Run log start-tree.mldist Contains the likelihood distances start-tree.model.gz Information about all models tested start-tree.treefile Maximum likelihood tree in NEWICK format, can be visualized with treeviewer programs iqtree \u00b6 Where possible descriptions were taken from IQ-TREE's Command Reference page, Web Server Tutorial page, and the Tutorial page. Filename Description core-genome.alninfo Alignment site statistics core-genome.bionj A neighbor joining tree produced by BIONJ core-genome.ckp.gz IQ-TREE writes a checkpoint file core-genome.contree Consensus tree with assigned branch supports where branch lengths are optimized on the original alignment; printed if Ultrafast Bootstrap is selected core-genome.iqtree Full result of the run, this is the main report file core-genome.log Run log core-genome.mldist Contains the likelihood distances core-genome.model.gz Information about all models tested core-genome.splits.nex Support values in percentage for all splits (bipartitions), computed as the occurence frequencies in the bootstrap trees core-genome.treefile Maximum likelihood tree in NEWICK format, can be visualized with treeviewer programs core-genome.ufboot Trees created during the bootstrap steps pirate \u00b6 Where possible descriptions were taken from PIRATE's Output files page. Filename Description binary_presence_absence.{fasta|nwk} A tree (.nwk) generated by fasttree from binary gene_family presence-absence data and the fasta file used to create it cluster_alleles.tab List of alleles in paralogous clusters co-ords/${SAMPLE_NAME}.co-ords.tab Gene feature co-ordinates for each sample core_alignment.fasta Gene-by-gene nucleotide alignments of the core genome created using MAFFT core_alignment.gff Annotation containing the position of the gene family within the core genome alignment feature_sequences/${GENE_FAMILY}.{aa|nucleotide}.fasta Amino acid and nucleotide sequences for each gene family genome2loci.tab List of loci for each genome genome_list.txt List of genomes in the analysis loci_list.tab List of loci and their associated genomes loci_paralog_categories.tab Concatenation of classified paralogs loci_paralog_categories.tab.idx Index of the classified paralogs modified_gffs/${SAMPLE_NAME}.gff GFF3 files which have been standardised for PIRATE pangenome_alignment.fasta.gz Gene-by-gene nucleotide alignments of the full pangenome created using MAFFT pangenome_alignment.gff Annotation containing the position of the gene family within the pangenome alignment pangenome.connected_blocks.tsv List of connected blocks in the pangenome graph pangenome.edges List of classified edges in the pangenome graph pangenome.gfa GFA network file representing all unique connections between gene families pangenome_iterations/pan_sequences.{50|60|70|80|90|95|98}.reclustered.reinflated List of clusters for each reinflation threshold pangenome_iterations/pan_sequences.blast.output BLAST output of sequences against representatives and self hits. pangenome_iterations/pan_sequences.cdhit_clusters A list of CDHIT representative clusters pangenome_iterations/pan_sequences.core_clusters.tab A list of core clusters. pangenome_iterations/pan_sequences.mcl_log.txt A log file from mcxdeblast and mcl pangenome_iterations/pan_sequences.representative.fasta FASTA file with sequences for each representative cluster pangenome.order.tsv Sorted list gene_families file on pangenome graph pangenome.reversed.tsv List of reversed blocks in the pangenome graph pangenome.syntenic_blocks.tsv List of syntenic blocks in the pangenome graph pan_sequences.fasta All representative sequences in the pangenome paralog_clusters.tab List of paralogous clusters PIRATE.gene_families.ordered.tsv Tabular summary of all gene families ordered on syntenic regions in the pangenome graph PIRATE.gene_families.tsv Tabular summary of all gene families PIRATE.genomes_per_allele.tsv A list of genomes associated with each allele PIRATE.log PIRATE log file PIRATE.pangenome_summary.txt Short summary of the number and frequency of genes in the pangenome PIRATE_plots.pdf Summary plots of the PIRATE pangenome PIRATE.unique_alleles.tsv Tabular summary of all unique alleles of each gene family split_groups.log Concatenation of log files from splitting paralogs refseq \u00b6 Extension Description .fna FASTA formated genome downloaded from NCBI Assembly database. .gff GFF output from the Prokka re-annotation of the reference FASTA Usage \u00b6 Required Parameters: --bactopia STR Directory containing Bactopia analysis results for all samples. This parameter is not required if '--only_completed' is used. Optional Parameters: --include STR A text file containing sample names to include in the analysis. The expected format is a single sample per line. --exclude STR A text file containing sample names to exclude from the analysis. The expected format is a single sample per line. --prefix DIR Prefix to use for final output files Default: core-genome --outdir DIR Directory to write results to Default: ./ --max_time INT The maximum number of minutes a job should run before being halted. Default: 2880 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single process. Default: 64 Gb --cpus INT Number of processors made available to a single process. Default: 10 RefSeq Assemblies Related Parameters: --assembly A single assembly, or directory of assemblies to be included in the pan-genome analysis. If compressed, gzip and the \".gz\" extension must be used. --assembly_pattern If a directory is given, use the given pattern to match assemblies. Default: *.fna --species STR The name of the species to download RefSeq assemblies for. This is a completely optional step and is meant to supplement your dataset with high-quality completed genomes. --accession STR A NCBI Assembly database RefSeq accession to be downloaded and included in the pan-genome analysis. --accessions STR A file with Assembly accessions (e.g. GCF*.*) to download from RefSeq. --limit INT Limit the number of RefSeq assemblies to download. If the the number of available genomes exceeds the given limit, a random subset will be selected. Default: Download all available genomes --only_completed Pan-genome will be created using only the completed RefSeq genomes. Requires either '--accessions' and/or '--species' --prokka_evalue STR Similarity e-value cut-off Default: 1e-09 --prokka_coverage INT Minimum coverage on query protein Default: 80 PIRATE Related Parameters: --steps STR Percent identity thresholds to use for pangenome construction Default: 50,60,70,80,90,95,98 --features STR Choose features to use for pangenome construction. Multiple may be entered, separated by a comma. Default: CDS --nucl Input CDS are nucleotides (e.g. not translated to AA sequence) --para_off Switch off paralog identification --keep_all_files Retain all intermediate files PIRATE Advanced Parameters: --perc INT Single percent identity threshold to use for pangenome Default: 98 % --cd_low INT CDHIT lowest percentage identity threshold Default: 98 % --cd_step FLOAT CDHIT step size Default: 0.5 --evalue STR E-value used for BLAST hit filtering Default: 1E-6 --hsp_len FLOAT Remove BLAST hsps that are < hsp_len proportion of query length Default: 0 --mcl_inflation FLOAT MCL inflation value Default: 1.5 --use_diamond Use Diamond instead of BLAST - incompatible with --nucl --split_diamond Split diamond files into batches for processing IQ-TREE Related Parameters: --skip_phylogeny Skip the creation a core-genome based phylogeny --m STR Substitution model name Default: MFP --bb INT Ultrafast bootstrap replicates Default: 1000 --alrt INT SH-like approximate likelihood ratio test replicates Default: 1000 --asr Ancestral state reconstruction by empirical Bayes Default: false --iqtree_opts STR Extra IQ-TREE options in quotes. Default: '' ClonalFrameML Related Parameters: --skip_clonalframe Skip the ClonalFrameML and use the original core-genome alignment for the final tree. --emsim INT Number of simulations to estimate uncertainty in the EM results. Default: 100 --clonal_opts STR Extra ClonalFrameML options in quotes. Default: '' SNP-Dists Related Parameters: --a Count all differences not just [AGTC] Default: false --b Blank top left corner cell Default: false --c Output CSV instead of TSV Default: false --k Keep case, don't uppercase all letters Default: false Nextflow Related Parameters: --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: true --conatainerPath Path to Singularity containers to be used by the 'slurm' profile. Default: /opt/bactopia/singularity --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds --nfconfig STR A Nextflow compatible config file for custom profiles. This allows you to create profiles specific to your environment (e.g. SGE, AWS, SLURM, etc...). This config file is loaded last and will overwrite existing variables if set. Default: Bactopia's default configs -resume Nextflow will attempt to resume a previous run. Please notice it is only a single '-' Useful Parameters: --version Print workflow version information --help Show this message and exit Conda Environment \u00b6 Below is the command that was used to create the Conda environment. conda create -y -n bactopia-pirate -c r -c conda-forge -c bioconda \\ bioconductor-ggtree \\ clonalframeml \\ iqtree \\ maskrc-svg \\ ncbi-genome-download \\ pigz \\ pirate \\ prokka \\ r-dplyr \\ r-ggplot2 \\ r-gridextra \\ r-phangorn \\ rename \\ snp-dists \\ tbl2asn-forever References \u00b6 ClonalFramML Didelot, X. & Wilson, D. J. ClonalFrameML: efficient inference of recombination in whole bacterial genomes. PLoS Comput. Biol. 11, e1004041 (2015) IQ-TREE L.-T. Nguyen, H.A. Schmidt, A. von Haeseler, B.Q. Minh (2015) IQ-TREE: A fast and effective stochastic algorithm for estimating maximum likelihood phylogenies. Mol. Biol. Evol., 32:268-274. S. Kalyaanamoorthy, B.Q. Minh, T.K.F. Wong, A. von Haeseler, L.S. Jermiin (2017) ModelFinder: Fast model selection for accurate phylogenetic estimates. Nat. Methods, 14:587-589. D.T. Hoang, O. Chernomor, A. von Haeseler, B.Q. Minh, L.S. Vinh (2018) UFBoot2: Improving the ultrafast bootstrap approximation. Mol. Biol. Evol., 35:518\u2013522. maskrc-svg Kwong, J. maskrc-svg - Masks recombination as detected by ClonalFrameML or Gubbins and draws an SVG. ncbi-genome-download Blin, K. ncbi-genome-download: Scripts to download genomes from the NCBI FTP servers PIRATE S. C. Bayliss, H. A. Thorpe, N. M. Coyle, S. K. Sheppard, E. J. Feil (2019) PIRATE: A fast and scalable pangenomics toolbox for clustering diverged orthologues in bacteria. Gigascience. 8 Prokka Seemann, T. Prokka: rapid prokaryotic genome annotation . Bioinformatics 30, 2068\u20132069 (2014). snp-dists Seemann, T. snp-dists - Pairwise SNP distance matrix from a FASTA sequence alignment.","title":"pirate"},{"location":"bactopia-tools/pirate/#bactopia-tools-pirate","text":"The pirate tool allows you to create a pan-genome of your samples using PIRATE . Often times, you may also want to include completed genomes in your pan-genome analysis. This is possible with the pirate tool. If you use the --species parameter, all completed genomes available from RefSeq will be downloaded with ncbi-genome-download and reannotated with Prokka (to make compatible gffs). You can also use the core genome alignment, produced by PIRATE, to create a core genome phylogeny using ClonalFrameMl , maskrc-svg , and IQ-TREE . The core genome pair-wise SNP distance for each sample is also calculated with snp-dists .","title":"Bactopia Tools - pirate"},{"location":"bactopia-tools/pirate/#example","text":"The following command will run PIRATE, on a set of samples in the include file. Then it will create a phylogenetic tree based on the core-genome alignment. bactopia tools pirate \\ --bactopia ~/bactopia-tutorial/bactopia \\ --include ~/bactopia-tutorial/GCF_900475245-include.txt \\ --cpus 4","title":"Example"},{"location":"bactopia-tools/pirate/#output-overview","text":"Below is the default output structure for the pirate tool. Where possible the file descriptions below were modified from a tools description. bactopia-tools/ \u2514\u2500\u2500 pirate/ \u2514\u2500\u2500 ${PREFIX} \u251c\u2500\u2500 bactopia-info \u2502 \u251c\u2500\u2500 pirate-report.html \u2502 \u251c\u2500\u2500 pirate-timeline.html \u2502 \u2514\u2500\u2500 pirate-trace.txt \u251c\u2500\u2500 clonalframe \u2502 \u251c\u2500\u2500 clonalframe.emsim.txt \u2502 \u251c\u2500\u2500 clonalframe.em.txt \u2502 \u251c\u2500\u2500 clonalframe.importation_status.txt \u2502 \u251c\u2500\u2500 clonalframe.labelled_tree.newick \u2502 \u251c\u2500\u2500 clonalframe.ML_sequence.fasta \u2502 \u251c\u2500\u2500 clonalframe.position_cross_reference.txt \u2502 \u251c\u2500\u2500 core_gene_alignment-masked.aln.gz \u2502 \u251c\u2500\u2500 start-tree.bionj \u2502 \u251c\u2500\u2500 start-tree.ckp.gz \u2502 \u251c\u2500\u2500 start-tree.iqtree \u2502 \u251c\u2500\u2500 start-tree.log \u2502 \u251c\u2500\u2500 start-tree.mldist \u2502 \u251c\u2500\u2500 start-tree.model.gz \u2502 \u2514\u2500\u2500 start-tree.treefile \u251c\u2500\u2500 iqtree \u2502 \u251c\u2500\u2500 core-genome.alninfo \u2502 \u251c\u2500\u2500 core-genome.bionj \u2502 \u251c\u2500\u2500 core-genome.ckp.gz \u2502 \u251c\u2500\u2500 core-genome.contree \u2502 \u251c\u2500\u2500 core-genome.iqtree \u2502 \u251c\u2500\u2500 core-genome.log \u2502 \u251c\u2500\u2500 core-genome.mldist \u2502 \u251c\u2500\u2500 core-genome.model.gz \u2502 \u251c\u2500\u2500 core-genome.splits.nex \u2502 \u251c\u2500\u2500 core-genome.treefile \u2502 \u2514\u2500\u2500 core-genome.ufboot \u251c\u2500\u2500 pirate \u2502 \u251c\u2500\u2500 binary_presence_absence.{fasta|nwk} \u2502 \u251c\u2500\u2500 cluster_alleles.tab \u2502 \u251c\u2500\u2500 co-ords \u2502 \u2502 \u2514\u2500\u2500 ${SAMPLE_NAME}.co-ords.tab \u2502 \u251c\u2500\u2500 core_alignment.fasta \u2502 \u251c\u2500\u2500 core_alignment.gff \u2502 \u251c\u2500\u2500 feature_sequences \u2502 \u2502 \u2514\u2500\u2500 ${GENE_FAMILY}.{aa|nucleotide|.fasta \u2502 \u251c\u2500\u2500 genome2loci.tab \u2502 \u251c\u2500\u2500 genome_list.txt \u2502 \u251c\u2500\u2500 loci_list.tab \u2502 \u251c\u2500\u2500 loci_paralog_categories.tab \u2502 \u251c\u2500\u2500 loci_paralog_categories.tab.idx \u2502 \u251c\u2500\u2500 modified_gffs \u2502 \u2502 \u2514\u2500\u2500 ${SAMPLE_NAME}.gff \u2502 \u251c\u2500\u2500 pangenome_alignment.fasta.gz \u2502 \u251c\u2500\u2500 pangenome_alignment.gff \u2502 \u251c\u2500\u2500 pangenome.connected_blocks.tsv \u2502 \u251c\u2500\u2500 pangenome.edges \u2502 \u251c\u2500\u2500 pangenome.gfa \u2502 \u251c\u2500\u2500 pangenome_iterations \u2502 \u2502 \u251c\u2500\u2500 pan_sequences.{50|60|70|80|90|95|98}.reclustered.reinflated \u2502 \u2502 \u251c\u2500\u2500 pan_sequences.blast.output \u2502 \u2502 \u251c\u2500\u2500 pan_sequences.cdhit_clusters \u2502 \u2502 \u251c\u2500\u2500 pan_sequences.core_clusters.tab \u2502 \u2502 \u251c\u2500\u2500 pan_sequences.mcl_log.txt \u2502 \u2502 \u2514\u2500\u2500 pan_sequences.representative.fasta \u2502 \u251c\u2500\u2500 pangenome.order.tsv \u2502 \u251c\u2500\u2500 pangenome.reversed.tsv \u2502 \u251c\u2500\u2500 pangenome.syntenic_blocks.tsv \u2502 \u251c\u2500\u2500 pan_sequences.fasta \u2502 \u251c\u2500\u2500 paralog_clusters.tab \u2502 \u251c\u2500\u2500 PIRATE.gene_families.ordered.tsv \u2502 \u251c\u2500\u2500 PIRATE.gene_families.tsv \u2502 \u251c\u2500\u2500 PIRATE.genomes_per_allele.tsv \u2502 \u251c\u2500\u2500 PIRATE.log \u2502 \u251c\u2500\u2500 PIRATE.pangenome_summary.txt \u2502 \u251c\u2500\u2500 PIRATE_plots.pdf \u2502 \u251c\u2500\u2500 PIRATE.unique_alleles.tsv \u2502 \u2514\u2500\u2500 split_groups.log \u251c\u2500\u2500 refseq \u2502 \u251c\u2500\u2500 fasta \u2502 \u2502 \u2514\u2500\u2500 *.fna \u2502 \u2514\u2500\u2500 gff \u2502 \u2514\u2500\u2500 *.gff \u251c\u2500\u2500 ${PREFIX}.aligned.fa.gz \u251c\u2500\u2500 ${PREFIX}.distance.txt \u2514\u2500\u2500 ${PREFIX}.iqtree Filename Description ${PREFIX}.aligned.fa.gz A multiple sequence alignment FASTA of the core genome ${PREFIX}.distance.txt Core genome Pair-wise SNP distance for each sample ${PREFIX}.iqtree Full result of the IQ-TREE core genome phylogeny","title":"Output Overview"},{"location":"bactopia-tools/pirate/#directory-description","text":"","title":"Directory Description"},{"location":"bactopia-tools/pirate/#bactopia-info","text":"Filename Description pirate-report.html The Nextflow Execution Report pirate-timeline.html The Nextflow Timeline Report pirate-trace.txt The Nextflow Trace report","title":"bactopia-info"},{"location":"bactopia-tools/pirate/#clonalframe","text":"Where possible descriptions were taken from the ClonalFrameML Wiki , IQ-TREE's Command Reference page, Web Server Tutorial page, and the Tutorial page. Filename Description clonalframe.emsim.txt The bootstrapped values for the three parameters R/theta, nu and delta clonalframe.em.txt The point estimates for R/theta, nu, delta and the branch lengths clonalframe.importation_status.txt The list of reconstructed recombination events clonalframe.labelled_tree.newick The output tree with all nodes labelled so that they can be referred to in other files clonalframe.ML_sequence.fasta The sequence reconstructed by maximum likelihood for all internal nodes of the phylogeny, as well as for all missing data in the input sequences clonalframe.position_cross_reference.txt A vector of comma-separated values indicating for each location in the input sequence file the corresponding position in the sequences in the output ML_sequence.fasta file core_gene_alignment-masked.aln.gz A core-genome alignment with the recomination masked start-tree.bionj A neighbor joining tree produced by BIONJ start-tree.ckp.gz IQ-TREE writes a checkpoint file start-tree.iqtree Full result of the run, this is the main report file start-tree.log Run log start-tree.mldist Contains the likelihood distances start-tree.model.gz Information about all models tested start-tree.treefile Maximum likelihood tree in NEWICK format, can be visualized with treeviewer programs","title":"clonalframe"},{"location":"bactopia-tools/pirate/#iqtree","text":"Where possible descriptions were taken from IQ-TREE's Command Reference page, Web Server Tutorial page, and the Tutorial page. Filename Description core-genome.alninfo Alignment site statistics core-genome.bionj A neighbor joining tree produced by BIONJ core-genome.ckp.gz IQ-TREE writes a checkpoint file core-genome.contree Consensus tree with assigned branch supports where branch lengths are optimized on the original alignment; printed if Ultrafast Bootstrap is selected core-genome.iqtree Full result of the run, this is the main report file core-genome.log Run log core-genome.mldist Contains the likelihood distances core-genome.model.gz Information about all models tested core-genome.splits.nex Support values in percentage for all splits (bipartitions), computed as the occurence frequencies in the bootstrap trees core-genome.treefile Maximum likelihood tree in NEWICK format, can be visualized with treeviewer programs core-genome.ufboot Trees created during the bootstrap steps","title":"iqtree"},{"location":"bactopia-tools/pirate/#pirate","text":"Where possible descriptions were taken from PIRATE's Output files page. Filename Description binary_presence_absence.{fasta|nwk} A tree (.nwk) generated by fasttree from binary gene_family presence-absence data and the fasta file used to create it cluster_alleles.tab List of alleles in paralogous clusters co-ords/${SAMPLE_NAME}.co-ords.tab Gene feature co-ordinates for each sample core_alignment.fasta Gene-by-gene nucleotide alignments of the core genome created using MAFFT core_alignment.gff Annotation containing the position of the gene family within the core genome alignment feature_sequences/${GENE_FAMILY}.{aa|nucleotide}.fasta Amino acid and nucleotide sequences for each gene family genome2loci.tab List of loci for each genome genome_list.txt List of genomes in the analysis loci_list.tab List of loci and their associated genomes loci_paralog_categories.tab Concatenation of classified paralogs loci_paralog_categories.tab.idx Index of the classified paralogs modified_gffs/${SAMPLE_NAME}.gff GFF3 files which have been standardised for PIRATE pangenome_alignment.fasta.gz Gene-by-gene nucleotide alignments of the full pangenome created using MAFFT pangenome_alignment.gff Annotation containing the position of the gene family within the pangenome alignment pangenome.connected_blocks.tsv List of connected blocks in the pangenome graph pangenome.edges List of classified edges in the pangenome graph pangenome.gfa GFA network file representing all unique connections between gene families pangenome_iterations/pan_sequences.{50|60|70|80|90|95|98}.reclustered.reinflated List of clusters for each reinflation threshold pangenome_iterations/pan_sequences.blast.output BLAST output of sequences against representatives and self hits. pangenome_iterations/pan_sequences.cdhit_clusters A list of CDHIT representative clusters pangenome_iterations/pan_sequences.core_clusters.tab A list of core clusters. pangenome_iterations/pan_sequences.mcl_log.txt A log file from mcxdeblast and mcl pangenome_iterations/pan_sequences.representative.fasta FASTA file with sequences for each representative cluster pangenome.order.tsv Sorted list gene_families file on pangenome graph pangenome.reversed.tsv List of reversed blocks in the pangenome graph pangenome.syntenic_blocks.tsv List of syntenic blocks in the pangenome graph pan_sequences.fasta All representative sequences in the pangenome paralog_clusters.tab List of paralogous clusters PIRATE.gene_families.ordered.tsv Tabular summary of all gene families ordered on syntenic regions in the pangenome graph PIRATE.gene_families.tsv Tabular summary of all gene families PIRATE.genomes_per_allele.tsv A list of genomes associated with each allele PIRATE.log PIRATE log file PIRATE.pangenome_summary.txt Short summary of the number and frequency of genes in the pangenome PIRATE_plots.pdf Summary plots of the PIRATE pangenome PIRATE.unique_alleles.tsv Tabular summary of all unique alleles of each gene family split_groups.log Concatenation of log files from splitting paralogs","title":"pirate"},{"location":"bactopia-tools/pirate/#refseq","text":"Extension Description .fna FASTA formated genome downloaded from NCBI Assembly database. .gff GFF output from the Prokka re-annotation of the reference FASTA","title":"refseq"},{"location":"bactopia-tools/pirate/#usage","text":"Required Parameters: --bactopia STR Directory containing Bactopia analysis results for all samples. This parameter is not required if '--only_completed' is used. Optional Parameters: --include STR A text file containing sample names to include in the analysis. The expected format is a single sample per line. --exclude STR A text file containing sample names to exclude from the analysis. The expected format is a single sample per line. --prefix DIR Prefix to use for final output files Default: core-genome --outdir DIR Directory to write results to Default: ./ --max_time INT The maximum number of minutes a job should run before being halted. Default: 2880 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single process. Default: 64 Gb --cpus INT Number of processors made available to a single process. Default: 10 RefSeq Assemblies Related Parameters: --assembly A single assembly, or directory of assemblies to be included in the pan-genome analysis. If compressed, gzip and the \".gz\" extension must be used. --assembly_pattern If a directory is given, use the given pattern to match assemblies. Default: *.fna --species STR The name of the species to download RefSeq assemblies for. This is a completely optional step and is meant to supplement your dataset with high-quality completed genomes. --accession STR A NCBI Assembly database RefSeq accession to be downloaded and included in the pan-genome analysis. --accessions STR A file with Assembly accessions (e.g. GCF*.*) to download from RefSeq. --limit INT Limit the number of RefSeq assemblies to download. If the the number of available genomes exceeds the given limit, a random subset will be selected. Default: Download all available genomes --only_completed Pan-genome will be created using only the completed RefSeq genomes. Requires either '--accessions' and/or '--species' --prokka_evalue STR Similarity e-value cut-off Default: 1e-09 --prokka_coverage INT Minimum coverage on query protein Default: 80 PIRATE Related Parameters: --steps STR Percent identity thresholds to use for pangenome construction Default: 50,60,70,80,90,95,98 --features STR Choose features to use for pangenome construction. Multiple may be entered, separated by a comma. Default: CDS --nucl Input CDS are nucleotides (e.g. not translated to AA sequence) --para_off Switch off paralog identification --keep_all_files Retain all intermediate files PIRATE Advanced Parameters: --perc INT Single percent identity threshold to use for pangenome Default: 98 % --cd_low INT CDHIT lowest percentage identity threshold Default: 98 % --cd_step FLOAT CDHIT step size Default: 0.5 --evalue STR E-value used for BLAST hit filtering Default: 1E-6 --hsp_len FLOAT Remove BLAST hsps that are < hsp_len proportion of query length Default: 0 --mcl_inflation FLOAT MCL inflation value Default: 1.5 --use_diamond Use Diamond instead of BLAST - incompatible with --nucl --split_diamond Split diamond files into batches for processing IQ-TREE Related Parameters: --skip_phylogeny Skip the creation a core-genome based phylogeny --m STR Substitution model name Default: MFP --bb INT Ultrafast bootstrap replicates Default: 1000 --alrt INT SH-like approximate likelihood ratio test replicates Default: 1000 --asr Ancestral state reconstruction by empirical Bayes Default: false --iqtree_opts STR Extra IQ-TREE options in quotes. Default: '' ClonalFrameML Related Parameters: --skip_clonalframe Skip the ClonalFrameML and use the original core-genome alignment for the final tree. --emsim INT Number of simulations to estimate uncertainty in the EM results. Default: 100 --clonal_opts STR Extra ClonalFrameML options in quotes. Default: '' SNP-Dists Related Parameters: --a Count all differences not just [AGTC] Default: false --b Blank top left corner cell Default: false --c Output CSV instead of TSV Default: false --k Keep case, don't uppercase all letters Default: false Nextflow Related Parameters: --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: true --conatainerPath Path to Singularity containers to be used by the 'slurm' profile. Default: /opt/bactopia/singularity --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds --nfconfig STR A Nextflow compatible config file for custom profiles. This allows you to create profiles specific to your environment (e.g. SGE, AWS, SLURM, etc...). This config file is loaded last and will overwrite existing variables if set. Default: Bactopia's default configs -resume Nextflow will attempt to resume a previous run. Please notice it is only a single '-' Useful Parameters: --version Print workflow version information --help Show this message and exit","title":"Usage"},{"location":"bactopia-tools/pirate/#conda-environment","text":"Below is the command that was used to create the Conda environment. conda create -y -n bactopia-pirate -c r -c conda-forge -c bioconda \\ bioconductor-ggtree \\ clonalframeml \\ iqtree \\ maskrc-svg \\ ncbi-genome-download \\ pigz \\ pirate \\ prokka \\ r-dplyr \\ r-ggplot2 \\ r-gridextra \\ r-phangorn \\ rename \\ snp-dists \\ tbl2asn-forever","title":"Conda Environment"},{"location":"bactopia-tools/pirate/#references","text":"ClonalFramML Didelot, X. & Wilson, D. J. ClonalFrameML: efficient inference of recombination in whole bacterial genomes. PLoS Comput. Biol. 11, e1004041 (2015) IQ-TREE L.-T. Nguyen, H.A. Schmidt, A. von Haeseler, B.Q. Minh (2015) IQ-TREE: A fast and effective stochastic algorithm for estimating maximum likelihood phylogenies. Mol. Biol. Evol., 32:268-274. S. Kalyaanamoorthy, B.Q. Minh, T.K.F. Wong, A. von Haeseler, L.S. Jermiin (2017) ModelFinder: Fast model selection for accurate phylogenetic estimates. Nat. Methods, 14:587-589. D.T. Hoang, O. Chernomor, A. von Haeseler, B.Q. Minh, L.S. Vinh (2018) UFBoot2: Improving the ultrafast bootstrap approximation. Mol. Biol. Evol., 35:518\u2013522. maskrc-svg Kwong, J. maskrc-svg - Masks recombination as detected by ClonalFrameML or Gubbins and draws an SVG. ncbi-genome-download Blin, K. ncbi-genome-download: Scripts to download genomes from the NCBI FTP servers PIRATE S. C. Bayliss, H. A. Thorpe, N. M. Coyle, S. K. Sheppard, E. J. Feil (2019) PIRATE: A fast and scalable pangenomics toolbox for clustering diverged orthologues in bacteria. Gigascience. 8 Prokka Seemann, T. Prokka: rapid prokaryotic genome annotation . Bioinformatics 30, 2068\u20132069 (2014). snp-dists Seemann, T. snp-dists - Pairwise SNP distance matrix from a FASTA sequence alignment.","title":"References"},{"location":"bactopia-tools/roary/","text":"Bactopia Tools - roary \u00b6 The roary tool allows you to create a pan-genome of your samples using Roary . Often times, you may also want to include completed genomes in your pan-genome analysis. This is possible with the roary tool. If you use the --species parameter, all completed genomes available from RefSeq will be downloaded with ncbi-genome-download and reannotated with Prokka (to make compatible gffs). You can also use the core genome alignment, produced by Roary, to create a core genome phylogeny using ClonalFrameMl , maskrc-svg , and IQ-TREE . The core genome pair-wise SNP distance for each sample is also calculated with snp-dists . Example \u00b6 The following command will run Roary, on a set of samples in the include file. Then it will create a phylogenetic tree based on the core-genome alignment. bactopia tools roary \\ --bactopia ~/bactopia-tutorial/bactopia \\ --include ~/bactopia-tutorial/GCF_900475245-include.txt \\ --cpus 4 \\ --n Output Overview \u00b6 Below is the default output structure for the roary tool. Where possible the file descriptions below were modified from a tools description. bactopia-tools \u2514\u2500\u2500roary/ \u2514\u2500\u2500 ${PREFIX} \u251c\u2500\u2500 bactopia-info \u2502 \u251c\u2500\u2500 roary-report.html \u2502 \u251c\u2500\u2500 roary-timeline.html \u2502 \u2514\u2500\u2500 roary-trace.txt \u251c\u2500\u2500 clonalframe \u2502 \u251c\u2500\u2500 clonalframe.emsim.txt \u2502 \u251c\u2500\u2500 clonalframe.em.txt \u2502 \u251c\u2500\u2500 clonalframe.importation_status.txt \u2502 \u251c\u2500\u2500 clonalframe.labelled_tree.newick \u2502 \u251c\u2500\u2500 clonalframe.ML_sequence.fasta \u2502 \u251c\u2500\u2500 clonalframe.position_cross_reference.txt \u2502 \u251c\u2500\u2500 core_gene_alignment-masked.aln.gz \u2502 \u251c\u2500\u2500 start-tree.bionj \u2502 \u251c\u2500\u2500 start-tree.ckp.gz \u2502 \u251c\u2500\u2500 start-tree.iqtree \u2502 \u251c\u2500\u2500 start-tree.log \u2502 \u251c\u2500\u2500 start-tree.mldist \u2502 \u251c\u2500\u2500 start-tree.model.gz \u2502 \u2514\u2500\u2500 start-tree.treefile \u251c\u2500\u2500 core-genome.aligned.fa.gz \u251c\u2500\u2500 core-genome.distance.txt \u251c\u2500\u2500 core-genome.iqtree \u251c\u2500\u2500 iqtree \u2502 \u251c\u2500\u2500 core-genome.alninfo \u2502 \u251c\u2500\u2500 core-genome.bionj \u2502 \u251c\u2500\u2500 core-genome.ckp.gz \u2502 \u251c\u2500\u2500 core-genome.contree \u2502 \u251c\u2500\u2500 core-genome.iqtree \u2502 \u251c\u2500\u2500 core-genome.log \u2502 \u251c\u2500\u2500 core-genome.mldist \u2502 \u251c\u2500\u2500 core-genome.model.gz \u2502 \u251c\u2500\u2500 core-genome.splits.nex \u2502 \u251c\u2500\u2500 core-genome.treefile \u2502 \u2514\u2500\u2500 core-genome.ufboot \u251c\u2500\u2500 refseq \u2502 \u251c\u2500\u2500 fasta \u2502 \u2502 \u2514\u2500\u2500 GCF_900475245.fna \u2502 \u2514\u2500\u2500 gff \u2502 \u2514\u2500\u2500 GCF_900475245.gff \u2514\u2500\u2500 roary \u251c\u2500\u2500 accessory_binary_genes.fa \u251c\u2500\u2500 accessory_binary_genes.fa.newick \u251c\u2500\u2500 accessory_graph.dot \u251c\u2500\u2500 accessory.header.embl \u251c\u2500\u2500 accessory.tab \u251c\u2500\u2500 blast_identity_frequency.Rtab \u251c\u2500\u2500 clustered_proteins \u251c\u2500\u2500 conserved_vs_total_genes.png \u251c\u2500\u2500 core_accessory_graph.dot \u251c\u2500\u2500 core_accessory.header.embl \u251c\u2500\u2500 core_accessory.tab \u251c\u2500\u2500 core_alignment_header.embl \u251c\u2500\u2500 core_gene_alignment.aln.gz \u251c\u2500\u2500 gene_presence_absence.csv \u251c\u2500\u2500 gene_presence_absence.Rtab \u251c\u2500\u2500 number_of_conserved_genes.Rtab \u251c\u2500\u2500 number_of_genes_in_pan_genome.Rtab \u251c\u2500\u2500 number_of_new_genes.Rtab \u251c\u2500\u2500 number_of_unique_genes.Rtab \u251c\u2500\u2500 pan_genome_reference.fa \u251c\u2500\u2500 Rplots.pdf \u251c\u2500\u2500 summary_statistics.txt \u2514\u2500\u2500 unique_vs_new_genes.png Filename Description core-genome.aligned.fa.gz A multiple sequence alignment FASTA of the core genome core-genome.distance.txt Core genome Pair-wise SNP distance for each sample core-genome.iqtree Full result of the IQ-TREE core genome phylogeny Directory Description \u00b6 bactopia-info \u00b6 Filename Description roary-report.html The Nextflow Execution Report roary-timeline.html The Nextflow Timeline Report roary-trace.txt The Nextflow Trace report clonalframe \u00b6 Where possible descriptions were taken from the ClonalFrameML Wiki , IQ-TREE's Command Reference page, Web Server Tutorial page, and the Tutorial page. Filename Description clonalframe.emsim.txt The bootstrapped values for the three parameters R/theta, nu and delta clonalframe.em.txt The point estimates for R/theta, nu, delta and the branch lengths clonalframe.importation_status.txt The list of reconstructed recombination events clonalframe.labelled_tree.newick The output tree with all nodes labelled so that they can be referred to in other files clonalframe.ML_sequence.fasta The sequence reconstructed by maximum likelihood for all internal nodes of the phylogeny, as well as for all missing data in the input sequences clonalframe.position_cross_reference.txt A vector of comma-separated values indicating for each location in the input sequence file the corresponding position in the sequences in the output ML_sequence.fasta file core_gene_alignment-masked.aln.gz A core-genome alignment with the recomination masked start-tree.bionj A neighbor joining tree produced by BIONJ start-tree.ckp.gz IQ-TREE writes a checkpoint file start-tree.iqtree Full result of the run, this is the main report file start-tree.log Run log start-tree.mldist Contains the likelihood distances start-tree.model.gz Information about all models tested start-tree.treefile Maximum likelihood tree in NEWICK format, can be visualized with treeviewer programs iqtree \u00b6 Where possible descriptions were taken from IQ-TREE's Command Reference page, Web Server Tutorial page, and the Tutorial page. Filename Description core-genome.alninfo Alignment site statistics core-genome.bionj A neighbor joining tree produced by BIONJ core-genome.ckp.gz IQ-TREE writes a checkpoint file core-genome.contree Consensus tree with assigned branch supports where branch lengths are optimized on the original alignment; printed if Ultrafast Bootstrap is selected core-genome.iqtree Full result of the run, this is the main report file core-genome.log Run log core-genome.mldist Contains the likelihood distances core-genome.model.gz Information about all models tested core-genome.splits.nex Support values in percentage for all splits (bipartitions), computed as the occurence frequencies in the bootstrap trees core-genome.treefile Maximum likelihood tree in NEWICK format, can be visualized with treeviewer programs core-genome.ufboot Trees created during the bootstrap steps refseq \u00b6 Extension Description .fna FASTA formated genome downloaded from NCBI Assembly database. .gff GFF output from the Prokka re-annotation of the reference FASTA roary \u00b6 Where possible descriptions were taken from the Roary Documentation . Filename Description accessory_binary_genes.fa A FASTA file with binary presence and absence of accessory genes accessory_binary_genes.fa.newick A tree created using the binary presence and absence of accessory genes accessory_graph.dot A graph in DOT format of how genes are linked together at the contig level in the accessory genome accessory.header.embl Tab/EMBL formatted file of accessory genes accessory.tab Tab/EMBL formatted file of accessory genes blast_identity_frequency.Rtab Blast results for percentage idenity graph clustered_proteins Groups file where each line lists the sequences in a cluster conserved_vs_total_genes.png Plot compairing conserved genes and total genes core_accessory_graph.dot A graph in DOT format of how genes are linked together at the contig level in the pan genome core_accessory.header.embl Tab/EMBL formatted file of core genes core_accessory.tab Tab/EMBL formatted file of core genes core_alignment_header.embl Tab/EMBL formatted file of core genome alignment core_gene_alignment.aln.gz A multi-FASTA alignment of all of the core genes gene_presence_absence.csv Lists each gene and which samples it is present in gene_presence_absence.Rtab Tab delimited binary matrix with the presence and absence of each gene in each sample number_of_conserved_genes.Rtab Graphs on how the pan genome varies as genomes are added (in random orders) number_of_genes_in_pan_genome.Rtab Graphs on how the pan genome varies as genomes are added (in random orders) number_of_new_genes.Rtab Graphs on how the pan genome varies as genomes are added (in random orders) number_of_unique_genes.Rtab Graphs on how the pan genome varies as genomes are added (in random orders) pan_genome_reference.fa FASTA file which contains a single representative nucleotide sequence from each of the clusters in the pan genome (core and accessory) Rplots.pdf PDF containing each plot summary_statistics.txt Number of genes in the core and accessory unique_vs_new_genes.png Plot compairing new vs old genes Usage \u00b6 Required Parameters: --bactopia STR Directory containing Bactopia analysis results for all samples. Optional Parameters: --include STR A text file containing sample names to include in the analysis. The expected format is a single sample per line. --exclude STR A text file containing sample names to exclude from the analysis. The expected format is a single sample per line. --prefix DIR Prefix to use for final output files Default: core-genome --outdir DIR Directory to write results to Default: ./ --max_time INT The maximum number of minutes a job should run before being halted. Default: 2880 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single process. Default: 64 Gb --cpus INT Number of processors made available to a single process. Default: 1 RefSeq Assemblies Related Parameters: --assembly A single assembly, or directory of assemblies to be included in the pan-genome analysis. If compressed, gzip and the \".gz\" extension must be used. --assembly_pattern If a directory is given, use the given pattern to match assemblies. Default: *.fna --species STR The name of the species to download RefSeq assemblies for. This is a completely optional step and is meant to supplement your dataset with high-quality completed genomes. --accession STR A NCBI Assembly database RefSeq accession to be downloaded and included in the pan-genome analysis. --limit INT Limit the number of RefSeq assemblies to download. If the the number of available genomes exceeds the given limit, a random subset will be selected. Default: Download all available genomes --only_completed Pan-genome will be created using only the completed RefSeq genomes. --prokka_evalue STR Similarity e-value cut-off Default: 1e-09 --prokka_coverage INT Minimum coverage on query protein Default: 80 Roary Related Parameters: --o STR Clusters output filename Default: clustered_proteins --n Execute a fast core gene alignment with MAFFT Default: Use PRANK --i INT Minimum percentage identity for blastp Default: 95 --cd INT Percentage of isolates a gene must be in to be core Default: 99% --g INT Maximum number of clusters Default: 50000 --s Do not split paralogs Default: false --ap Allow paralogs in core alignment Default: false --iv STR Change the MCL inflation value Default: 1.5 IQ-TREE Related Parameters: --skip_phylogeny Skip the creation a core-genome based phylogeny --m STR Substitution model name Default: MFP --bb INT Ultrafast bootstrap replicates Default: 1000 --alrt INT SH-like approximate likelihood ratio test replicates Default: 1000 --asr Ancestral state reconstruction by empirical Bayes Default: false --iqtree_opts STR Extra IQ-TREE options in quotes. Default: '' ClonalFrameML Related Parameters: --skip_clonalframe Skip the ClonalFrameML and use the original core-genome alignment for the final tree. --emsim INT Number of simulations to estimate uncertainty in the EM results. Default: 100 --clonal_opts STR Extra ClonalFrameML options in quotes. Default: '' SNP-Dists Related Parameters: --a Count all differences not just [AGTC] Default: false --b Blank top left corner cell Default: false --c Output CSV instead of TSV Default: false --k Keep case, don't uppercase all letters Default: false Nextflow Related Parameters: --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: null --conatainerPath Path to Singularity containers to be used by the 'slurm' profile. Default: /opt/bactopia/singularity --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds Useful Parameters: --version Print workflow version information --help Show this message and exit Conda Environment \u00b6 Below is the command that was used to create the Conda environment. conda create -y -n bactopia-roary -c r -c conda-forge -c bioconda \\ clonalframeml \\ iqtree \\ maskrc-svg \\ ncbi-genome-download \\ pigz \\ prokka \\ r-ggplot2 \\ rename \\ roary \\ snp-dists \\ tbl2asn-forever References \u00b6 ClonalFramML Didelot, X. & Wilson, D. J. ClonalFrameML: efficient inference of recombination in whole bacterial genomes. PLoS Comput. Biol. 11, e1004041 (2015) IQ-TREE L.-T. Nguyen, H.A. Schmidt, A. von Haeseler, B.Q. Minh (2015) IQ-TREE: A fast and effective stochastic algorithm for estimating maximum likelihood phylogenies. Mol. Biol. Evol., 32:268-274. S. Kalyaanamoorthy, B.Q. Minh, T.K.F. Wong, A. von Haeseler, L.S. Jermiin (2017) ModelFinder: Fast model selection for accurate phylogenetic estimates. Nat. Methods, 14:587-589. D.T. Hoang, O. Chernomor, A. von Haeseler, B.Q. Minh, L.S. Vinh (2018) UFBoot2: Improving the ultrafast bootstrap approximation. Mol. Biol. Evol., 35:518\u2013522. maskrc-svg Kwong, J. maskrc-svg - Masks recombination as detected by ClonalFrameML or Gubbins and draws an SVG. ncbi-genome-download Blin, K. ncbi-genome-download: Scripts to download genomes from the NCBI FTP servers Prokka Seemann, T. Prokka: rapid prokaryotic genome annotation . Bioinformatics 30, 2068\u20132069 (2014). Roary Page, A. J. et al. Roary: rapid large-scale prokaryote pan genome analysis. Bioinformatics 31, 3691\u20133693 (2015) snp-dists Seemann, T. snp-dists - Pairwise SNP distance matrix from a FASTA sequence alignment.","title":"roary"},{"location":"bactopia-tools/roary/#bactopia-tools-roary","text":"The roary tool allows you to create a pan-genome of your samples using Roary . Often times, you may also want to include completed genomes in your pan-genome analysis. This is possible with the roary tool. If you use the --species parameter, all completed genomes available from RefSeq will be downloaded with ncbi-genome-download and reannotated with Prokka (to make compatible gffs). You can also use the core genome alignment, produced by Roary, to create a core genome phylogeny using ClonalFrameMl , maskrc-svg , and IQ-TREE . The core genome pair-wise SNP distance for each sample is also calculated with snp-dists .","title":"Bactopia Tools - roary"},{"location":"bactopia-tools/roary/#example","text":"The following command will run Roary, on a set of samples in the include file. Then it will create a phylogenetic tree based on the core-genome alignment. bactopia tools roary \\ --bactopia ~/bactopia-tutorial/bactopia \\ --include ~/bactopia-tutorial/GCF_900475245-include.txt \\ --cpus 4 \\ --n","title":"Example"},{"location":"bactopia-tools/roary/#output-overview","text":"Below is the default output structure for the roary tool. Where possible the file descriptions below were modified from a tools description. bactopia-tools \u2514\u2500\u2500roary/ \u2514\u2500\u2500 ${PREFIX} \u251c\u2500\u2500 bactopia-info \u2502 \u251c\u2500\u2500 roary-report.html \u2502 \u251c\u2500\u2500 roary-timeline.html \u2502 \u2514\u2500\u2500 roary-trace.txt \u251c\u2500\u2500 clonalframe \u2502 \u251c\u2500\u2500 clonalframe.emsim.txt \u2502 \u251c\u2500\u2500 clonalframe.em.txt \u2502 \u251c\u2500\u2500 clonalframe.importation_status.txt \u2502 \u251c\u2500\u2500 clonalframe.labelled_tree.newick \u2502 \u251c\u2500\u2500 clonalframe.ML_sequence.fasta \u2502 \u251c\u2500\u2500 clonalframe.position_cross_reference.txt \u2502 \u251c\u2500\u2500 core_gene_alignment-masked.aln.gz \u2502 \u251c\u2500\u2500 start-tree.bionj \u2502 \u251c\u2500\u2500 start-tree.ckp.gz \u2502 \u251c\u2500\u2500 start-tree.iqtree \u2502 \u251c\u2500\u2500 start-tree.log \u2502 \u251c\u2500\u2500 start-tree.mldist \u2502 \u251c\u2500\u2500 start-tree.model.gz \u2502 \u2514\u2500\u2500 start-tree.treefile \u251c\u2500\u2500 core-genome.aligned.fa.gz \u251c\u2500\u2500 core-genome.distance.txt \u251c\u2500\u2500 core-genome.iqtree \u251c\u2500\u2500 iqtree \u2502 \u251c\u2500\u2500 core-genome.alninfo \u2502 \u251c\u2500\u2500 core-genome.bionj \u2502 \u251c\u2500\u2500 core-genome.ckp.gz \u2502 \u251c\u2500\u2500 core-genome.contree \u2502 \u251c\u2500\u2500 core-genome.iqtree \u2502 \u251c\u2500\u2500 core-genome.log \u2502 \u251c\u2500\u2500 core-genome.mldist \u2502 \u251c\u2500\u2500 core-genome.model.gz \u2502 \u251c\u2500\u2500 core-genome.splits.nex \u2502 \u251c\u2500\u2500 core-genome.treefile \u2502 \u2514\u2500\u2500 core-genome.ufboot \u251c\u2500\u2500 refseq \u2502 \u251c\u2500\u2500 fasta \u2502 \u2502 \u2514\u2500\u2500 GCF_900475245.fna \u2502 \u2514\u2500\u2500 gff \u2502 \u2514\u2500\u2500 GCF_900475245.gff \u2514\u2500\u2500 roary \u251c\u2500\u2500 accessory_binary_genes.fa \u251c\u2500\u2500 accessory_binary_genes.fa.newick \u251c\u2500\u2500 accessory_graph.dot \u251c\u2500\u2500 accessory.header.embl \u251c\u2500\u2500 accessory.tab \u251c\u2500\u2500 blast_identity_frequency.Rtab \u251c\u2500\u2500 clustered_proteins \u251c\u2500\u2500 conserved_vs_total_genes.png \u251c\u2500\u2500 core_accessory_graph.dot \u251c\u2500\u2500 core_accessory.header.embl \u251c\u2500\u2500 core_accessory.tab \u251c\u2500\u2500 core_alignment_header.embl \u251c\u2500\u2500 core_gene_alignment.aln.gz \u251c\u2500\u2500 gene_presence_absence.csv \u251c\u2500\u2500 gene_presence_absence.Rtab \u251c\u2500\u2500 number_of_conserved_genes.Rtab \u251c\u2500\u2500 number_of_genes_in_pan_genome.Rtab \u251c\u2500\u2500 number_of_new_genes.Rtab \u251c\u2500\u2500 number_of_unique_genes.Rtab \u251c\u2500\u2500 pan_genome_reference.fa \u251c\u2500\u2500 Rplots.pdf \u251c\u2500\u2500 summary_statistics.txt \u2514\u2500\u2500 unique_vs_new_genes.png Filename Description core-genome.aligned.fa.gz A multiple sequence alignment FASTA of the core genome core-genome.distance.txt Core genome Pair-wise SNP distance for each sample core-genome.iqtree Full result of the IQ-TREE core genome phylogeny","title":"Output Overview"},{"location":"bactopia-tools/roary/#directory-description","text":"","title":"Directory Description"},{"location":"bactopia-tools/roary/#bactopia-info","text":"Filename Description roary-report.html The Nextflow Execution Report roary-timeline.html The Nextflow Timeline Report roary-trace.txt The Nextflow Trace report","title":"bactopia-info"},{"location":"bactopia-tools/roary/#clonalframe","text":"Where possible descriptions were taken from the ClonalFrameML Wiki , IQ-TREE's Command Reference page, Web Server Tutorial page, and the Tutorial page. Filename Description clonalframe.emsim.txt The bootstrapped values for the three parameters R/theta, nu and delta clonalframe.em.txt The point estimates for R/theta, nu, delta and the branch lengths clonalframe.importation_status.txt The list of reconstructed recombination events clonalframe.labelled_tree.newick The output tree with all nodes labelled so that they can be referred to in other files clonalframe.ML_sequence.fasta The sequence reconstructed by maximum likelihood for all internal nodes of the phylogeny, as well as for all missing data in the input sequences clonalframe.position_cross_reference.txt A vector of comma-separated values indicating for each location in the input sequence file the corresponding position in the sequences in the output ML_sequence.fasta file core_gene_alignment-masked.aln.gz A core-genome alignment with the recomination masked start-tree.bionj A neighbor joining tree produced by BIONJ start-tree.ckp.gz IQ-TREE writes a checkpoint file start-tree.iqtree Full result of the run, this is the main report file start-tree.log Run log start-tree.mldist Contains the likelihood distances start-tree.model.gz Information about all models tested start-tree.treefile Maximum likelihood tree in NEWICK format, can be visualized with treeviewer programs","title":"clonalframe"},{"location":"bactopia-tools/roary/#iqtree","text":"Where possible descriptions were taken from IQ-TREE's Command Reference page, Web Server Tutorial page, and the Tutorial page. Filename Description core-genome.alninfo Alignment site statistics core-genome.bionj A neighbor joining tree produced by BIONJ core-genome.ckp.gz IQ-TREE writes a checkpoint file core-genome.contree Consensus tree with assigned branch supports where branch lengths are optimized on the original alignment; printed if Ultrafast Bootstrap is selected core-genome.iqtree Full result of the run, this is the main report file core-genome.log Run log core-genome.mldist Contains the likelihood distances core-genome.model.gz Information about all models tested core-genome.splits.nex Support values in percentage for all splits (bipartitions), computed as the occurence frequencies in the bootstrap trees core-genome.treefile Maximum likelihood tree in NEWICK format, can be visualized with treeviewer programs core-genome.ufboot Trees created during the bootstrap steps","title":"iqtree"},{"location":"bactopia-tools/roary/#refseq","text":"Extension Description .fna FASTA formated genome downloaded from NCBI Assembly database. .gff GFF output from the Prokka re-annotation of the reference FASTA","title":"refseq"},{"location":"bactopia-tools/roary/#roary","text":"Where possible descriptions were taken from the Roary Documentation . Filename Description accessory_binary_genes.fa A FASTA file with binary presence and absence of accessory genes accessory_binary_genes.fa.newick A tree created using the binary presence and absence of accessory genes accessory_graph.dot A graph in DOT format of how genes are linked together at the contig level in the accessory genome accessory.header.embl Tab/EMBL formatted file of accessory genes accessory.tab Tab/EMBL formatted file of accessory genes blast_identity_frequency.Rtab Blast results for percentage idenity graph clustered_proteins Groups file where each line lists the sequences in a cluster conserved_vs_total_genes.png Plot compairing conserved genes and total genes core_accessory_graph.dot A graph in DOT format of how genes are linked together at the contig level in the pan genome core_accessory.header.embl Tab/EMBL formatted file of core genes core_accessory.tab Tab/EMBL formatted file of core genes core_alignment_header.embl Tab/EMBL formatted file of core genome alignment core_gene_alignment.aln.gz A multi-FASTA alignment of all of the core genes gene_presence_absence.csv Lists each gene and which samples it is present in gene_presence_absence.Rtab Tab delimited binary matrix with the presence and absence of each gene in each sample number_of_conserved_genes.Rtab Graphs on how the pan genome varies as genomes are added (in random orders) number_of_genes_in_pan_genome.Rtab Graphs on how the pan genome varies as genomes are added (in random orders) number_of_new_genes.Rtab Graphs on how the pan genome varies as genomes are added (in random orders) number_of_unique_genes.Rtab Graphs on how the pan genome varies as genomes are added (in random orders) pan_genome_reference.fa FASTA file which contains a single representative nucleotide sequence from each of the clusters in the pan genome (core and accessory) Rplots.pdf PDF containing each plot summary_statistics.txt Number of genes in the core and accessory unique_vs_new_genes.png Plot compairing new vs old genes","title":"roary"},{"location":"bactopia-tools/roary/#usage","text":"Required Parameters: --bactopia STR Directory containing Bactopia analysis results for all samples. Optional Parameters: --include STR A text file containing sample names to include in the analysis. The expected format is a single sample per line. --exclude STR A text file containing sample names to exclude from the analysis. The expected format is a single sample per line. --prefix DIR Prefix to use for final output files Default: core-genome --outdir DIR Directory to write results to Default: ./ --max_time INT The maximum number of minutes a job should run before being halted. Default: 2880 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single process. Default: 64 Gb --cpus INT Number of processors made available to a single process. Default: 1 RefSeq Assemblies Related Parameters: --assembly A single assembly, or directory of assemblies to be included in the pan-genome analysis. If compressed, gzip and the \".gz\" extension must be used. --assembly_pattern If a directory is given, use the given pattern to match assemblies. Default: *.fna --species STR The name of the species to download RefSeq assemblies for. This is a completely optional step and is meant to supplement your dataset with high-quality completed genomes. --accession STR A NCBI Assembly database RefSeq accession to be downloaded and included in the pan-genome analysis. --limit INT Limit the number of RefSeq assemblies to download. If the the number of available genomes exceeds the given limit, a random subset will be selected. Default: Download all available genomes --only_completed Pan-genome will be created using only the completed RefSeq genomes. --prokka_evalue STR Similarity e-value cut-off Default: 1e-09 --prokka_coverage INT Minimum coverage on query protein Default: 80 Roary Related Parameters: --o STR Clusters output filename Default: clustered_proteins --n Execute a fast core gene alignment with MAFFT Default: Use PRANK --i INT Minimum percentage identity for blastp Default: 95 --cd INT Percentage of isolates a gene must be in to be core Default: 99% --g INT Maximum number of clusters Default: 50000 --s Do not split paralogs Default: false --ap Allow paralogs in core alignment Default: false --iv STR Change the MCL inflation value Default: 1.5 IQ-TREE Related Parameters: --skip_phylogeny Skip the creation a core-genome based phylogeny --m STR Substitution model name Default: MFP --bb INT Ultrafast bootstrap replicates Default: 1000 --alrt INT SH-like approximate likelihood ratio test replicates Default: 1000 --asr Ancestral state reconstruction by empirical Bayes Default: false --iqtree_opts STR Extra IQ-TREE options in quotes. Default: '' ClonalFrameML Related Parameters: --skip_clonalframe Skip the ClonalFrameML and use the original core-genome alignment for the final tree. --emsim INT Number of simulations to estimate uncertainty in the EM results. Default: 100 --clonal_opts STR Extra ClonalFrameML options in quotes. Default: '' SNP-Dists Related Parameters: --a Count all differences not just [AGTC] Default: false --b Blank top left corner cell Default: false --c Output CSV instead of TSV Default: false --k Keep case, don't uppercase all letters Default: false Nextflow Related Parameters: --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: null --conatainerPath Path to Singularity containers to be used by the 'slurm' profile. Default: /opt/bactopia/singularity --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds Useful Parameters: --version Print workflow version information --help Show this message and exit","title":"Usage"},{"location":"bactopia-tools/roary/#conda-environment","text":"Below is the command that was used to create the Conda environment. conda create -y -n bactopia-roary -c r -c conda-forge -c bioconda \\ clonalframeml \\ iqtree \\ maskrc-svg \\ ncbi-genome-download \\ pigz \\ prokka \\ r-ggplot2 \\ rename \\ roary \\ snp-dists \\ tbl2asn-forever","title":"Conda Environment"},{"location":"bactopia-tools/roary/#references","text":"ClonalFramML Didelot, X. & Wilson, D. J. ClonalFrameML: efficient inference of recombination in whole bacterial genomes. PLoS Comput. Biol. 11, e1004041 (2015) IQ-TREE L.-T. Nguyen, H.A. Schmidt, A. von Haeseler, B.Q. Minh (2015) IQ-TREE: A fast and effective stochastic algorithm for estimating maximum likelihood phylogenies. Mol. Biol. Evol., 32:268-274. S. Kalyaanamoorthy, B.Q. Minh, T.K.F. Wong, A. von Haeseler, L.S. Jermiin (2017) ModelFinder: Fast model selection for accurate phylogenetic estimates. Nat. Methods, 14:587-589. D.T. Hoang, O. Chernomor, A. von Haeseler, B.Q. Minh, L.S. Vinh (2018) UFBoot2: Improving the ultrafast bootstrap approximation. Mol. Biol. Evol., 35:518\u2013522. maskrc-svg Kwong, J. maskrc-svg - Masks recombination as detected by ClonalFrameML or Gubbins and draws an SVG. ncbi-genome-download Blin, K. ncbi-genome-download: Scripts to download genomes from the NCBI FTP servers Prokka Seemann, T. Prokka: rapid prokaryotic genome annotation . Bioinformatics 30, 2068\u20132069 (2014). Roary Page, A. J. et al. Roary: rapid large-scale prokaryote pan genome analysis. Bioinformatics 31, 3691\u20133693 (2015) snp-dists Seemann, T. snp-dists - Pairwise SNP distance matrix from a FASTA sequence alignment.","title":"References"},{"location":"bactopia-tools/staph-typer/","text":"Bactopia Tools - staph-typer \u00b6 The staph-typer tool includes multiple tools that are specific for typing certain features of Staphylococcus aureus . Currently staph-typer includes AgrVATE - agr locus type and agr operon variants. spaTyper - spa type staphopia-sccmec - SCCmec type This tool will evolve with S. aureus genomics, so you can expect it to add more typing methods (maybe even replace current methods) in the future. If a certain typing method for S. aureus please feel free to suggest it be added!~ Example \u00b6 The following command will run staph-typer on each available sample. bactopia tools staph-typer --bactopia ~/bactopia-tutorial/bactopia Output Overview \u00b6 Below is the default output structure for the staph-typer tool. Where possible the file descriptions below were modified from a tools description. bactopia-tools/ \u2514\u2500\u2500 staph-typer/ \u2514\u2500\u2500 ${PREFIX}/ \u251c\u2500\u2500 bactopia-info \u2502 \u251c\u2500\u2500 staph-typer-report.html \u2502 \u251c\u2500\u2500 staph-typer-timeline.html \u2502 \u2514\u2500\u2500 staph-typer-trace.txt \u2514\u2500\u2500 ${SAMPLE_NAME} \u2502 \u251c\u2500\u2500 agrvate \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}-agr_gp.tab \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}-agr_operon.fna \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}-agr_operon_frameshifts.tab \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}-blastn_log.txt \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}-mummer/ \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}-mummer-log.txt \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}-snippy/ \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}-snippy-log.txt \u2502 \u2502 \u2514\u2500\u2500 ${SAMPLE_NAME}-summary.tab \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}-spatyper.txt \u2502 \u2514\u2500\u2500 ${SAMPLE_NAME}-sccmec.txt \u251c\u2500\u2500 agrvate-results.txt \u251c\u2500\u2500 spatyper-results.txt \u2514\u2500\u2500 sccmec-results.txt Below is a description of staph-typer outputs. Filename Description agrvate-results.txt Merged set of outputs from AgrVATE spatyper-results.txt Merged set of outputs from spaTyper sccmec-results.txt Merged set of outputs from staphopia-sccmec Directory Description \u00b6 bactopia-info \u00b6 Filename Description staph-typer-report.html The Nextflow Execution Report staph-typer-timeline.html The Nextflow Timeline Report staph-typer-trace.txt The Nextflow Trace report Per Sample \u00b6 Filename Description ${SAMPLE_NAME}-spatyper.txt Predicted spa type from spaTyper ${SAMPLE_NAME}-sccmec.txt Predicted SCCmec type from staphopia-sccmec agrvate \u00b6 AgrVATE includes outputs from multiple programs so it gets a separate directory within the sample directory. Extension Description -agr_gp.tab Detailed report for agr kmer matches -agr_operon.fna Agr operon extracted from in-silico PCR -agr_operon_frameshifts.tab Frameshift mutations in CDS of extracted agr operon detected by Snippy log.txt Log files from programs called by AgrVATE -{mummer|snippy}/ Intermediate files from mummer and snippy -summary.tab A final summary report for agr typing Usage \u00b6 Required Parameters: --bactopia STR Directory containing Bactopia analysis results for all samples. AgrVATE Parameters: --typing_only Does agr typing only. Skips agr operon extraction and frameshift detection. spaTyper Parameters: --do_enrich Do PCR product enrichment staphopia-sccmec Parameters: --hamming Report the results as hamming distances. Default: True (perfect match) or False (at least one mismatch) Optional Parameters: --include STR A text file containing sample names to include in the analysis. The expected format is a single sample per line. --exclude STR A text file containing sample names to exclude from the analysis. The expected format is a single sample per line. --prefix DIR Prefix to use for final output files Default: staph-typer --outdir DIR Directory to write results to Default: ./ --min_time INT The minimum number of minutes a job should run before being halted. Default: 60 minutes --max_time INT The maximum number of minutes a job should run before being halted. Default: 120 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single process. Default: 32 Gb --cpus INT Number of processors made available to a single process. Default: 1 Nextflow Related Parameters: --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --registry STR Docker registry to pull containers from. Available options: dockerhub, quay, or github Default: dockerhub --singularity_cache STR Directory where remote Singularity images are stored. If using a cluster, it must be accessible from all compute nodes. Default: NXF_SINGULARITY_CACHEDIR evironment variable, otherwise /local/home/rpetit/.bactopia/singularity --queue STR The name of the queue(s) to be used by a job scheduler (e.g. AWS Batch or SLURM). If using multiple queues, please seperate queues by a comma without spaces. Default: general --disable_scratch All intermediate files created on worker nodes of will be transferred to the head node. Default: Only result files are transferred back --cleanup_workdir After Bactopia is successfully executed, the work directory will be deleted. Warning: by doing this you lose the ability to resume workflows. --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: true --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds --nfconfig STR A Nextflow compatible config file for custom profiles. This allows you to create profiles specific to your environment (e.g. SGE, AWS, SLURM, etc...). This config file is loaded last and will overwrite existing variables if set. Default: Bactopia's default configs -resume Nextflow will attempt to resume a previous run. Please notice it is only a single '-' AWS Batch Related Parameters: --aws_region STR AWS Region to be used by Nextflow Default: us-east-1 --aws_volumes STR Volumes to be mounted from the EC2 instance to the Docker container Default: /opt/conda:/mnt/conda --aws_cli_path STR Path to the AWS CLI for Nextflow to use. Default: /home/ec2-user/conda/bin/aws --aws_upload_storage_class STR The S3 storage slass to use for storing files on S3 Default: STANDARD --aws_max_parallel_transfers INT The number of parallele transfers between EC2 and S3 Default: 8 --aws_delay_between_attempts INT The duration of sleep (in seconds) between each transfer between EC2 and S3 Default: 15 --aws_max_transfer_attempts INT The maximum number of times to retry transferring a file between EC2 and S3 Default: 3 --aws_max_retry INT The maximum number of times to retry a process on AWS Batch Default: 4 --aws_ecr_registry STR The ECR registry containing Bactopia related containers. Default: Use the registry given by --registry Useful Parameters: --version Print workflow version information --help Show this message and exit Conda Environment \u00b6 Below is the command used to create the Conda environment. conda create -n staph-typer -c conda-forge -c bioconda agrvate spatyper staphopia-sccmec 'snippy>=4.5.0' References \u00b6 AgrVATE Rapid identification of Staphylococcus aureus agr locus type and agr operon variants. Raghuram V., AgrVATE: Rapid identification of Staphylococcus aureus agr locus type and agr operon variants. spaTyper Computational method for finding spa types. Harmsen D., Claus H., Witte W., Rothg\u00e4nger J., Claus H., Turnwald D., and Vogel U.. Typing of methicillin-resistant Staphylococcus aureus in a university hospital setting using a novel software for spa-repeat determination and database management. J. Clin. Microbiol. 41:5442-5448 (2003). Sanchez-Herrero J. F., and Sullivan M. (2020, October 2). spaTyper: Staphylococcal protein A (spa) characterization pipeline . Zenodo. staphopia-sccmec A standalone version of Staphopia's SCCmec typing method. Petit III R. A., Read T. D., Staphylococcus aureus viewed from the perspective of 40,000+ genomes. PeerJ 6, e5261 (2018).","title":"staph-typer"},{"location":"bactopia-tools/staph-typer/#bactopia-tools-staph-typer","text":"The staph-typer tool includes multiple tools that are specific for typing certain features of Staphylococcus aureus . Currently staph-typer includes AgrVATE - agr locus type and agr operon variants. spaTyper - spa type staphopia-sccmec - SCCmec type This tool will evolve with S. aureus genomics, so you can expect it to add more typing methods (maybe even replace current methods) in the future. If a certain typing method for S. aureus please feel free to suggest it be added!~","title":"Bactopia Tools - staph-typer"},{"location":"bactopia-tools/staph-typer/#example","text":"The following command will run staph-typer on each available sample. bactopia tools staph-typer --bactopia ~/bactopia-tutorial/bactopia","title":"Example"},{"location":"bactopia-tools/staph-typer/#output-overview","text":"Below is the default output structure for the staph-typer tool. Where possible the file descriptions below were modified from a tools description. bactopia-tools/ \u2514\u2500\u2500 staph-typer/ \u2514\u2500\u2500 ${PREFIX}/ \u251c\u2500\u2500 bactopia-info \u2502 \u251c\u2500\u2500 staph-typer-report.html \u2502 \u251c\u2500\u2500 staph-typer-timeline.html \u2502 \u2514\u2500\u2500 staph-typer-trace.txt \u2514\u2500\u2500 ${SAMPLE_NAME} \u2502 \u251c\u2500\u2500 agrvate \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}-agr_gp.tab \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}-agr_operon.fna \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}-agr_operon_frameshifts.tab \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}-blastn_log.txt \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}-mummer/ \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}-mummer-log.txt \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}-snippy/ \u2502 \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}-snippy-log.txt \u2502 \u2502 \u2514\u2500\u2500 ${SAMPLE_NAME}-summary.tab \u2502 \u251c\u2500\u2500 ${SAMPLE_NAME}-spatyper.txt \u2502 \u2514\u2500\u2500 ${SAMPLE_NAME}-sccmec.txt \u251c\u2500\u2500 agrvate-results.txt \u251c\u2500\u2500 spatyper-results.txt \u2514\u2500\u2500 sccmec-results.txt Below is a description of staph-typer outputs. Filename Description agrvate-results.txt Merged set of outputs from AgrVATE spatyper-results.txt Merged set of outputs from spaTyper sccmec-results.txt Merged set of outputs from staphopia-sccmec","title":"Output Overview"},{"location":"bactopia-tools/staph-typer/#directory-description","text":"","title":"Directory Description"},{"location":"bactopia-tools/staph-typer/#bactopia-info","text":"Filename Description staph-typer-report.html The Nextflow Execution Report staph-typer-timeline.html The Nextflow Timeline Report staph-typer-trace.txt The Nextflow Trace report","title":"bactopia-info"},{"location":"bactopia-tools/staph-typer/#per-sample","text":"Filename Description ${SAMPLE_NAME}-spatyper.txt Predicted spa type from spaTyper ${SAMPLE_NAME}-sccmec.txt Predicted SCCmec type from staphopia-sccmec","title":"Per Sample"},{"location":"bactopia-tools/staph-typer/#agrvate","text":"AgrVATE includes outputs from multiple programs so it gets a separate directory within the sample directory. Extension Description -agr_gp.tab Detailed report for agr kmer matches -agr_operon.fna Agr operon extracted from in-silico PCR -agr_operon_frameshifts.tab Frameshift mutations in CDS of extracted agr operon detected by Snippy log.txt Log files from programs called by AgrVATE -{mummer|snippy}/ Intermediate files from mummer and snippy -summary.tab A final summary report for agr typing","title":"agrvate"},{"location":"bactopia-tools/staph-typer/#usage","text":"Required Parameters: --bactopia STR Directory containing Bactopia analysis results for all samples. AgrVATE Parameters: --typing_only Does agr typing only. Skips agr operon extraction and frameshift detection. spaTyper Parameters: --do_enrich Do PCR product enrichment staphopia-sccmec Parameters: --hamming Report the results as hamming distances. Default: True (perfect match) or False (at least one mismatch) Optional Parameters: --include STR A text file containing sample names to include in the analysis. The expected format is a single sample per line. --exclude STR A text file containing sample names to exclude from the analysis. The expected format is a single sample per line. --prefix DIR Prefix to use for final output files Default: staph-typer --outdir DIR Directory to write results to Default: ./ --min_time INT The minimum number of minutes a job should run before being halted. Default: 60 minutes --max_time INT The maximum number of minutes a job should run before being halted. Default: 120 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single process. Default: 32 Gb --cpus INT Number of processors made available to a single process. Default: 1 Nextflow Related Parameters: --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --registry STR Docker registry to pull containers from. Available options: dockerhub, quay, or github Default: dockerhub --singularity_cache STR Directory where remote Singularity images are stored. If using a cluster, it must be accessible from all compute nodes. Default: NXF_SINGULARITY_CACHEDIR evironment variable, otherwise /local/home/rpetit/.bactopia/singularity --queue STR The name of the queue(s) to be used by a job scheduler (e.g. AWS Batch or SLURM). If using multiple queues, please seperate queues by a comma without spaces. Default: general --disable_scratch All intermediate files created on worker nodes of will be transferred to the head node. Default: Only result files are transferred back --cleanup_workdir After Bactopia is successfully executed, the work directory will be deleted. Warning: by doing this you lose the ability to resume workflows. --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: true --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds --nfconfig STR A Nextflow compatible config file for custom profiles. This allows you to create profiles specific to your environment (e.g. SGE, AWS, SLURM, etc...). This config file is loaded last and will overwrite existing variables if set. Default: Bactopia's default configs -resume Nextflow will attempt to resume a previous run. Please notice it is only a single '-' AWS Batch Related Parameters: --aws_region STR AWS Region to be used by Nextflow Default: us-east-1 --aws_volumes STR Volumes to be mounted from the EC2 instance to the Docker container Default: /opt/conda:/mnt/conda --aws_cli_path STR Path to the AWS CLI for Nextflow to use. Default: /home/ec2-user/conda/bin/aws --aws_upload_storage_class STR The S3 storage slass to use for storing files on S3 Default: STANDARD --aws_max_parallel_transfers INT The number of parallele transfers between EC2 and S3 Default: 8 --aws_delay_between_attempts INT The duration of sleep (in seconds) between each transfer between EC2 and S3 Default: 15 --aws_max_transfer_attempts INT The maximum number of times to retry transferring a file between EC2 and S3 Default: 3 --aws_max_retry INT The maximum number of times to retry a process on AWS Batch Default: 4 --aws_ecr_registry STR The ECR registry containing Bactopia related containers. Default: Use the registry given by --registry Useful Parameters: --version Print workflow version information --help Show this message and exit","title":"Usage"},{"location":"bactopia-tools/staph-typer/#conda-environment","text":"Below is the command used to create the Conda environment. conda create -n staph-typer -c conda-forge -c bioconda agrvate spatyper staphopia-sccmec 'snippy>=4.5.0'","title":"Conda Environment"},{"location":"bactopia-tools/staph-typer/#references","text":"AgrVATE Rapid identification of Staphylococcus aureus agr locus type and agr operon variants. Raghuram V., AgrVATE: Rapid identification of Staphylococcus aureus agr locus type and agr operon variants. spaTyper Computational method for finding spa types. Harmsen D., Claus H., Witte W., Rothg\u00e4nger J., Claus H., Turnwald D., and Vogel U.. Typing of methicillin-resistant Staphylococcus aureus in a university hospital setting using a novel software for spa-repeat determination and database management. J. Clin. Microbiol. 41:5442-5448 (2003). Sanchez-Herrero J. F., and Sullivan M. (2020, October 2). spaTyper: Staphylococcal protein A (spa) characterization pipeline . Zenodo. staphopia-sccmec A standalone version of Staphopia's SCCmec typing method. Petit III R. A., Read T. D., Staphylococcus aureus viewed from the perspective of 40,000+ genomes. PeerJ 6, e5261 (2018).","title":"References"},{"location":"bactopia-tools/summary/","text":"Bactopia Tools - summary \u00b6 The summary tool allows you to quickly aggregate the results of your Bactopia analysis. For each sample the sequence stats (before and after QC), assembly stats, and the annotation stats are put into a single tab-delimited file. For each sample, the summary assigns a rank of Gold , Silver , Bronze , or Fail . The rank is determined by sequence quality and assembly quality. Below is the default cutoffs for each rank. Rank Coverage Mean Per-Read Quality Mean Read Length Total Contigs Gold 100x Q30 95bp 100 Silver 50x Q20 75bp 200 Bronze 20x Q12 49bp 500 Fail <20x < @12 <49bp >500 Samples that fail to meet all the cutoffs for at least a Bronze rank are added to a exclude file. This turns out to be a useful feature beacuse all other Bactopia Tools can read this file and automatically exclude the samples marked as Fail from downstream analysis. Example \u00b6 bactopia tools summary --bactopia ~/bactopia-tutorial/bactopia Output Overview \u00b6 bactopia-tools/ \u2514\u2500\u2500 summary/ \u251c\u2500\u2500 amrfinder \u2502 \u251c\u2500\u2500 amrfinder-(gene|protein)-detailed-summary.txt \u2502 \u2514\u2500\u2500 amrfinder-(gene|protein)-summary.txt \u251c\u2500\u2500 ariba \u2502 \u251c\u2500\u2500 ariba-(card|vfdb|etc...)-detailed-summary.txt \u2502 \u2514\u2500\u2500 ariba-(card|vfdb|etc...)-summary.txt \u251c\u2500\u2500 bactopia-exclude.txt \u251c\u2500\u2500 bactopia-info \u2502 \u251c\u2500\u2500 summary-report.html \u2502 \u251c\u2500\u2500 summary-timeline.html \u2502 \u2514\u2500\u2500 summary-trace.txt \u251c\u2500\u2500 bactopia-results.txt \u2514\u2500\u2500 bactopia-summary.txt Filename Description bactopia-exclude.txt A list of samples and the reason they failed quality cutoffs bactopia-results.txt A tab-delimited file containing sequence, assembly and annotation stats for all samples bactopia-summary.txt Brief breakdown of ranks and qc-failures Directory Description \u00b6 amrfinder \u00b6 Filename Description amrfinder-(gene|protein)-detailed-summary.txt Detailed information about each hit against a specific antimicrobial resistance amrfinder-(gene|protein)-summary.txt A presence/absence matrix for hits against a specific antimicrobial resistance ariba \u00b6 Filename Description ariba-(card|vfdb|etc...)-detailed-summary.txt Detailed information about each hit against a reference Ariba dataset ariba-(card|vfdb|etc...)-summary.txt A presence/absence matrix for hits against a reference Ariba dataset bactopia-info \u00b6 Filename Description summary-report.html The Nextflow Execution Report summary-timeline.html The Nextflow Timeline Report summary-trace.txt The Nextflow Trace report Usage \u00b6 Required Parameters: --bactopia STR Directory containing Bactopia analysis results for all samples. Bactopia Summary Parameters: --gold_coverage FLOAT Minimum amount of coverage required for Gold status Default: 100 --gold_quality INT Minimum per-read mean quality score required for Gold status Default: 30 --gold_read_length INT Minimum mean read length required for Gold status Default: 95 --gold_contigs INT Maximum contig count required for Gold status Default: 100 --silver_coverage FLOAT Minimum amount of coverage required for Silver status Default: 50 --silver_quality INT Minimum per-read mean quality score required for Silver status Default: 20 --silver_read_length INT Minimum mean read length required for Silver status Default: 75 --silver_contigs INT Maximum contig count required for Silver status Default: 200 --min_coverage FLOAT Minimum amount of coverage required to pass Default: 20 --min_quality INT Minimum per-read mean quality score required to pass Default: 12 --min_read_length INT Minimum mean read length required to pass Default: 49 --max_contigs INT Maximum contig count required to pass Default: 500 --min_genome_size INT Minimum assembled genome size. Default: null --max_genome_size INT Maximum assembled genome size. Default: null Ariba Summary Parameters: --all_hits Include all hits (matches and partials) in the summary Default: Only report hits that are a match AMRFinder+ Summary Parameters: --subclass Group the report by subclass (ex. Streptomycin). Default: Group by class (ex. Aminoglycoside) Optional Parameters: --prefix STR Prefix to use for final output files Default: bactopia --outdir DIR Directory to write results to Default: ./ --max_time INT The maximum number of minutes a job should run before being halted. Default: 120 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single process. Default: 32 Gb --cpus INT Number of processors made available to a single process. Default: 4 Nextflow Related Parameters: --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: false --conatainerPath Path to Singularity containers to be used by the 'slurm' profile. Default: /opt/bactopia/singularity --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds Useful Parameters: --verbose Increase the verbosity of processes. --version Print workflow version information --help Show this message and exit","title":"summary"},{"location":"bactopia-tools/summary/#bactopia-tools-summary","text":"The summary tool allows you to quickly aggregate the results of your Bactopia analysis. For each sample the sequence stats (before and after QC), assembly stats, and the annotation stats are put into a single tab-delimited file. For each sample, the summary assigns a rank of Gold , Silver , Bronze , or Fail . The rank is determined by sequence quality and assembly quality. Below is the default cutoffs for each rank. Rank Coverage Mean Per-Read Quality Mean Read Length Total Contigs Gold 100x Q30 95bp 100 Silver 50x Q20 75bp 200 Bronze 20x Q12 49bp 500 Fail <20x < @12 <49bp >500 Samples that fail to meet all the cutoffs for at least a Bronze rank are added to a exclude file. This turns out to be a useful feature beacuse all other Bactopia Tools can read this file and automatically exclude the samples marked as Fail from downstream analysis.","title":"Bactopia Tools - summary"},{"location":"bactopia-tools/summary/#example","text":"bactopia tools summary --bactopia ~/bactopia-tutorial/bactopia","title":"Example"},{"location":"bactopia-tools/summary/#output-overview","text":"bactopia-tools/ \u2514\u2500\u2500 summary/ \u251c\u2500\u2500 amrfinder \u2502 \u251c\u2500\u2500 amrfinder-(gene|protein)-detailed-summary.txt \u2502 \u2514\u2500\u2500 amrfinder-(gene|protein)-summary.txt \u251c\u2500\u2500 ariba \u2502 \u251c\u2500\u2500 ariba-(card|vfdb|etc...)-detailed-summary.txt \u2502 \u2514\u2500\u2500 ariba-(card|vfdb|etc...)-summary.txt \u251c\u2500\u2500 bactopia-exclude.txt \u251c\u2500\u2500 bactopia-info \u2502 \u251c\u2500\u2500 summary-report.html \u2502 \u251c\u2500\u2500 summary-timeline.html \u2502 \u2514\u2500\u2500 summary-trace.txt \u251c\u2500\u2500 bactopia-results.txt \u2514\u2500\u2500 bactopia-summary.txt Filename Description bactopia-exclude.txt A list of samples and the reason they failed quality cutoffs bactopia-results.txt A tab-delimited file containing sequence, assembly and annotation stats for all samples bactopia-summary.txt Brief breakdown of ranks and qc-failures","title":"Output Overview"},{"location":"bactopia-tools/summary/#directory-description","text":"","title":"Directory Description"},{"location":"bactopia-tools/summary/#amrfinder","text":"Filename Description amrfinder-(gene|protein)-detailed-summary.txt Detailed information about each hit against a specific antimicrobial resistance amrfinder-(gene|protein)-summary.txt A presence/absence matrix for hits against a specific antimicrobial resistance","title":"amrfinder"},{"location":"bactopia-tools/summary/#ariba","text":"Filename Description ariba-(card|vfdb|etc...)-detailed-summary.txt Detailed information about each hit against a reference Ariba dataset ariba-(card|vfdb|etc...)-summary.txt A presence/absence matrix for hits against a reference Ariba dataset","title":"ariba"},{"location":"bactopia-tools/summary/#bactopia-info","text":"Filename Description summary-report.html The Nextflow Execution Report summary-timeline.html The Nextflow Timeline Report summary-trace.txt The Nextflow Trace report","title":"bactopia-info"},{"location":"bactopia-tools/summary/#usage","text":"Required Parameters: --bactopia STR Directory containing Bactopia analysis results for all samples. Bactopia Summary Parameters: --gold_coverage FLOAT Minimum amount of coverage required for Gold status Default: 100 --gold_quality INT Minimum per-read mean quality score required for Gold status Default: 30 --gold_read_length INT Minimum mean read length required for Gold status Default: 95 --gold_contigs INT Maximum contig count required for Gold status Default: 100 --silver_coverage FLOAT Minimum amount of coverage required for Silver status Default: 50 --silver_quality INT Minimum per-read mean quality score required for Silver status Default: 20 --silver_read_length INT Minimum mean read length required for Silver status Default: 75 --silver_contigs INT Maximum contig count required for Silver status Default: 200 --min_coverage FLOAT Minimum amount of coverage required to pass Default: 20 --min_quality INT Minimum per-read mean quality score required to pass Default: 12 --min_read_length INT Minimum mean read length required to pass Default: 49 --max_contigs INT Maximum contig count required to pass Default: 500 --min_genome_size INT Minimum assembled genome size. Default: null --max_genome_size INT Maximum assembled genome size. Default: null Ariba Summary Parameters: --all_hits Include all hits (matches and partials) in the summary Default: Only report hits that are a match AMRFinder+ Summary Parameters: --subclass Group the report by subclass (ex. Streptomycin). Default: Group by class (ex. Aminoglycoside) Optional Parameters: --prefix STR Prefix to use for final output files Default: bactopia --outdir DIR Directory to write results to Default: ./ --max_time INT The maximum number of minutes a job should run before being halted. Default: 120 minutes --max_memory INT The maximum amount of memory (Gb) allowed to a single process. Default: 32 Gb --cpus INT Number of processors made available to a single process. Default: 4 Nextflow Related Parameters: --condadir DIR Directory to Nextflow should use for Conda environments Default: Bactopia's Nextflow directory --publish_mode Set Nextflow's method for publishing output files. Allowed methods are: 'copy' (default) Copies the output files into the published directory. 'copyNoFollow' Copies the output files into the published directory without following symlinks ie. copies the links themselves. 'link' Creates a hard link in the published directory for each process output file. 'rellink' Creates a relative symbolic link in the published directory for each process output file. 'symlink' Creates an absolute symbolic link in the published directory for each process output file. Default: copy --force Nextflow will overwrite existing output files. Default: false --conatainerPath Path to Singularity containers to be used by the 'slurm' profile. Default: /opt/bactopia/singularity --sleep_time After reading datases, the amount of time (seconds) Nextflow will wait before execution. Default: 5 seconds Useful Parameters: --verbose Increase the verbosity of processes. --version Print workflow version information --help Show this message and exit","title":"Usage"},{"location":"bactopia-tools/whatsgnu/","text":"","title":"Whatsgnu"}]}